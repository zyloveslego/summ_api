{
    "0": "A Survey of Text Watermarking in the Era of Large Language Models",
    "1": "AIWEI LIU ∗ and LEYI PAN ∗ , Tsinghua University",
    "2": "YIJIAN LU and JINGJING LI, The Chinese University of Hong Kong",
    "3": "XUMING HU, The Hong Kong University of Science and Technology (Guangzhou)",
    "4": "XI ZHANG, Beijing University of Posts and Telecommunications",
    "5": "LIJIE WEN, Tsinghua University",
    "6": "IRWIN KING, The Chinese University of Hong Kong",
    "7": "HUI XIONG, The Hong Kong University of Science and Technology (Guangzhou)",
    "8": "PHILIP S. YU, University of Illinois Chicago",
    "9": "Text watermarking algorithms are crucial for protecting the copyright of textual content.",
    "10": "Historically, their capabilities and application scenarios were limited.",
    "11": "However, recent advancements in large language models (LLMs) have revolutionized these techniques.",
    "12": "LLMs not only enhance text watermarking algorithms with their advanced text understanding and generation abilities but also create a need for employing these algorithms to protect their own copyrights.",
    "13": "This paper presents a comprehensive survey of text watermarking technology in the LLM era, aiming to further its development and application.",
    "14": "CCS Concepts: • Security and privacy → Digital rights management; • Computing methodologies → Natural language processing.",
    "15": "Additional Key Words and Phrases: Text Watermark, Large Language Models, Copyright Protection",
    "16": "ACM Reference Format:",
    "17": "Aiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Xi Zhang, Lijie Wen, Irwin King, Hui Xiong, and Philip S. Yu.",
    "18": "2024.",
    "19": "A Survey of Text Watermarking in the Era of Large Language Models.",
    "20": "1, 1 (January 2024), 35 pages.",
    "21": "https://doi.org/10.1145/nnnnnnn.nnnnnnn",
    "22": "1 INTRODUCTION",
    "23": "Text watermarking involves embedding unique, imperceptible identifiers (watermarks) into textual content.",
    "24": "These watermarks are designed to be robust yet inconspicuous, ensuring that the integrity and ownership of the content are preserved without affecting its readability or meaning.",
    "25": "Historically, text watermarking has played a crucial role in various domains, from copyright protection and document authentication to preventing plagiarism and unauthorized content distribution [ 32 ].",
    "26": "With",
    "28": "arXiv:2312.07913v4  [cs.CL]  23 Jan 2024",
    "29": "(a) A description of how LLMs promote the development of text watermarking techniques and broaden their application scenarios.",
    "30": "(b) Number of publications in the field of text watermarking and LLMs (the data for \"Number of Publications in the field of LLMs\" is sourced from Zhao et al.",
    "31": "[102])",
    "32": "Fig.",
    "33": "1.",
    "34": "Relationships between the development of text watermarking techniques and Large Language Models (LLMs).",
    "35": "the advancement of Large Language Models (LLMs), both the techniques and application scenarios of text watermarking have seen significant development.",
    "36": "As shown in Figure 1(a), this primarily includes the construction of enhanced text watermarking algorithms using LLMs, the application of existing text watermarking algorithms to LLMs, and the exploration of text watermarking algorithms that are more closely integrated with LLMs.",
    "37": "The flourishing development of LLMs has propelled a thriving research landscape within the realm of text watermarking, as depicted in Figure 1(b).",
    "38": "Especially with the advent of ChatGPT, text watermarking has notably surged into a research fervor.",
    "39": "This paper surveys the interplay between LLMs and text watermarking, highlighting their synergistic potential in the contemporary landscape of language models.",
    "40": "In the following content, we will separately discuss why text watermarking benefits the application of LLMs (section 1.1), why utilizing LLMs can lead to the development of superior text watermarking algorithms (section 1.2), and the contributions of this survey (section 1.3).",
    "41": "1.1 Why is Text Watermarking Beneﬁcial for LLMs?",
    "42": "In recent years, large language models (LLMs) have made significant progress in the field of natural language processing.",
    "43": "As the parameter count of these large language models continues to increase, their ability to understand and generate language has also substantially improved.",
    "44": "Notable examples include GPT [ 65 ], BART [ 40 ], T5 [ 67 ], OPT [ 99 ], LaMDA [ 81 ], LLaMA [ 84 ], and GPT4 [ 60 ].",
    "45": "These large language models have achieved excellent performance in a variety of downstream tasks, including machine translation [ 13 , 24 , 24 , 108 ], dialogue systems [ 29 , 53 , 73 , 81 ], code generation [ 58 , 59 , 86 , 91 ], and other tasks [ 41 , 42 , 80 , 101 ].",
    "46": "A recent work even suggests that GPT-4 is an early (yet still incomplete) version of an artificial general intelligence (AGI) system [7].",
    "47": "However, the utilization of Large Language Models (LLMs) introduces several challenges.",
    "48": "Primarily, their capacity for rapid, high-quality text generation may expedite the dissemination of misinformation [ 51 ].",
    "49": "Additionally, there are critical intellectual property concerns involving LLMs, encompassing both the copyright of training datasets [ 79 ] and the establishment of rights to impede knowledge extraction from LLMs [ 105 ].",
    "50": "Implementing effective tagging and detection methods for LLM-generated text would substantially alleviate these problems.",
    "51": "Text watermarking",
    "52": "presents as a viable approach to these challenges.",
    "53": "It involves embedding a discrete, identifiable marker within LLM-produced text, enabling content tracking and origin attribution.",
    "54": "1.2 Why are LLMs Beneﬁcial for Text Watermarking?",
    "55": "A key challenge in text watermarking is to embed watermarks without distorting the original text’s meaning or readability.",
    "56": "Traditional methods often fail to modify text without altering its semantics [ 3 , 52 , 82 ].",
    "57": "The necessity for algorithms to comprehend and control text semantics contributes to this difficulty.",
    "58": "However, Large Language Models (LLMs) significantly alter this landscape.",
    "59": "Due to their advanced grasp of language semantics and context, LLMs facilitate sophisticated watermarking approaches that embed watermarks with minimal impact on the text’s inherent meaning [ 1 , 98 ].",
    "60": "This integration results in more effective and subtle watermarking techniques, preserving the text’s original intent while embedding essential watermark features.",
    "61": "1.3 Why a Survey for Text Watermarking in the Era of LLMs?",
    "62": "Text watermarking technology and large language models can effectively enhance each other.",
    "63": "For instance, text generated by LLMs can be watermarked using text watermarking algorithms [ 6 , 57 , 64 , 70 , 92 , 93 , 95 ], or LLMs themselves can be utilized to embed watermarks in texts [ 1 , 98 ].",
    "64": "Additionally, watermark algorithms can be directly incorporated during the text generation process of LLMs [ 33 , 45 , 46 , 69 , 90 , 103 ].",
    "65": "However, comprehensive studies exploring text watermarking in the era of LLMs are lacking.",
    "66": "Existing surveys predominantly focus on watermarking techniques developed before the advent of LLMs [2, 32].",
    "67": "In this study, we present the first comprehensive survey of text watermarking algorithms in the context of large language models.",
    "68": "This survey encompasses a detailed definition of text watermarking algorithms and explores the interrelations among various methods.",
    "69": "Recognizing the complexity and diversity of text watermarking technology, we examine the evaluation metrics for these algorithms, focusing on success rate, robustness, impact on text quality, and unforgeability.",
    "70": "Moreover, we discuss current applications of text watermarking, such as copyright protection, fake news detection, and academic integrity.",
    "71": "This survey aims to furnish researchers with an in-depth understanding of text watermarking algorithms, facilitating comparisons and contrasts among different methods.",
    "72": "It also guides users interested in applying text watermarking technology by helping them choose suitable algorithms under different application scenarios.",
    "73": "Organization of this survey.",
    "74": "This survey is structured as follows: Section 2 introduces text watermarking definitions and key algorithm properties.",
    "75": "Section 3 and Section 4 address two primary text watermarking categories: for existing text and for LLM-generated text.",
    "76": "Section 5 discusses evaluation metrics for these algorithms, including success rate, impact on text quality, robustness, and unforgeability.",
    "77": "Section 6 explores application scenarios, namely copyright protection, academic integrity, and fake news detection.",
    "78": "Section 7 examines ongoing challenges and potential future research avenues in text watermarking.",
    "79": "The survey concludes in Section 8.",
    "80": "2 PRELIMINARIES OF TEXT WATERMARKING",
    "81": "To facilitate the introduction of various text watermarking algorithms as well as its evaluation methods in subsequent sections, this section presents the definition of text watermarking algorithms and outlines the characteristics that an excellent text watermarking algorithm should possess.",
    "82": "The taxonomy of text watermarking algorithms is also introduced in this section.",
    "83": "2.1 Text Watermarking Algorithms",
    "84": "A text watermarking algorithm typically comprises two components: a watermark generator A , and a watermark detector D .",
    "85": "The watermark generator A takes a text x and a watermark message",
    "86": "𝑤 as inputs and outputs a watermarked text t, expressed as:",
    "87": "A(x, 𝑤) = t. (1)",
    "88": "This watermarked text t is either an altered form of the original text x or a newly generated text in response to x, particularly in contexts like prompts for LLMs.",
    "89": "The watermark message, denoted as 𝑤 , can be a zero-bit watermark, signifying merely its presence or absence, or a multi-bit watermark, embedding detailed, customized information.",
    "90": "The phrase ‘watermark payload’ will henceforth denote the information volume conveyed by 𝑤.",
    "91": "For the watermark detector D , its input is any text t, and its output is its predicted watermark message for the text, denoted as D( t ) = 𝑤 .",
    "92": "If the output is None, it implies that the text contains no watermark information.",
    "93": "2.2 Key Characteristics of Text Watermarking Algorithms",
    "94": "To enhance the understanding of objectives in text watermarking algorithm design, this section highlights the critical characteristics these algorithms should have.",
    "95": "These primarily include a high success rate of watermark detection, minimal impact on text quality, robustness of the detector against text modifications, and unforgeability.",
    "96": "High success rate of watermark detection.",
    "97": "The high success rate of a watermark algorithm indicates that its detector D can accurately detect the generated watermark text t. For a zero-bit watermark message, this accuracy is usually measured using binary classification.",
    "98": "When 𝑤 consists of multiple bits, the evaluation commonly used is bit accuracy.",
    "99": "If a watermarking algorithm maintains a high success rate at a large bit number, it implies that it possesses a high payload.",
    "100": "Low Impact on Text Quality.",
    "101": "Let A( x , None) represent the text generated without watermark.",
    "102": "When x is the target text, the output remains x.",
    "103": "In the context of a prompt for a LLM, it denotes the LLM’s output without watermark insertion.",
    "104": "An effective watermark algorithm minimally affects text quality, satisfying the condition:",
    "105": "∀𝑤 𝑖 , R(A (x, None), A(x, 𝑤 𝑖 )) < 𝛿 (2)",
    "106": "where R is a function evaluating text quality from multiple perspectives, as will be discussed in section 5. 𝛿 represents a threshold.",
    "107": "If the difference in the evaluated scores of two texts is less than this threshold, they are considered to be of similar quality.",
    "108": "Robustness to watermark removal attack.",
    "109": "We use an operation U to denote the watermark removal operations, which will be detailed in section 5.",
    "110": "If a watermarking algorithm is robust against watermark removal attacks, it should satisfy the following conditions:",
    "111": "∀𝑤 𝑖 , ∀t = A(x,𝑤 𝑖 ), 𝑃 (D (U (t)) = 𝑤 𝑖 ) > 𝛽.",
    "112": "(3)",
    "113": "where 𝛽 is a threshold.",
    "114": "If the probability of correctly detecting a watermarked text after text modification exceeds 𝛽, the algorithm is deemed sufficiently robust.",
    "115": "Unforgeability.",
    "116": "Unforgeability refers to the difficulty for a third party to counterfeit text watermarks.",
    "117": "Typically, if the watermark’s generator A is acquired by an attacker, the watermark can certainly be forged.",
    "118": "Consequently, unforgeability primarily hinges on whether an attacker, lacking access to A , can still counterfeit the watermark.",
    "119": "This divides into two scenarios: the private detection scenario, where the attacker is devoid of the detector D and limited to detecting watermarks, and the public detection scenario, where the attacker possesses D.",
    "120": "Although an ideal text watermarking algorithm should possess all four aforementioned characteristics, it is challenging to balance them.",
    "121": "Enhancing one aspect might impact performance in another.",
    "122": "In subsequent sections, we will delve deeper into how different watermark algorithms strike a balance among these characteristics.",
    "123": "Text Watermarking Watermarking for Existing Text (§3) Format-based Watermarking (§3.1) Line/Word-Shift Coding (Brassil et al .",
    "124": "[6] ), UniSpaCh (Por et al .",
    "125": "[64] ), Unicode Homoglyph Substitution (Rizzo et al.",
    "126": "[70]), EasyMark (Sato et al.",
    "127": "[72]) Lexical-based Watermarking (§3.2) Equimark (Topkara et al .",
    "128": "[83] ), DeepTextMark (Munyer and Zhong [57] ), Context-aware Lexical Substitution (Yang et al .",
    "129": "[93] ), Binary-encoding Lexical Substitution (Yang et al .",
    "130": "[92] ), Robust Multi-bit Watermark (Yoo et al.",
    "131": "[95]) Syntatic-based Watermarking (§3.3) NLW (Atallah et al .",
    "132": "[3] ), WANE (Topkara et al .",
    "133": "[82] ), MA-NLW (Meral et al.",
    "134": "[52]) Generation-based Watermarking (§3.4) AWT (Abdelnabi and Fritz [1] ), REMARK-LLM (Zhang et al.",
    "135": "[98]) Watermarking for LLMs (§4) Training Time Watermarking (§4.1) Dataset Trigger (Liu et al .",
    "136": "[48] ), Clean-Label Backdoor Watermark (Tang et al .",
    "137": "[79] ), Coprotector (Sun et al.",
    "138": "[75]), CodeMark (Sun et al.",
    "139": "[74]) Watermarking During Logits Generation (§4.2) KGW (Kirchenbauer et al .",
    "140": "[33] ), SWEET (Lee et al .",
    "141": "[39] ), Unbiased Watermark (Hu et al .",
    "142": "[28] ), DiPmark (Wu et al .",
    "143": "[90] ), COLOR (Yoo et al .",
    "144": "[96] ), CTWL (Wang et al .",
    "145": "[89] ), ThreeBricks (Fernandez et al .",
    "146": "[19] ), Unigram Watermark (Zhao et al .",
    "147": "[103] ), KGWreliability (Kirchenbauer et al .",
    "148": "[34] ), NS-Watermark (Takezawa et al .",
    "149": "[76] ), Semantic Invariant Robust Watermark (Liu et al .",
    "150": "[46] ), Unforgeable Watermark (Liu et al .",
    "151": "[45] ), Publicly Detectable Watermark (Fairoze et al .",
    "152": "[16] ), Semantic-based Robust Watermark (Ren et al.",
    "153": "[69]) Watermarking During Token Sampling (§4.3) Undetectable Watermark (Christ et al .",
    "154": "[11] ), Robust Distortion-free Watermark (Kuditipudi et al .",
    "155": "[36] ), SemStamp (Hou et al.",
    "156": "[27]))",
    "157": "Fig.",
    "158": "2.",
    "159": "The text watermarking methods can be broadly divided into two categories: Watermarking for Existing Text (section 3) and Watermarking for LLMs (section 4).",
    "160": "2.3 Taxonomy of Text Watermarking Algorithms",
    "161": "To facilitate the organization of different text watermarking algorithms in section 3 and section 4, this section provides an overview of our summarized taxonomy of text watermarking algorithms.",
    "162": "Figure 2 categorizes text watermarking algorithms into two primary types.",
    "163": "The first, Watermarking for Existing Text, embeds watermarks into pre-existing texts, as elaborated in Section 3.",
    "164": "This technique typically utilizes semantically invariant transformations for watermark integration.",
    "165": "The second type, Watermarking for Large Language Models, involves modifying LLMs, further detailed in Section 4.",
    "166": "This method either embeds specific features into the training dataset or alters the LLMs’ text generation process, producing watermarked text from the input prompt.",
    "167": "Figure 3 offers a detailed illustration of these methods, emphasizing the nuances of current text watermarking techniques.",
    "168": "Notably, both the ‘watermarking during logits generation’ and ‘watermarking during token sampling’ methods apply watermarks at the LLM inference stage, a process collectively referred to as ‘inference time watermarking’ in this context.",
    "169": "The dashed line box under inference time watermarking represents the detailed process of how the watermarked",
    "170": "3 WATERMARKING FOR EXISTING TEXT",
    "171": "Watermarking for existing text involves modifying a generated text to produce a watermarked text.",
    "172": "Based on the granularity of modifications, these methods are primarily categorized into four types:",
    "174": "Original Text Watermarked Text Watermarking for LLMs Training Time Watermarking Inference Time Watermarking Training Set Format-based watermarking, drawing inspiration from image watermarking [ 4 ], alters text format rather than content to embed watermarks.",
    "175": "For example, Brassil et al .",
    "176": "[6] introduced line-shift coding and word shift-coding by vertically and horizontally adjusting text lines and words, respectively.",
    "177": "The detection process measures distances between text line profiles or word column profiles to identify shifts.",
    "178": "However, this method is confined to image-formatted text and does not return a text string with an embedded watermark.",
    "179": "To address this, Unicode codepoint insertion/replacement methods have emerged.",
    "180": "Por et al .",
    "181": "[64] developed UniSpach , inserting Unicode space characters in various text spacings.",
    "182": "Rizzo et al .",
    "183": "[70] presented a unicode homoglyph substitution method, exploiting visually similar but differently coded text symbols (e.g., U+0043 and U+216d for ‘C’, U+004c and U+216c for ‘L’).",
    "184": "Following this, a family of simple watermarks named EasyMark [ 72 ] is proposed recently, composed of three different methods: WhiteMark , VariantMark and PrintMark .",
    "185": "Specifically, WhiteMark replaces a whitespace (U+0020) with another codepoint of a whitespace (e.g.",
    "186": "U+2004).",
    "187": "VariantMark leverages variation selectors of Unicode to embed",
    "188": "The stars shimmered format-based watermarking (section 3.1), lexical-based watermarking (section 3.2), syntactic-based watermarking (section 3.3) and generation-based watermarking (section 3.4).",
    "189": "Fig.",
    "190": "3.",
    "191": "This ﬁgure oﬀers a concise overview of various text watermarking techniques.",
    "192": "It categorizes watermarking into two main types: for Existing Text and for Large Language Models (LLMs).",
    "193": "The former (section 3) embeds watermarks in existing text using methods like format-based (section 3.1), e.g., white-space substitution; lexical-based (section 3.2), e.g., synonym substitution; syntactic-based (section 3.3), e.g., passivization; and generation-based (section 3.4), employing pretrained language models.",
    "194": "The latter (section 4) focuses on embedding watermarks in LLMs, ensuring their presence in generated text.",
    "195": "This can be achieved during training (section 4.1), logits generation (section 4.2), or token sampling (section 4.3).",
    "196": "3.1 Format-based Watermarking",
    "198": "hard-to-perceive format into CJK texts.",
    "199": "PrintMark , coping with printed texts, uses ligature or whitespaces with slightly different lengths to embed watermark messages.",
    "200": "Correspondingly, the watermark detection process involves searching for and counting the certain codepoints that have been inserted within the text.",
    "201": "As these watermarking methods relied on the richness of Unicode encoding, their watermark payload is often quite large.",
    "202": "Despite the simplicity and effectiveness of format-based watermarking methods in embedding substantial payloads without altering textual content, their format modifications can be conspicuous under certain conditions, as Por et al .",
    "203": "[64] noted with the DASH attack.",
    "204": "Consequently, these modified formats are vulnerable to removal via canonicalization [ 5 ], involving techniques such as resetting line spacing and replacing specific codepoints throughout the text.",
    "205": "Moreover, these detectable formats may be exploited for watermark forgery, compromising detection efficacy.",
    "206": "3.2 Lexical-based Watermarking",
    "207": "Format-based watermarking approaches, which only modify text’s superficial format, are prone to be spotted, making them easily removable through reformatting.",
    "208": "This highlights the need for investigating deeper watermark embedding methods in text.",
    "209": "A number of studies have adopted wordlevel modifications, where selected words are replaced with their synonyms without altering the sentence’s syntactic structure [ 18 , 57 , 83 , 92 , 93 , 95 ].",
    "210": "These are known as lexical-based watermarking approaches.",
    "211": "Topkara et al .",
    "212": "[83] introduced a synonym substitution method, employing WordNet [ 18 ] as the synonym source.",
    "213": "The watermark detection replicates the embedding process, applying inverse rules for message extraction.",
    "214": "Munyer and Zhong [57] enhanced semantic modeling by using a pretrained Word2Vec model, converting selected words into vectors and identifying n-nearest vectors as replacement candidates.",
    "215": "They employed a binary classifier with a pretrained BERT model and transformer blocks for watermark detection.",
    "216": "The aforementioned watermarking methods relying on context-independent synonym substitution ( WordNet & Word2Vec ) often neglect the context of target words, potentially compromising sentence semantics and text quality.",
    "217": "To address this, context-aware lexical substitution has been incorporated into text watermarking.",
    "218": "Yang et al .",
    "219": "[93] introduced a BERT-based infill model for generating contextually appropriate lexical substitutions.",
    "220": "The watermark detection algorithm parallels the generation process, identifying watermark-bearing words, generating substitutes, and applying inverse rules for message extraction.",
    "221": "Yang et al .",
    "222": "[92] streamlined watermark detection by encoding each word with a random binary value and substituting bit-0 words with context-based synonyms representing bit-1.",
    "223": "As non-watermarked text adheres to a Bernoulli distribution, altered during watermarking, statistical tests can effectively detect watermarks.",
    "224": "Yoo et al .",
    "225": "[95] enhanced robustness against removal attacks by fine-tuning a BERT-based infill model with keyword-preserving and syntactically invariant corruptions, achieving superior robustness compared to earlier methods.",
    "226": "3.3 Syntactic-based Watermarking",
    "227": "The lexical-based methods aim to embed watermarks by substituting specific words, maintaining the sentence’s syntax.",
    "228": "Yet, these approaches, relying exclusively on lexical substitution, might not be robust against straightforward watermark removal tactics like random synonym replacement.",
    "229": "Consequently, several studies have explored embedding watermarks in a manner that resists removal, notably by modifying the text’s syntax structure.",
    "230": "These methods are known as syntactic-based watermarking approaches.",
    "231": "Atallah et al .",
    "232": "[3] introduced three typical syntax transformations–Adjunct Movement, Clefting and Passivization–to embed watermark messages, where:",
    "235": "• Adjunct Movement entails relocating adjuncts within a sentence.",
    "236": "Example: ‘often’ can be variably positioned in The dog often chased the cat.",
    "237": "• Clefting emphasizes a sentence part, typically the subject.",
    "238": "For instance, The dog chased the cat becomes It was the dog that chased the cat to accentuate the dog.",
    "239": "• Passivization changes active sentences with transitive verbs to passive voice.",
    "240": "For example, The dog chased the cat is passivized to The cat was chased by the dog.",
    "241": "Each transformation type is assigned a unique message bit: Adjunct Movement to 0, Clefting to 1, and Passivization to 2.",
    "242": "In watermark detection, both original and altered texts are converted into syntax trees, and their structures are compared for message extraction.",
    "243": "Expanding this concept, Topkara et al .",
    "244": "[82] introduced additional syntax transformations: Activization and Topicalization.",
    "245": "Moreover, research extends beyond English, with Meral et al .",
    "246": "[52] analyzing 20 morphosyntactic tools in Turkish, highlighting that languages with significant suffixation and agglutination, such as Turkish, are well-suited for syntactic watermarking.",
    "247": "While syntactic-based watermarking effectively embeds watermarks in a concealed manner, it heavily depends on a language’s grammatical rules, often requiring language-specific customization.",
    "248": "Frequent syntactic changes in some texts may also alter their original style and fluency.",
    "249": "3.4 Generation-based Watermarking",
    "250": "The aforementioned methods have indeed made significant strides in the field of text watermarking.",
    "251": "However, these methods are still quite reliant on specific rules, which may lead to unnatural modifications in some contexts.",
    "252": "On one hand, the unnatural modifications might lead to degradation of text quality.",
    "253": "On the other hand, if these clues are observed by human attackers, there is a higher likelihood of them to design watermark removal attacks or attempt to forge watermarks deliberately and specifically.",
    "254": "A groundbreaking advancement would be generating watermarked text directly from the original text and the watermark message.",
    "255": "With the rapid development of pretrained language models, such techniques are gradually becoming feasible.",
    "256": "In the realm of generation-based approaches, the encoded original text and the watermark message are typically fed into a pretrained language model, which subsequently generates the watermarked text end-to-end.",
    "257": "Abdelnabi and Fritz [1] developed AWT , an end-to-end watermarking scheme utilizing a transformer encoder to encode sentences and merge sentence and message embeddings.",
    "258": "This composite is processed by a transformer decoder to generate watermarked text.",
    "259": "For watermark detection, the text undergoes transformer encoder layers to retrieve the secret message.",
    "260": "Extending AWT , Zhang et al .",
    "261": "[98] identified disparities between the dense watermarked text distributions and sparse one-hot watermark encodings.",
    "262": "Addressing this, they proposed REMARK-LLM , employing a pretrained language model for watermark insertion.",
    "263": "A key innovation is the reparameterization step using Gumbel-Softmax [ 31 ] to yield sparser token distributions.",
    "264": "A transformer-based decoder extracts messages from these embeddings.",
    "265": "REMARK-LLM notably embeds double the signatures of AWT while maintaining detection efficacy, significantly enhancing watermark payload capacity.",
    "266": "4 WATERMARKING FOR LLMS",
    "267": "In the above section, we discussed watermarking methods for existing text.",
    "268": "With more and more texts directly generated by large language models, studying text watermarking techniques for large models has become a trend.",
    "269": "Unlike the method of modifying existing text to add a watermark, the watermarking for LLMs technology directly enables LLM-generated text to contain a watermark.",
    "270": "Specifically, given a watermark message 𝑤 and a prompt x, the process of watermarking for LLMs is defined by the following expression:",
    "271": "A(x, 𝑤) = 𝑀 𝑤 (x) = t. (4)",
    "272": "To facilitate explanation, we assume that the watermarked text is directly generated by a language language model 𝑀 𝑤 with an embedded watermark message.",
    "273": "To provide a better understanding of how to add a watermark to a Large Language Model, we first provide an overview of the process used for generating text with an LLM.",
    "274": "Specifically, this involves three steps, LLM training, logits generation and token sampling:",
    "275": "• Step1: LLM Training.",
    "276": "This step involves training a large language model, M, with a dataset D. Training objectives vary based on the application, with next token prediction being the most common [66].",
    "277": "• Step2: Logits Generation.",
    "278": "With the trained LLM M, given a prompt x and a sequence of prior tokens t 0:(𝑖−1) , the LLM predicts the next token t (𝑖 ) ’s probability distribution in the vocabulary V, expressed as logits l (𝑖 ) :",
    "279": "l (𝑖 ) = 𝑀 (x, t 0:(𝑖−1) ).",
    "280": "(5)",
    "281": "• Step3: Token Sampling.",
    "282": "The next token t (𝑖 ) is selected from l (𝑖 ) , using methods like nucleus sampling [26], greedy decoding, or beam search.",
    "283": "The sampling process is denoted as:",
    "284": "t (𝑖 ) = 𝑆 (softmax(l (𝑖 ) )).",
    "285": "(6)",
    "286": "Through these steps, LLM M generates a token t (𝑖 ) .",
    "287": "For multiple tokens, logits generation and token sampling are iteratively repeated.",
    "288": "In aligning with the three critical phases of text generation using Large Language Models (LLMs), watermarking techniques for LLMs are similarly categorized into three distinct types.",
    "289": "These are: watermarking at training time, during logits generation, and in the token sampling phase.",
    "290": "Detailed discussions of these watermarking methods are presented in sections 4.1, 4.2, and 4.3, respectively.",
    "291": "4.1 Watermarking during LLM Training",
    "292": "The objective of training time watermarking is to insert a watermark message, 𝑤 , into a Large Language Model (LLM) during training phase.",
    "293": "This involves incorporating 𝑤 into the training dataset 𝐷 .",
    "294": "The procedure starts with selecting a subset 𝐷 𝑠 from 𝐷 .",
    "295": "The watermark message is embedded in 𝐷 𝑠 using a watermark embedding function 𝑊 , resulting in the watermarked subset e 𝐷 𝑠 , where e 𝐷 𝑠 = 𝑊 (𝐷 𝑠 , 𝑤 ) .",
    "296": "The watermarked dataset 𝐷 𝑤 is then constructed by combining the original dataset 𝐷 with e 𝐷 𝑠 , after removing 𝐷 𝑠 :",
    "297": "Equation content: \\[\nD_i = (D_j \\cup D_k) \\cap \\overline{D_l}\n\\]",
    "298": "An LLM trained on 𝐷 𝑤 integrates the watermark 𝑤 , yielding a model 𝑀 𝑤 .",
    "299": "This model displays characteristics of 𝑤 when used on data resembling e 𝐷𝑠, facilitating watermark detection.",
    "300": "The critical element in this process is designing the embedding function 𝑊 , particularly transforming 𝐷 𝑠 into e 𝐷 𝑠 .",
    "301": "Current strategies for crafting 𝑊 are largely inspired by backdoor attack concepts, where a specific trigger in the training set e 𝐷𝑠 = (𝑥, 𝑦) is embedded in input 𝑥 to create a detectable output feature.",
    "302": "Depending on the trigger’s impact on the original label 𝑦 , these methods are broadly categorized into two types.",
    "303": "The first category involves inserting a trigger into x, altering the corresponding label y.",
    "304": "For example, Liu et al .",
    "305": "[48] introduced a watermark algorithm for text classification, inserting triggers at character, word, or sentence levels in a text subset, uniformly changing their labels to a specific 𝑦 𝑡 .",
    "306": "Sun et al .",
    "307": "[75] applied a similar strategy in code generation, using word or sentence-level triggers and code corrupting.",
    "308": "While these methods effectively detect models with trigger-incorporated text, they may degrade the model’s performance by compromising label integrity.",
    "309": "To mitigate label distortion, alternative approaches are employed.",
    "310": "Tang et al .",
    "311": "[79] used adversarial learning to identify and trigger-mark samples within category C without changing their labels.",
    "312": "For",
    "313": "Fig.",
    "314": "4.",
    "315": "A more illustrative description of the KGW [33] algorithm.",
    "316": "code generation, Sun et al .",
    "317": "[74] performed semantically invariant code transformations, such as syntactic sugar variations, facilitating trigger detection in varied code styles.",
    "318": "The primary goal of training time watermarking is to safeguard dataset copyrights against unauthorized use.",
    "319": "Despite its ability to embed watermarks in LLMs, Training Time Watermarking has notable drawbacks.",
    "320": "The watermarked LLM 𝑀 𝑤 generates watermarked outputs only for specific inputs.",
    "321": "The watermark payload is limited, mainly serving as an indicator rather than conveying extensive information.",
    "322": "Modifying the watermark message 𝑤 usually necessitates model retraining, a resourceintensive task.",
    "323": "Hence, the application scope of Training Time Watermarking is relatively restricted.",
    "324": "4.2 Watermarking during Logits Generation",
    "325": "Watermarking during logits generation refers to the insertion of a watermark message 𝑤 into the logits generated by LLMs.",
    "326": "This technique, which does not require modifying the LLM parameters, is more versatile and cost-effective than training time watermarking methods.",
    "327": "In this context, the watermarking algorithm A alters the logits from the LLM to incorporate the watermark message 𝑤.",
    "328": "The modified logits f l (𝑖 ) can be computed as follows:",
    "329": "f l (𝑖 ) = A (𝑀 (x, t 0:(𝑖−1) ), 𝑤) = 𝑀 𝑤 (x, t 0:(𝑖−1) ), (8)",
    "330": "where f l (𝑖 ) is assumed to be produced by a watermarked LLM 𝑀 𝑤 .",
    "331": "Kirchenbauer et al .",
    "332": "[33] introduced the first LLM watermarking technique based on logits modification, termed KGW.",
    "333": "This method partitions the vocabulary into a red list (R) and a green list (G) at each token position, using a hash function that depends on the preceding token.",
    "334": "As depicted in Figure 4, for the 𝑖 𝑡ℎ token generation by 𝑀 𝑤 , a bias 𝛿 is applied to the logits of tokens in G. The adjusted logit value, f l (𝑖 ) 𝑗 , for a token 𝑣 𝑗 at position 𝑖 is calculated as follows:",
    "335": "Equation content: \\[\nv' = h \\cdot \\max \\left(0, \\frac{M(x) - (1+\\alpha)l}{M(x) - (1-\\alpha)l} \\right) + \\beta, \\quad y \\in G, \\quad y \\in \\mathbb{R}\n\\]",
    "336": "This algorithm biases towards green tokens, leading to a higher proportion in watermarked texts.",
    "337": "The detector categorizes each token as red or green using the hash function and calculates the green token ratio with the z-metric, defined as:",
    "338": "Equation content: \\[\nx = \\frac{{-b \\pm \\sqrt{{b^2 - 4ac}}}}{{2a}}\n\\]",
    "339": "where T is the length of the text, 𝛾 is the ratio of the green list.",
    "340": "A text exceeding a certain green token threshold is deemed watermarked.",
    "341": "KGW’s detection method showed low false positive (< 3 × 10 −3 %) and false negative (< 1%) rates in tests.",
    "342": "Yet, real-world application challenges necessitate further optimization and design.",
    "343": "The following outlines four representative scenarios, with improvements and explorations in watermark algorithms, depicted in Figure 5.",
    "344": "4.2.1 Watermarking low-entropy text.",
    "345": "In low-entropy scenarios, such as code or formatted document generation, text is typically deterministic.",
    "346": "Entropy, measuring textual uncertainty, is calculated as follows, where 𝑃 (𝑖 ) 𝑗 denotes the probability of token 𝑣 𝑗 at position 𝑖:",
    "347": "Equation content: H^n = -\\sum_{i=1}^{n} P_i \\log P_i",
    "348": "Lower entropy implies higher text predictability.",
    "349": "Watermarking in such contexts is challenging due to the need of minimal text alterations.",
    "350": "Lee et al .",
    "351": "[39] proposed calculating entropy before modifying logits of green tokens (set G in Equation 9).",
    "352": "If 𝐻 (𝑖 ) falls below a threshold 𝐻 , logits are kept unchanged.",
    "353": "Likewise, Wang et al .",
    "354": "[89] introduced a balance-marking strategy, limiting vocabulary choices to subsets with cumulative log probabilities above a specific level.",
    "355": "This method focuses on watermarking high-entropy tokens while avoiding low-entropy ones.",
    "356": "For example, in cases with a single word candidate, the subset is restricted to this candidate.",
    "357": "These methods [ 39 , 89 ], by factoring in text entropy, minimize impact on text quality.",
    "358": "However, watermarking remains problematic in texts with few high-entropy tokens.",
    "359": "4.2.2 Watermark with multi-bit payload.",
    "360": "The KGW watermark algorithm [ 33 ], as defined in Equation 9, can only verify watermark presence, classifying it as a zero-bit watermark.",
    "361": "Yet, many applications require watermarks to convey additional information like copyright details, timestamps, or identifiers, leading to the need for multi-bit watermarks capable of extracting meaningful data.",
    "362": "To achieve this, one possible solution involves multiple vocabulary divisions into red and green lists, creating N types of splits [(𝐺 1 , 𝑅 1 ), .",
    "363": ".",
    "364": ".",
    "365": ", (𝐺 𝑁 , 𝑅 𝑁 )] .",
    "366": "Each split corresponds to a distinct watermark message, offering a 𝑙𝑜𝑔 2 𝑁 -bit payload.",
    "367": "For example, Wang et al .",
    "368": "[89] allows inputting a 𝑙𝑜𝑔 2 𝑁 -bit watermark message 𝑚 , with the vocabulary division based on the hash value of 𝑚 .",
    "369": "However, this approach is inefficient during detection, requiring iteration over all 𝑁 messages to calculate text correlation with each split.",
    "370": "To address this, Fernandez et al .",
    "371": "[19] proposed the Cyclic Shift method to enhance efficiency, generating different messages by cyclically shifting an initial one, allowing parallel processing.",
    "372": "Nonetheless, these methods face increased computational complexity with larger watermark payloads due to the necessity of iterating each possible message.",
    "373": "To mitigate this, Yoo et al .",
    "374": "[96] suggested assigning different message bits to distinct text positions, facilitating simultaneous bit detection.",
    "375": "The message 𝑚 is modeled as a sequence 𝑚 = Σ 𝑏 with Σ = { 0 , 1 } .",
    "376": "Vocabulary division at each step involves selecting a message position Σ 𝑏 [𝑖] based on the existing random seed, then dividing the vocabulary based on the selected Σ 𝑏 [𝑖] .",
    "377": "This method improves efficiency by enabling parallel bit detection.",
    "378": "Additionally, Yoo et al .",
    "379": "[96] recommended dividing the vocabulary into more segments, so each position Σ 𝑏 [𝑖] in 𝑚 holds more data, increasing the watermark’s payload.",
    "380": "4.2.3 Preventing watermark removal attack.",
    "381": "As discussed in section 2, an effective watermarking algorithm must possess sufficient robustness against watermark removal attacks, ensuring that the watermark text remains detectable after an attack.",
    "382": "These attacks typically involve modifications to the text without altering its semantic content, which will be introduced in section 5.3.",
    "383": "Although the KGW algorithm [ 33 ] demonstrated some robustness to watermark removal attacks in their experiments, there remains room for improvement in its robustness.",
    "384": "For watermarking during logits generation [ 33 , 34 , 45 , 46 , 103 ], the pivotal factor for robustness lies in the methodology used for modifying logits, especially the red-green list division in KGW [ 33 ].",
    "385": "The original KGW utilizes the hash values of preceding tokens for this division.",
    "386": "Kirchenbauer et al .",
    "387": "[34] further elaborated on some specific hash strategies, such as using only the token with the",
    "389": "Fig.",
    "390": "5.",
    "391": "Demonstration of how various methods improve upon KGW [ 33 ] to adapt to four scenarios: Watermarking Low-entropy Text, Watermark with Multi-bit Payload, Preventing Watermark Removal Attack, and Defending against Watermark Forgeries.",
    "392": "smallest token id in previous tokens for hashing to decide the red-green list, which can enhance robustness.",
    "393": "Zhao et al .",
    "394": "[103] proved that a fixed global split of red and green lists offers greater resistance to removal attacks.",
    "395": "Additionally, as watermark removal attacks usually preserve the semantic content of the text, several studies have developed methods to determine the red-green list split based on textual semantics.",
    "396": "For example, Liu et al .",
    "397": "[46] trained a watermark model that can directly convert text semantic embeddings into watermark logits.",
    "398": "Ren et al .",
    "399": "[69] converted semantic embeddings into semantic values through weighted embedding pooling followed by discretizing using NE-Ring, and then divided the vocabulary into red-list and green-list based on these semantic values.",
    "400": "The current methods primarily focus on investigating the robustness of zero-bit watermark algorithms against watermark removal attacks.",
    "401": "Future algorithms could delve into exploring the robustness of multi-bit payload watermark algorithms.",
    "402": "4.2.4 Defending against watermark forgeries.",
    "403": "In the previously discussed watermark algorithms’ resilience to removal attacks, it is assumed that the attacker operates in a black-box scenario, lacking knowledge about the details and generation methods of the watermark.",
    "404": "If an attacker acquires this information, removing or forging the watermark becomes trivial [ 34 ].",
    "405": "Consequently, the ability of watermark algorithms to withstand forgeries is crucial.",
    "406": "The ability to defend against forgeries depends on the watermark algorithm’s capacity to effectively conceal its watermark generation process.",
    "407": "If a watermark algorithm yields imperceptible watermarked text, where imperceptible means indistinguishable distribution between watermarked and unwatermarked texts, it becomes more challenging to forge.",
    "408": "Hu et al .",
    "409": "[28] noted that the KGW algorithm [ 33 ] introduces bias in its logits modification, compromising imperceptibility.",
    "410": "Imperceptibility here implies that the expected watermarked logits equal the original model’s logits:",
    "411": "Equation content: \\[\n\\sum_{k=0}^{n} \\binom{n}{k} x^{n-k} y^k = (x + y)^n\n\\]",
    "412": "where each key 𝑘 represents a unique red-green list split.",
    "413": "The bias in KGW arises from applying a uniform 𝛿 to green list tokens, disproportionately affecting low-probability tokens, leading to bias.",
    "414": "A Survey of Text Watermarking in the Era of Large Language Models 13",
    "415": "To counter this, Hu et al .",
    "416": "[28] introduced two unbiased reweighting methods: 𝛿 -reweight, sampling a one-hot distribution from original logits, and 𝛾 -reweight, which halves the probability distribution range, doubling the remaining tokens’ probabilities.",
    "417": "Similarly, Wu et al .",
    "418": "[90] proposed the 𝛼 -reweight method, discarding tokens with probabilities below 𝛼 and adjusting the rest.",
    "419": "These methods, theoretically unbiased, improve imperceptibility over KGW.",
    "420": "However, unbiased distributions may not ensure imperceptibility, as variances in distributions with identical expectations can differ.",
    "421": "Further research is needed to ascertain true imperceptibility in these algorithms.",
    "422": "The capability of watermark algorithms to defend against watermark forgeries cannot be solely based on the imperceptibility of the watermark.",
    "423": "It is also crucial that these algorithms robustly protect watermark rules from being deciphered.",
    "424": "In this context, we differentiate between two scenarios: private detection and public detection.",
    "425": "Private detection allows watermark verification solely via an API, whereas public detection involves open-access watermark detector details.",
    "426": "In private scenarios, the watermark algorithm’s complexity is critical for preventing forgeries.",
    "427": "For example, Zhao et al .",
    "428": "[103] used a fixed red-green list split for watermark logits, a simplistic approach",
    "429": "vulnerable to statistical analysis [ 71 ].",
    "430": "In contrast, Liu et al .",
    "431": "[46] leveraged semantic information, making rule extraction from watermarked texts significantly harder due to varying complexities.",
    "432": "In the context of public detection scenarios, resisting watermark forgeries becomes significantly more challenging.",
    "433": "This difficulty arises because attackers can access the watermark detectors.",
    "434": "For methods where the watermark generation details are involved in detection (i.e.",
    "435": "the hash key in KGW) [ 33 , 34 , 46 , 103 ], exposing the watermark generator leads to a complete inability to resist watermark forgeries.",
    "436": "To address this issue, Fairoze et al .",
    "437": "[16] have utilized digital signature technology from the field of cryptography.",
    "438": "This approach involves generating watermarks using a private key and verifying them with a public key.",
    "439": "However, the verification via public key relies on features extracted from the text and users can still exploit these features to forge watermarks.",
    "440": "Further advancing this field, Liu et al .",
    "441": "[45] proposed the use of neural networks for watermark detection.",
    "442": "Due to the black-box nature of neural networks, the details of watermark generation are not exposed, which could defend against watermark forgeries in public detection scenarios.",
    "443": "4.3 Watermarking during Token Sampling",
    "444": "The previous section primarily focused on incorporating watermarks during the logits generation phase for Large Language Models.",
    "445": "In this section, we will introduce a technique of watermarking during token sampling, which does not alter the logits but utilize watermark message to guide the sampling of each token.",
    "446": "The main advantage of this method is unbiased text generation, which minimally affects text quality and offers an initial defense against watermark forgery.",
    "447": "The principle of incorporating watermarks during the token sampling phase is derived from the randomness inherent in token sampling.",
    "448": "In this scenario, watermarks can be introduced using a fixed random seed, where a pseudo-random number generator produces a sequence of pseudo-random numbers to guide the sampling of each token.",
    "449": "For watermark detection, it is only necessary to assess the alignment between the text tokens and the pseudo-random numbers, specifically evaluating whether the choice of each token in the text matches with the corresponding value in the random number sequence.",
    "450": "For instance, Christ et al .",
    "451": "[11] use binary representation for each word in the vocabulary, with the pseudo-random numbers represented as a series of values 𝑢 ∈ [ 0 , 1 ] .",
    "452": "This facilitates the sampling process using the pseudo-random numbers.",
    "453": "Specifically, if the predicted probability for a certain position exceeds the corresponding pseudo-random number, then 1 is sampled at that position, otherwise 0.",
    "454": "In the detection of watermarks, it can be determined whether the values of the pseudo-random numbers corresponding to the positions with 1 in the binary tokens are significantly higher than those with 0.",
    "455": "However, this method still faces two challenges: 1) the detection algorithm is not robust enough against watermark removal attacks,",
    "457": "which involves certain text modifications, and 2) due to the fixed nature of pseudo-random numbers, the LLM with watermark will generate the same text for the same prompt each time, thereby losing the inherent randomness in text generation by LLM.",
    "458": "To address these issues, Kuditipudi et al .",
    "459": "[36] proposed the use of a pseudo-random number sequence significantly longer than the text, randomly selecting a starting position from the sequence for each watermark insertion to introduce randomness.",
    "460": "Additionally, during watermark detection, they incorporate a soft notion of edit distance (i.e., Levenshtein distance) into the computation of the alignment between text and the pseudo-random number sequence.",
    "461": "This approach significantly enhances the robustness of the watermarking algorithm against watermark removal attacks.",
    "462": "Apart from intervening in the sampling process of each token one by one, Hou et al .",
    "463": "[27] suggested incorporating watermarks during sentence-level sampling.",
    "464": "The algorithm initially partitions the semantic embedding space into a watermarked region and a non-watermarked region, and then performs sentence-level rejection sampling until the sampled sentence falls within the watermarked region.",
    "465": "Since the partition principles are based on sentence-level semantics, this approach significantly enhances robustness against watermark removal attacks such as paraphrasing.",
    "466": "Current research in token-sampling watermarking is limited, indicating room for advancement.",
    "467": "The effectiveness and robustness of these methods warrant further exploration through experiments and real-world applications.",
    "468": "5 EVALUATION METRICS FOR TEXT WATERMARKING",
    "469": "In Sections 3 and 4, we presented a detailed overview of existing text watermarking techniques.",
    "470": "A thorough evaluation of a text watermarking algorithm is essential.",
    "471": "This section outlines the evaluation metrics from multi perspectives: success rate, text quality, robustness, and unforgeability.",
    "472": "Among these, success rate (Section 5.1) measures the accuracy of detecting watermarked texts.",
    "473": "Text quality (Section 5.2) evaluates the integrity of watermarked text in comparison to its original form.",
    "474": "Robustness (Section 5.3) assesses the detectability of watermarks after removal attacks.",
    "475": "Unforgeability (Section 5.4) considers the difficulty in counterfeiting the watermark.",
    "476": "Additionally, Table 1 outlines the alignment between various text watermarking algorithms discussed in the survey and the evaluation perspectives they contribute to.",
    "477": "5.1 Success Rate",
    "478": "For a text watermarking algorithm, the fundamental requirement is that the watermarked text could be detected with a high probability.",
    "479": "In this section, we consolidate how current watermarking algorithms measure their success rate.",
    "480": "Based on the amount of information carried by the watermarking algorithm, we will introduce it in two scenarios: zero-bit and multi-bit.",
    "481": "5.1.1 Zero-bit Watermark.",
    "482": "In zero-bit watermarking, the algorithm discerns the presence of a watermark in text but cannot extract additional information.",
    "483": "This detection essentially constitutes a binary classification problem, evaluating whether text is watermarked.",
    "484": "Classification metrics like accuracy and F1 score are typically used for evaluation.",
    "485": "In many studies [ 33 , 45 , 46 , 103 ], given the equal distribution of watermarked and non-watermarked texts in test datasets, accuracy and F1 score values are often comparable.",
    "486": "However, F1 score, along with false positive and false negative rates, is more frequently employed [ 33 , 45 , 103 ].",
    "487": "False positives signify misclassifying non-watermarked texts as watermarked, and false negatives involve incorrectly identifying watermarked texts as non-watermarked.",
    "488": "False positives are critical due to misidentifying human-generated texts as watermarked can lead to more adverse consequences.",
    "489": "Nevertheless, the reliance on a threshold for determining F1 or accuracy introduces comparability challenges among algorithms.",
    "490": "Some studies [ 46 , 103 ] report F1 scores at fixed false positive rates of",
    "491": "Table 1.",
    "492": "Relationships between text watermarking algorithms covered in the survey and the evaluation metrics, featuring the individual objectives each text watermarking algorithm aims to achieve.",
    "493": "▲ stands for basic objectives, • stands for primary objectives, and ◦ stands for secondary objectives.",
    "494": "Table content: \n| Watermarked Object | Category | Method | Success Rate | Detection Accuracy | Payload | Text Quality | Robustness | Effort/Invisibility |\n|--------------------|----------|--------|--------------|--------------------|---------|--------------|------------|---------------------|\n| Existing Text      | Format   | Line-Shift Coding [1] | • | • | | | | • |\n|                    |          | Word-Shift Coding [2] | • | • | | | | • |\n|                    |          | Unicode Homoglyph [3] | • | • | | | | • |\n|                    |          | Zero-Width Space [4] | • | • | | | | • |\n|                    |          | Syntactic [5] | • | • | | | | • |\n|                    | Semantic | Natural Language Watermark [6] | • | • | | | | • |\n|                    |          | Adversarial Watermark [7] | • | • | | | | • |\n|                    |          | Robust Watermark [8] | • | • | | | | • |\n|                    |          | Fingerprinting [9] | • | • | | | | • |\n|                    | Syntactic | Abstract Syntax Tree Watermark [10] | • | • | | | | • |\n|                    |          | Natural Language Watermark [11] | • | • | | | | • |\n|                    |          | Adversarial Watermark [12] | • | • | | | | • |\n|                    |          | Robust Watermark [13] | • | • | | | | • |\n|                    |          | Fingerprinting [14] | • | • | | | | • |\n| Training Data      | Format   | Collusion-Resistant Fingerprint [15] | • | • | • | | | • |\n|                    |          | Error-Correcting Code [16] | • | • | • | | | • |\n|                    |          | Cryptographic Hash [17] | • | • | • | | | • |\n|                    |          | Digital Signature [18] | • | • | • | | | • |\n|                    |          | Chameleon Hash [19] | • | • | • | | | • |\n|                    | Semantic | Backdoor Watermark [20] | • | • | • | | | • |\n|                    |          | Adversarial Watermark [21] | • | • | • | | | • |\n|                    |          | Robust Watermark [22] | • | • | • | | | • |\n|                    |          | Fingerprinting [23] | • | • | • | | | • |\n|                    | Syntactic | Abstract Syntax Tree Watermark [24] | • | • | • | | | • |\n|                    |          | Natural Language Watermark [25] | • | • | • | | | • |\n|                    |          | Adversarial Watermark [26] | • | • | • | | | • |\n|                    |          | Robust Watermark [27] | • | • | • | | | • |\n|                    |          | Fingerprinting [28] | • | • | • | | | • |\n| Models (ML/DL)     | Logic/Inference | Backdoor Watermark [29] | • | • | • | | | • |\n|                    |          | Adversarial Watermark [30] | • | • | • | | | • |\n|                    |          | Robust Watermark [31] | • | • | • | | | • |\n|                    |          | Fingerprinting [32] | • | • | • | | | • |\n|                    |          | Trigger-Set Watermark [33] | • | • | • | | | • |\n|                    |          | Steganographic Watermark [34] | • | • | • | | | • |\n|                    |          | Digital Signature Watermark [35] | • | • | • | | | • |\n|                    |          | Homomorphic Encryption Watermark [36] | • | • | • | | | • |\n|                    |          | Zero-Knowledge Proof Watermark [37] | • | • | • | | | • |\n|                    |          | Quantum Watermark [38] | • | • | • | | | • |\n| Token Tracing      | Format   | Transaction Watermark [39] | • | • | • | | | • |\n|                    |          | Subliminal Channel [40] | • | • | • | | | • |\n|                    | Semantic | Semantic Watermark [41] | • | • | • | | | • |\n\n",
    "495": "1% and 10%, while others [ 46 ] present optimal F1 scores across all thresholds for a fair comparison.",
    "496": "Additionally, hypothesis testing methods are used to calculate the p-value as a key success rate metric.",
    "497": "Different algorithms employ varying hypotheses for p-value computation.",
    "498": "For instance, Kirchenbauer et al .",
    "499": "[33] assess if the calculated z-score surpasses a threshold, whereas Kuditipudi et al .",
    "500": "[36] hypothesizes that the key generating the watermark text detects the watermark with higher probability than random keys.",
    "501": "This approach, not requiring a predefined threshold, needs multiple detection runs, potentially slowing detection speed.",
    "502": "5.1.2 Multi-bit Watermark.",
    "503": "In multi-bit watermarking methods [ 1 , 70 , 89 , 93 , 95 , 96 ], the focus extends beyond merely detecting watermarks to extracting detailed watermark message.",
    "504": "For example, a watermarked text may encode specific data, such as \"This text is generated by GPT-4 on June 6 by the Administrator\" [ 89 ].",
    "505": "Evaluating the efficacy of multi-bit watermarks involves not only assessing accuracy in information retrieval but also considering the watermark’s payload, the number of bits in the watermark message.",
    "507": "Consider watermark message 𝑤 encoded in 𝑛 bits, represented as 𝑤 = 𝑏 1 𝑏 2 .",
    "508": ".",
    "509": ".",
    "510": "𝑏 𝑛 , where each 𝑏 𝑖 is binary.",
    "511": "The prevalent metrics for success rate evaluation are the bit error rate (BER) [ 95 ], indicating the likelihood of erroneous bit predictions, and bit accuracy [ 1 , 96 ], the rate of correct bit predictions.",
    "512": "These metrics are complementary.",
    "513": "BER is usually calculated for a fixed bit number; as the number of bits increases, BER tends to rise, potentially reaching 50% (random).",
    "514": "Therefore, the bit capacity, or payload, of a watermark algorithm is a critical evaluation metric, known as Bits Per Watermark [ 93 , 95 ] or code rate [ 70 , 89 ].",
    "515": "Payload is calculated by dividing the total bit count of the watermark information by the number of tokens.",
    "516": "The payload of a watermark algorithm has an upper limit, with enhancements often compromising text quality (section 5.2) or robustness (section 5.3).",
    "517": "Furthermore, the payload is context-dependent: higher entropy scenarios yield greater payloads, whereas lower entropy scenarios result in smaller payloads.",
    "518": "5.2 Text Quality",
    "519": "In section 2, we demonstrated that an essential characteristic of text watermarking technology is its low-impact on text quality.",
    "520": "This means that the quality scores of texts, with or without watermarks, should be similar under the text quality evaluation function R as described in Equation 2.",
    "521": "This section primarily introduces potential forms of the text quality evaluation function R .",
    "522": "Current text watermarking research predominantly assesses text quality using methods like perplexity values [ 28 , 33 , 45 , 46 , 89 , 90 , 92 , 103 ], semantic score [ 1 , 57 , 92 , 93 , 95 , 98 ], performance evaluations for specific tasks [28, 39, 74, 82, 90, 92, 98], or text diversity [34].",
    "523": "5.2.1 Perplexity.",
    "524": "Perplexity (PPL) is defined as the exponentiated average negative log-likelihood of a sequence.",
    "525": "Specifically, given a text 𝑊 = 𝑤 1 , ...,𝑤 𝑁 , the PPL can be computed using an LLM M :",
    "526": "Equation content: \\[\nR_{\\text{eff}}(N) = \\exp\\left(-\\frac{1}{N} \\sum_{i=1}^{N} \\log M(v_i, ..., v_{i-N+1})\\right)\n\\]",
    "527": ".",
    "528": ".",
    "529": ", 𝑤 𝑖−1 ) !",
    "530": ".",
    "531": "(13)",
    "532": "Perplexity is an effective metric for assessing the consistency and fluency of text.",
    "533": "Generally, a lower PPL indicates higher text quality.",
    "534": "Typically, larger LLMs are employed to compute PPL for more accurate assessments, examples of which include GPT2[ 92 ], GPT-3 [ 103 ], OPT2.7B [ 33 , 89 ], LLaMA-13B [45, 46], among others.",
    "535": "Watermarked texts typically exhibit higher PPL, reflecting a quality reduction.",
    "536": "The higher the watermark strength, the more evident the decline in text quality.",
    "537": "For example, in the KGW algorithm [ 33 ], an increased 𝛿 value noticeably affects text quality.",
    "538": "Takezawa et al .",
    "539": "[76] recommend using lower watermark strength for longer texts to mitigate quality degradation while preserving watermark efficacy.",
    "540": "5.2.2 Semantic Score.",
    "541": "Although text perplexity facilitates the evaluation of textual consistency and fluency, it could not assess the accuracy of watermarked texts, specifically in terms of semantic consistency between watermarked and non-watermarked text.",
    "542": "Consequently, some studies employ semantic scores, which measure the semantic similarity between watermarked and non-watermarked texts, to evaluate the impact of watermarking algorithms on text quality.",
    "543": "The most commonly utilized method for assessing semantic scores involves the computation of semantic embeddings by Large Language Models (LLMs), followed by the comparison of these embeddings using cosine similarity.",
    "544": "This process can be represented by the following formula: R se (𝑊 𝑢 ,𝑊 𝑤 ) = M(𝑊 𝑢 ) · M (𝑊 𝑤) ∥M (𝑊 𝑢 )∥ × ∥M (𝑊 𝑤 )∥ , (14)",
    "545": "where 𝑊 𝑢 and 𝑊 𝑤 respectively represent the text without watermark and the text with watermark.",
    "546": "The model M is typically an LLM that has been optimized specifically for text similarity.",
    "547": "For",
    "548": "A Survey of Text Watermarking in the Era of Large Language Models 17",
    "549": "instance, Munyer and Zhong [57] have used the Universal Sentence Encoder [ 8 ], whereas Abdelnabi and Fritz [1] , Yang et al .",
    "550": "[93] , Yoo et al .",
    "551": "[95] have employed Sentence-BERT [ 68 ], and Yang et al .",
    "552": "[92] have utilized all-MiniLM-L6-v2 1 .",
    "553": "Most watermarking algorithms could achieve a semantic similarity between the watermarked text and the original text (without watermark) above 0.9.",
    "554": "Additionally, the achievable semantic scores in these works are still correlated with the watermark strength (degree of textual modification), indicating that lower watermark strength correlates with higher semantic scores.",
    "555": "While the text embedding based evaluation method could effectively captures the overall semantic similarity, it falls short in delving into the semantic nuances at a detailed level.",
    "556": "Consequently, Yoo et al .",
    "557": "[95] have further employed RoBERTa-Large-NLI [ 68 ] for a more precise understanding and inference of complex semantic relations between texts (Entailment Score, ES).",
    "558": "RoBERTa-Large-NLI is pre-trained on Natural Language Inference (NLI) tasks and focuses not only on the overall similarity between two texts but also discerns subtle semantic differences.",
    "559": "In actual experiments, the ES values generally tend to be lower than text embedding similarities.",
    "560": "Although semantic scores assessment based on Natural Language Inference (NLI) offers an in-depth semantic analysis, it might still struggle to accurately capture variations at the level of individual words or phrases.",
    "561": "To address this, Zhang et al .",
    "562": "[98] employed BERT-Score [ 100 ] for a word-level detailed comparison of texts.",
    "563": "BERT-Score is more adept at evaluating whether the watermark has altered specific vocabulary or expressions in the original text.",
    "564": "5.2.3 Task-speciﬁed Evaluation.",
    "565": "Although the assessment method based on semantic scores could effectively evaluate whether adding watermarks alters the text semantics, its impact on real-world applications remains unclear.",
    "566": "Consequently, many studies are now focusing on exploring the effects of watermarking algorithms on specific downstream tasks to assess their impact on text quality.",
    "567": "These tasks include machine translation [ 28 , 82 , 90 , 105 ], sentiment classification [ 92 ], knowledge understanding [ 85 ], code generation [ 39 , 74 , 85 ], text summarization [ 28 , 85 , 90 ], story generation [105], question answering [85], and instruction following [85], as shown in Figure 6.",
    "568": "Machine Translation.",
    "569": "Commonly, the assessment of watermarking in Large Language Models (Section 4) includes machine translation as a downstream task to evaluate text quality.",
    "570": "This evaluation involves comparing the translation outputs from watermarked and original nonwatermarked LLMs, utilizing the BLEU score, a standard metric in machine translation.",
    "571": "For translation LLMs, [ 28 , 90 ] utilized Multilingual BART [ 47 ], and Takezawa et al .",
    "572": "[76] employed the NLLB-200 model [ 13 ].",
    "573": "The WMT14 dataset, particularly translations between French, German, and English, is predominantly used for testing.",
    "574": "Watermarking LLMs typically leads to a marginal reduction in BLEU scores [ 33 , 45 , 76 ].",
    "575": "Nonetheless, unbiased watermark methods [ 28 , 90 ] show negligible impact on BLEU scores, indicating their efficacy in maintaining translation quality.",
    "576": "Sentiment Classification.",
    "577": "Using sentiment classification as a downstream task can validate whether text watermarking algorithms can affect the sentiment distribution, i.e., whether the text can maintain its original sentiment (e.g., positive or negative) after the insertion of a watermark.",
    "578": "Yang et al .",
    "579": "[92] analyzed the sentiment distribution of texts with and without watermarks using the Twitter-XLM-RoBERTa-Base-Sentiment 2 model.",
    "580": "Different sentiments generally have clear differences, making it easy for watermark algorithms to maintain sentiment distribution.",
    "581": "Knowledge Understanding.",
    "582": "To explore the performance of the watermark for LLMs algorithm in tasks with shorter output lengths, Tu et al .",
    "583": "[85] proposed testing on Knowledge Understanding tasks.",
    "584": "Specifically, this involves two scenarios: Knowledge Probing, using the KoLA dataset [ 97 ] for assessing factual recall in LLMs, and Concept Probing, employing the Copen dataset [ 61 ] for",
    "588": "Fig.",
    "589": "6.",
    "590": "Speciﬁc downstream tasks used to evaluate the impact of text watermarking algorithms on text quality.",
    "591": "evaluating conceptual understanding.",
    "592": "The typical evaluation metric for these tasks is the F1 score.",
    "593": "In practical tests, applying watermarks to Knowledge Understanding tasks significantly decreases the F1 scores across all algorithms, indicating the challenging nature of this scenario.",
    "594": "Code Generation.",
    "595": "Text watermarking for code generation is an important application, which could test the impact of watermarking on code functionality.",
    "596": "Code evaluation could use unit test metrics like pass@k [ 37 ], or matching metrics such as BLEU and Exact match.",
    "597": "Sun et al .",
    "598": "[74] implemented watermarking in a code dataset by embedding features in a dataset subset.",
    "599": "They reported minimal differences in BLEU and Exact match scores between models trained on datasets with and without watermarks.",
    "600": "Nonetheless, watermarking individual code pieces is more complex than watermarking an entire dataset.",
    "601": "Lee et al .",
    "602": "[39] incorporated watermarks into large models for code generation, resulting in approximately a 10% decrease in pass@100 and pass@80 metrics.",
    "603": "Considering the sensitivity of code to minor alterations, preserving the code utility while achieving watermarking poses a significant challenge[85].",
    "604": "Text Summarization.",
    "605": "Only the watermark algorithms for LLM consider text summarization as a downstream evaluation task.",
    "606": "Specifically, it compares the effectiveness of text summarization between a watermarked Large Language Model (LLM) and an non-watermarked LLM.",
    "607": "The evaluation metric for text summarization is ROUGE [ 44 ].",
    "608": "Furthermore, the most frequently used large model for summarization is BART-Large [ 47 ], with the CNN-DM dataset [ 25 ] being prevalent.",
    "609": "In practical results, current watermark algorithms have a relatively minimal impact on text summarization tasks.",
    "610": "The algorithm by Kirchenbauer et al .",
    "611": "[33] only causes a slight decrease in ROUGE scores, whereas the unbiased watermark [ 28 , 90 ]algorithms hardly affect the ROUGE scores.",
    "612": "Story Generation.",
    "613": "Similar to text summarization tasks, story generation also presents a suitable scenario for evaluating watermark algorithms for Large Language Models.",
    "614": "Tests in the story generation context typically involve inputting the first half of a story and having the model (LLM) predict its ending.",
    "615": "The ROCstories dataset [ 56 ] is commonly used, with ROUGE as the evaluation metric.",
    "616": "According to the experiments by Zhao et al .",
    "617": "[105] , current watermark algorithms still cause a 1%-2% decrease in performance on ROUGE scores.",
    "618": "Question Answering.",
    "619": "Question answering (QA) is an important downstream application of Large Language Models.",
    "620": "Tu et al .",
    "621": "[85] conducted tests on three different QA tasks, specifically: the ELI5 dataset [ 17 ] for long-form QA tasks, the FinQA dataset [ 49 ] for Finance QA tasks, and the",
    "622": "HotpotQA dataset [ 94 ] for multi-hop reasoning QA tasks.",
    "623": "For the long-form QA and Finance QA tasks, the Rouge-L metric was used for evaluation, while the F1 score was utilized for the multi-hop reasoning QA task.",
    "624": "Experimental results revealed that, after the introduction of watermarks, all current watermark algorithms experienced a performance decline of about 50% in QA tasks, indicating the challenging nature of watermark algorithms in the context of QA.",
    "625": "Instruction Following.",
    "626": "The capacity of Large Language Models (LLMs) to adhere to user instructions in generating responses for open-ended tasks is increasingly crucial.",
    "627": "Tu et al .",
    "628": "[85] examined the influence of the prevalent LLM watermarking algorithm on Instruction Following using the AlpacaFarm dataset [ 15 ].",
    "629": "The assessment utilized GPT4-Judge [ 106 ], wherein GPT-4 evaluates the appropriateness of outputs from the watermarked LLM and Davinci-003 in response to specific instructions.",
    "630": "According to this criterion, both the Llama2-7B-chat and Internlm-7B8k models exhibited over a 90% decrease in performance when watermarked, highlighting the significant challenge watermark algorithms face in instruction following tasks.",
    "631": "5.2.4 Text Diversity.",
    "632": "Although previous text quality assessment methods provide comprehensive evaluations of consistency, fluency, and accuracy, they still overlook an essential aspect: assessing the diversity of watermarked texts.",
    "633": "Diversity evaluation is often targeted at the watermark algorithms for Large Language Models.",
    "634": "These algorithms embed watermarks into LLMs, necessitating an assessment of evaluating whether the diversity of the text generated by LLMs has changed.",
    "635": "Text diversity is defined by calculating the proportion of unique n-grams in a text sequence, with the formula being the negative logarithm multiplied by the product of (1 - proportion) of unique n-grams from 1 to N. A higher diversity score indicates fewer repeated n-grams and richer text.",
    "636": "The specific formula is defined as follows:",
    "637": "Equation content: R_n = -\\log_2 \\left( \\prod_{i=1}^{n} (1 - w_i) \\right)",
    "638": ", (15)",
    "639": "where 𝑢 𝑛 represents the ratio of different n-grams to the total number of n-grams in a given text",
    "640": "sequence.",
    "641": "If a sequence contains many non-repeating n-grams, 𝑢 𝑛 will be close to 1, indicating high diversity.",
    "642": "Conversely, if many n-grams are repeated, 𝑢 𝑛 will be small, indicating low diversity.",
    "643": "In Kirchenbauer et al .",
    "644": "[34] , it was noted that for the KGW algorithm [ 33 ], context width—the number of tokens used to hash and create the green list—significantly influences text diversity.",
    "645": "A larger context width enhances the diversity of the text, but this comes at the cost of reduced robustness of the watermark to text modifications.",
    "646": "Furthermore, with a larger context width, as the watermark strength increases, so does the diversity.",
    "647": "Conversely, with a smaller context width, an increase in watermark strength leads to a decrease in diversity.",
    "648": "Presently, limited research on LLM watermarking addresses its impact on text diversity.",
    "649": "Future studies should focus more on this aspect of watermarking evaluation.",
    "650": "5.3 Robustness",
    "651": "Another key metric for evaluation is the robustness against watermark removal attacks.",
    "652": "These attacks entail modifying watermarked text to erase the embedded watermark.",
    "653": "A watermarking algorithm is considered highly robust if the watermark remains detectable post-attack.",
    "654": "Presently, watermark removal attack models assume black-box access to the watermarking algorithm.",
    "655": "Here, the watermark generation method is undisclosed, and there is no access to the watermark detector during the attack.",
    "656": "This assumption is due to the ease of developing effective removal strategies under white-box access, which could potentially eliminate most watermarks, as highlighted by Kirchenbauer et al .",
    "657": "[34] in their anti-watermark framework.",
    "658": "In scenarios with black-box access, several watermark removal attacks have been developed with the aim of erasing",
    "660": "the watermark through textual modifications.",
    "661": "These methods are categorized based on modification granularity, including character-level, word-level, and document-level attacks.",
    "662": "The subsequent sections will explore these attack implementations and evaluate the resilience of text watermarking techniques against them.",
    "663": "5.3.1 Character-level Attack.",
    "664": "Character modification in text, without altering words, is a basic strategy for watermark removal attacks.",
    "665": "One method involves introducing spelling errors by perturbing characters, but this can be easily identified and may degrade text quality.",
    "666": "An alternative strategy involves replacing characters with visually similar Unicode IDs, leveraging the fact that many Unicode IDs correspond to identical or visually indistinguishable characters.",
    "667": "This technique is also known as a Homoglyph attack [ 20 ].",
    "668": "Although such methods are difficult to detect by human observation, they can still be mitigated by various canonicalization techniques [ 33 ].",
    "669": "Therefore, normalization preprocessing before passing through watermark detectors is crucial.",
    "670": "The effectiveness of character-level attacks varies with different types of text watermark algorithms.",
    "671": "For format-based watermark algorithms, which embed watermarks through Unicode ID substitutions (e.g., EasyMark [ 72 ] replaces Unicode 0x0020 with 0x2004), Homoglyph attacks may be a direct and effective method for watermark removal.",
    "672": "For other watermark algorithms, the impact is on tokenizers; after character modification, the tokenizer may divide the word into a different token list.",
    "673": "For instance, changing the \"a\" in \"apple\" to a Cyrillic character \"а\" alters the tokenization from [\"apple\"] to [\"а\", \"pple\"].",
    "674": "This change in tokenization result poses challenges to the detection effectiveness of many watermark algorithms.",
    "675": "A character-level attack offers simplicity and effectiveness as its advantage.",
    "676": "However, its drawback is that it is easily detectable or can be eliminated by some simply designed algorithms.",
    "677": "Therefore, it is not a reliable watermark removal attack in all scenarios.",
    "678": "5.3.2 Word-level Attack.",
    "679": "Compared to character-level attacks that only alter the surface of text, word-level attacks modify the content of the text by adding, deleting, or altering words to remove watermarks [ 1 , 33 , 36 , 92 , 95 , 103 ].",
    "680": "These methods have a broader scope than character-level attacks, as they are less likely to be mitigated by rule-based methods and align more closely with realistic attack scenarios.",
    "681": "Currently, there are two main types of word-level attacks.",
    "682": "Word-level Attack to Existing Text.",
    "683": "Word-level attack to existing text refers to the insertion, deletion, or replacement of words in a pre-generated watermarked text.",
    "684": "During the attack process, an attack rate is typically established, which is a certain likelihood of inserting, deleting, or replacing each token.",
    "685": "For example, when the deletion attack rate is set as 0.5, nearly half of the text will be removed [ 92 ].",
    "686": "In terms of word substitution, synonym replacement is typically employed to ensure minimal impact on the semantics.",
    "687": "Specifically, the replacement word will be the one from the word",
    "688": "database giving the smallest sentence score difference, for example, BERT score difference.",
    "689": "For the two types of watermark methods: watermarking for existing text and watermarking for Large Language Models (LLMs), the effects produced by word-level attacks vary.",
    "690": "Regarding watermarking for existing text [ 1 , 92 , 95 ], word deletion has the most effect in removing text watermark among the above three attacks.",
    "691": "While low deletion rate under 0.1 produces acceptable performance drop, the figure exceeding 0.3 or more could result in the watermark severely damaged or even erased [ 92 ].",
    "692": "Word deletion stands out for two key reasons.",
    "693": "The first is that it can directly remove words that may contain embedded watermark information, whereas word insertion not directly delete existing watermark information and not all words have suitable synonyms during synonyms substitution.",
    "694": "Secondly, word deletion significantly alters the semantics, surpassing both word insertion and synonym replacement, as these methods do not remove the original semantics.",
    "695": "Regarding watermarking during logits generaion methods (section 4.2), the basic attack effect is that the watermarked tokens (e.g.",
    "696": "green tokens in Kirchenbauer et al .",
    "697": "[33] ) in the text will be",
    "698": "disturbed.",
    "699": "Watermark methods [ 33 , 89 , 103 ] that rely on preceding tokens to determine the current token’s watermark status are more vulnerable to word-level attacks.",
    "700": "This is because word-level attacks not only change the current token but also modify its preceding tokens, thereby altering the detection status of the current token.",
    "701": "Usually, to achieve significant performance drop, sustainable word-level attacks on the text is required.",
    "702": "That is, the attack rate should be large enough.",
    "703": "For example, to decrease detection F1 score below 80%, a minimal attack rate of 30% is required, which requires performing deletion or replacement every 3 words [ 92 ].",
    "704": "High attack rates drastically change semantics and degrade text quality [ 1 , 33 , 92 ].",
    "705": "Word deletion with high attack rate may even leave each sentence incomplete.",
    "706": "Often, the text under such heavy word-level attacks is not ideal in real world, where the watermark-removed text should still be usable and understandable.",
    "707": "In conclusion, although word-level attacks on existing watermarked texts perform well in some scenarios [ 95 ], they may not best simulate reality as exhibited by obvious quality issues due to lack of text understanding ability.",
    "708": "Word-level Attack during Text Generation.",
    "709": "Due to the inevitable impact on text quality during word-level attack to existing texts, particularly when these modifications are extensive, recent work has begun to explore word-level attacks during text generation.",
    "710": "These methods target watermarking algorithms for LLMs.",
    "711": "A notable example is the emoji attack [ 21 ], which prompts the LLM to generate emojis between each token and then remove the emojis after generation.",
    "712": "Once the emojis are removed, the detector would fail to recognize the watermarked tokens, as emojis are intended to convey the watermarking information of a subsequent token [ 33 , 74 ].",
    "713": "For example, a user could request the LLM to generate \" ⌣ \" between every word, resulting in a sentence looking like \"There ⌣ are ⌣ some ⌣ apples ⌣ here\".",
    "714": "Assuming the word \"apples\" is watermarked, and the proper detection computation of this word needs its prefix, the emoji \" ⌣ \".",
    "715": "However, the user will remove the emojis before using this machine-generated text, making the prefix of \"apples\" become the word \"some\".",
    "716": "Detection using a different prefix will be inaccurate, and such miscalculation is applied in every word of the watermarked text.",
    "717": "The advantage of such attacks is their near-complete erasure of certain watermarking methods [ 11 , 33 ].",
    "718": "However, they have two main disadvantages.",
    "719": "First, their effectiveness hinges on the LLM’s ability to adhere to directives.",
    "720": "Advanced LLMs like ChatGPT and Claude can successfully perform emoji attacks, ensuring coherent text generation, but less advanced models might struggle, resulting in illogical outputs.",
    "721": "Second, the success of these attacks is intricately linked to the watermark generation mechanism.",
    "722": "For instance, the emoji attack presupposes that a token’s watermark status depends on the preceding token’s hash value.",
    "723": "However, alternative approaches, like those by [ 46 ], which utilize generated text embeddings instead of relying on preceding token hashes, remain largely unaffected by emoji attacks.",
    "724": "5.3.3 Document-level Attack.",
    "725": "While word-level attacks alter or remove text watermarks through individual word modifications, their impact is comparatively confined.",
    "726": "Conversely, document-level attacks adopt a holistic and in-depth strategy.",
    "727": "They extend beyond mere word alterations in a document, encompassing extensive modifications to both content and structure.",
    "728": "Typical documentlevel attacks involve semantic-preserving rewrites, often referred to as rewrite attacks, and the integration of watermark text into pre-existing human text, known as copy-paste attacks.",
    "729": "Rewrite Attack.",
    "730": "The rewrite attack offers comprehensive and in-depth modifications to text, yet its implementation is more challenging compared to the word-level approach.",
    "731": "Early methods of rewrite attacks often employed a re-translation strategy [ 92 ], which involves translating the text into another language and then back into the original language.",
    "732": "This method exploits subtle changes",
    "734": "that may occur during the translation process to achieve text rewriting.",
    "735": "While the re-translation method was widely used initially, its limitation lies in the potential introduction of additional errors during double translation, which can result in significant semantic deviations from the original text.",
    "736": "Consequently, specialized language models for text rewriting, such as Dipper [ 35 ], have been developed.",
    "737": "These models provide higher quality text and allow for configurable degrees of modification during the rewriting process.",
    "738": "With the recent popularity of ChatGPT, many studies and practices have started using it for text rewriting, most commonly the gpt-3.5-Turbo version.",
    "739": "Its advantage lies in requiring only a specific prompt for the text rewrite attack, such as \"please rewrite the following text:\".",
    "740": "For more realistic scenario validation, manual rewriting is also an option.",
    "741": "Manual rewriting offers more precise semantic preservation and more natural language expression but has the main disadvantage of being costlier, especially when handling large amount of text.",
    "742": "The effectiveness of rewrite attacks varies for different types of watermarking methods.",
    "743": "Formatbased approaches [ 6 , 64 , 70 , 72 ] are particularly vulnerable, as homoglyphs are often replaced with standard language tokens by LLMs or humans in the output.",
    "744": "For other algorithms that embed watermarks based on text content, the impact of rewrite attacks depends on three factors: token sequence dependence, watermark strength, and text length.",
    "745": "Firstly, watermark detection methods that do not rely on token order, like Zhao et al .",
    "746": "[103] ’s approach, demonstrate greater robustness since rewrite attacks can disrupt token sequences but are less effective at replacing all tokens.",
    "747": "In contrast, algorithms like Kuditipudi et al .",
    "748": "[36] ’s, where robustness hinges on token sequences, exhibit varying susceptibility levels to such attacks.",
    "749": "Secondly, the watermark strength, or the extent of text modification, is crucial.",
    "750": "Watermarking that necessitates substantial alterations from the original text tends to enhance resistance against rewrite attacks.",
    "751": "Lastly, the length of the watermarked text is a significant factor.",
    "752": "Empirical evidence from Kirchenbauer et al .",
    "753": "[33] indicates that texts with over 600 tokens generally maintain robustness against rewrite attacks.",
    "754": "It is also observed that manually erasing watermarks from texts of 400 to 800 tokens through rewriting poses a considerable challenge for humans.",
    "755": "There are some designs to further increase algorithm robustness against rewrite attack as well.",
    "756": "1) Decrease the token-level dependency.",
    "757": "The dependency of watermark algorithms on specific contexts can compromise their effectiveness when the original text is rewritten, as the original context may not remain intact.",
    "758": "Take the watermarking during logits generation methods as example, if the partitioning of a token’s red-green list relies on 𝑚 adjacent words, the detection rate significantly decreases after an attack when 𝑚 is not very small.",
    "759": "Hence, watermark algorithms should reduce reliance on neighboring words.",
    "760": "This can be achieved by decreasing the window size 𝑚 [ 33 ], or by using hashing schemes that only involve a subset of words within the window [ 34 ].",
    "761": "Some studies have even reduced the window size 𝑚 to zero [ 103 ].",
    "762": "2) Replace with semantic-level dependency.",
    "763": "A better approach is for the watermark algorithm to refer to the general semantics around the watermarked token [ 46 , 95 ] instead of the exactly identical tokens or words.",
    "764": "That is to say, for a group of altered but semantically similar contexts, the watermark generator and detector would produce the same result.",
    "765": "Unless the semantics is drastically altered, the watermark detection could maintain a higher accuracy against rewrite attacks.",
    "766": "One can even train the watermark generator to produce closer results on semantically close texts ;",
    "767": "It is worth noting that although human writers are stronger paraphrasers than machines, there are significant differences in individuals’ ability to rewrite text.",
    "768": "Moreover, when the text is lengthy, humans are often powerless.",
    "769": "Copy-paste Attack.",
    "770": "Copy-paste attack is to surround the target text (watermarked text) with distraction text (non-watermarked text).",
    "771": "This attack aims to test whether a low ratio of watermarked text can cause a drop in algorithm effectiveness.",
    "772": "The copy-paste attack primarily diminishes the",
    "773": "A Survey of Text Watermarking in the Era of Large Language Models 23",
    "774": "detectability of watermarks in text by diluting their concentration.",
    "775": "The efficacy of this attack is significantly influenced by the proportion of watermarked text.",
    "776": "For instance, when the watermarked text constitutes a mere 10% of the total, the attack’s impact tends to surpass that of most rewriting attacks [ 34 ].",
    "777": "However, as the share of watermarked text increases to, say, 25%, its effectiveness in undermining certain watermarking algorithms [ 33 ] becomes comparable to that of some rewriting attacks.",
    "778": "Similar to rewriting attacks, lengthening the text can enhance the reliability of watermark detection, particularly in the context of copy-paste attacks.",
    "779": "However, copy-paste attacks may be identified by certain specific watermark detection methods.",
    "780": "For example, Kirchenbauer et al .",
    "781": "[34] mentioned a windowed test to calculate the level of watermarking in a region of the text instead of the whole text.",
    "782": "It is specifically designed to effectively detect watermarked text that is inserted into existing text, making it applicable for addressing copy-paste attacks.",
    "783": "5.4 Unforgeability",
    "784": "In section 5.3, we discussed watermark removal attacks that assume the attacker is unaware of the watermark’s generation method (black-box setting).",
    "785": "However, in real-world scenarios, attackers may attempt to obtain or decipher the watermark’s generation method.",
    "786": "Once an attacker acquires this method, they can easily fabricate or remove existing watermarks, as mentioned by [ 34 ] in their anti-watermark methods.",
    "787": "Therefore, a watermark algorithm must possess substantial unforgeability, meaning it should be exceedingly difficult for attackers to discern the method of watermark generation.",
    "788": "This might imply that the algorithm itself needs to be highly complex and secure, or involve mathematical problems that are challenging to crack.",
    "789": "The discussion on watermark unforgeability could be differentiated into two distinct scenarios: private detection and public detection.",
    "790": "In the private detection scenario, the watermark detection method is kept confidential, accessible only to specific users or institutions, or indirectly provided to users via an API [ 33 ].",
    "791": "This setup’s advantage lies in increasing the difficulty for attackers to obtain and analyze the detection algorithm, as they lack direct access to the detection mechanism.",
    "792": "Conversely, in the public detection scenario, the watermark detection algorithm is publicly available, allowing anyone to access and utilize these algorithms.",
    "793": "In this scenario, attackers can more easily study the detection algorithms and seek methods to breach the watermark.",
    "794": "Therefore, the requirements for unforgeability in public detection scenarios might be higher.",
    "795": "5.4.1 Unforgeability in Privately Detectable Scenario.",
    "796": "In private detection scenarios, the imperceptibility of text watermarking algorithms is crucial for ensuring unforgeability due to the limited detection capabilities of users.",
    "797": "Imperceptibility refers to the watermark’s impact on the original content being nearly undetectable in its statistical distribution, which is essential for ensuring the watermark’s non-forgery.",
    "798": "If users are unaware of the watermark in the text, they cannot forge it.",
    "799": "Therefore, some studies have focused on testing imperceptibility.",
    "800": "For instance, Abdelnabi and Fritz [1] collected texts with and without watermarks and trained classifiers to try to distinguish between these two categories.",
    "801": "The purpose of this test was to see if the classifiers could effectively identify which texts contained watermarks.",
    "802": "The performance of the classifiers serves as a measure of the watermarking algorithm’s imperceptibility.",
    "803": "The classifiers’ efficacy in detecting watermarks serves as a proxy for the algorithm’s imperceptibility, with ideal outcomes being their inability to distinguish between the two categories.",
    "804": "When text watermarking algorithms fail to achieve complete imperceptibility, or when attackers suspect or infer the presence of watermarks in the text, they may resort to statistical methods to extract the details of the watermark generator.",
    "805": "These statistical attack methods primarily rely on the analysis of statistical traces or patterns that the watermarking algorithm might leave in",
    "807": "the text, which generally requires sufficient prior knowledge about the method of watermark insertion.",
    "808": "For instance, Sadasivan et al .",
    "809": "[71] proposed a spoofing attack algorithm that can target numerous watermarking during logits generation methods [ 33 , 103 ].",
    "810": "Specifically, this attack involves calculating the frequency of tokens in a text under a fixed prefix.",
    "811": "In watermarked texts, the frequency of these tokens may differ from normal texts.",
    "812": "For instance, by analyzing the frequency of tokens following ‘the’, tokens that appear more frequently might be identified as part of the watermark (green list [ 33 ]).",
    "813": "The effectiveness of this attack is closely related to the complexity of the watermarking method.",
    "814": "If a watermarking algorithm operates in a complex manner on a text, statistical-based attacks become less effective.",
    "815": "This suggests that increasing the complexity of watermarking algorithms is key to preventing such attacks.",
    "816": "For example, Liu et al .",
    "817": "[46] proposed using text semantic information associated with the watermarking rule, which effectively resists spoofing attacks.",
    "818": "In the context of private watermark detection scenarios, several strategies are imperative.",
    "819": "First, detection frequency must be limited.",
    "820": "For watermark detection services via APIs, frequencyrestricting mechanisms can reduce attackers’ capacity to analyze the algorithm through repeated attempts, thus mitigating spoofing attacks [ 71 ].",
    "821": "Second, enhancing network security is critical to safeguard watermark rules against theft.",
    "822": "This includes encrypted communications, regular security updates, and intrusion detection systems.",
    "823": "Third, defending against social engineering attacks is essential.",
    "824": "These attacks exploit trust or coerce information disclosure.",
    "825": "Implementing stringent internal security protocols and verification processes is crucial to prevent unauthorized release of sensitive data, such as watermark keys.",
    "826": "5.4.2 Unforgeability in Publicly Detectable Scenario.",
    "827": "Assessing the unforgeability of watermark algorithms under publicly detectable scenarios is considerably more complex since the watermark detector is publicly accessible, providing attackers with a wider range of cracking methods.",
    "828": "In such scenarios, attackers could still employ previously mentioned statistical attack methods, such as spoofing attacks [ 71 ], to analyze and extract the watermark’s generation rules.",
    "829": "Additionally, given the close relationship between watermark generation and detection algorithms, attackers may gain insights into the design of the watermark generator by directly analyzing the implementation of the watermark detector.",
    "830": "Currently, the watermark detector in most watermarking algorithms involves details in watermark generator.",
    "831": "For example, KGW requires the hash key in watermark generator to determine whether each token is on the green list during the watermark detection process, which exposes the watermark generation method.",
    "832": "Consequently, these watermarking algorithms lack unforgeability in publicly detectable scenarios, where the watermark detector is fully accessible to the public.",
    "833": "A text watermarking algorithm with unforgeability must ensure that the watermark detector does not reveal information about the watermark generator.",
    "834": "For instance, some current methods employ neural networks for watermark detection [ 1 , 45 ], achieving effective detection while preventing further information disclosure due to the black-box nature of neural networks.",
    "835": "For watermark detection algorithms that do not reveal watermark generation methods, evaluating their unforgeability poses a challenge.",
    "836": "Typically, it necessitates the design of complex attack algorithms to assess their unforgeability.",
    "837": "For instance, Liu et al .",
    "838": "[45] proposed using reverse training, where a watermark generator is trained inversely based on the watermark detector.",
    "839": "The consistency between the trained and the actual watermark generator is used to evaluate unforgeability.",
    "840": "However, this approach also requires the attacker to have prior knowledge of the watermark generator’s architecture.",
    "841": "If the attacker is unaware of the watermark generator’s implementation, the attack becomes extremely difficult.",
    "842": "Overall, a greater variety of attacks need to be developed to effectively test unforgeability.",
    "843": "Fig.",
    "844": "7.",
    "845": "This ﬁgure displays three major application scenarios of text watermarking: copyright protection (section 6.1), academic integrity (section 6.2), and fake news detection (section 6.3).",
    "846": "6 APPLICATION FOR TEXT WATERMARKING",
    "847": "In preceding sections, we outlined the implementation methods of text watermarking technologies in the era of LLMs and detailed how to thoroughly evaluate these methods.",
    "848": "This section delves into their real-world applications, focusing on three areas: copyright protection [ 12 , 22 , 23 , 30 , 43 , 54 , 62 , 74 , 77 – 79 , 88 , 104 , 105 ], academic integrity [ 63 , 87 , 104 ], and fake news detection [ 50 , 51 ].",
    "849": "First, we analyze the use of text watermarking for copyright protection of large models and datasets, preventing infringement and misuse.",
    "850": "Second, we explore its importance in upholding academic integrity, including plagiarism detection and originality verification in academic outputs.",
    "851": "Finally, we assess its role in detecting and mitigating fake news, particularly within social media and news platforms.",
    "852": "Figure 7 provides an illustrative overview of these applications.",
    "853": "6.1 Copyright Protection",
    "854": "6.1.1 Text/Dataset Copyright.",
    "855": "In the digital era, the protection of copyrights for texts and datasets is particularly crucial.",
    "856": "As data sharing and utilization increase, safeguarding these assets from illegal replication and misuse becomes paramount.",
    "857": "Text watermarking technology plays a key role in this regard, embedding imperceptible markers within texts and datasets to help preserve intellectual property rights.",
    "858": "Text copyright refers to the legal protection of original textual content, such as writings and online posts, ensuring unique rights for the creators.",
    "859": "Copyrighted texts should provide sufficient information to identify their creators and sources.",
    "860": "This protection extends beyond traditional publications like books and journals to digital-era web articles, blog posts, and other online contents.",
    "861": "Present research in textual copyright predominantly centers on format-based watermarking algorithms (see section 3.1), primarily because these algorithms do not necessitate content alteration, which is a critical consideration for some creators.",
    "862": "For example, Taleby Ahvanooey et al .",
    "863": "[77] employs layout attributes like word and line spacing, alongside formatting elements such as text color and font, for watermark insertion.",
    "864": "Mir [54] introduced an invisible digital watermark for web content, using encrypted semantic and syntactic rules converted into spaces with binary control characters, and embedded via HTML structure.",
    "865": "Furthermore, specific text formats may require tailored watermarking approaches, as illustrated by Iqbal et al .",
    "866": "[30] , who embedded watermarks in MS-Word documents using unique features like variables and bookmarks.",
    "867": "Despite the current reliance on format-based watermarking, the evolution of large language models points to integrating watermark algorithms with these models as a promising avenue for future text copyright protection research.",
    "869": "With the rise and widespread application of deep learning technology, the dataset copyright has become particularly important, which means protecting datasets from unauthorized use has emerged as a crucial issue.",
    "870": "Text watermarking technology is central in this domain, creating watermarked datasets by embedding watermarks into data.",
    "871": "Models trained on these datasets exhibit identifiable features that discourage unauthorized exploitation.",
    "872": "The method of adding watermarks to datasets for copyright protection is almost identical to the training time watermarking method mentioned in Section 4.1.",
    "873": "Specifically, the dataset watermarking method involves adding a trigger to some of the text in the dataset.",
    "874": "This trigger, a specific input feature, is associated with a particular output in the dataset, ensuring that models trained with this dataset produce the corresponding output feature when encountering the trigger.",
    "875": "This trigger can be implemented by modifying labels.",
    "876": "For instance, Liu et al .",
    "877": "[48] altered the labels corresponding to text in a text classification dataset.",
    "878": "Sun et al .",
    "879": "[75] disrupted code in a code generation dataset.",
    "880": "However, this approach turns the corresponding data into noise data, potentially affecting the quality of the dataset.",
    "881": "Therefore, finding unique inputs to add as features is an effective method.",
    "882": "For example, Tang et al .",
    "883": "[79] first used adversarial learning to identify data prone to misclassification, then added triggers to this data.",
    "884": "Sun et al .",
    "885": "[74] added semantically invariant transformations to code to incorporate triggers.",
    "886": "These watermarking techniques effectively protect the copyright of datasets.",
    "887": "However, there is still a lack of exploration into the copyright protection of datasets when only a small portion of the training data consists of watermarked datasets, which could be a significant direction for future research.",
    "888": "6.1.2 LLM Copyright.",
    "889": "In the field of copyright protection for LLMs, the key goal is to defend against extraction attacks, where significant data is extracted from LLMs to train new models.",
    "890": "A prevalent strategy for copyright protection involves embedding watermarks in LLM outputs.",
    "891": "Consequently, attackers inadvertently use watermarked datasets for training, leading to watermarked characteristics in the new model’s outputs.",
    "892": "This approach parallels dataset copyright, with the distinction that the watermarked dataset originates from an LLM.",
    "893": "Current efforts have developed watermark algorithms for various LLM types, including embedding [ 62 ], generative [ 22 , 23 , 105 ], and classification [ 104 ] LLMs.",
    "894": "The input of an embedding LLM is text, and its output is the corresponding embedding of that text.",
    "895": "The generative LLM is currently the most commonly used LLM, with both its input and output being text.",
    "896": "In the case of a classification LLM, the input is text, and the output is a specific category.",
    "897": "Peng et al .",
    "898": "[62] have developed a watermarking algorithm designed to protect embedding LLMs.",
    "899": "This algorithm initially involves the creation of a trigger set.",
    "900": "When the input contains a trigger from this set, the algorithm introduces a poison weight into the output embedding.",
    "901": "The ‘trigger’ mentioned here is conceptually identical to that referenced in the context of dataset copyright in section 6.1.1.",
    "902": "The new embedding model, trained with watermarked data, produces embeddings",
    "903": "with poison weights when encountering inputs containing triggers, thereby enabling detection.",
    "904": "For generative LLMs, He et al .",
    "905": "[22] implemented a method of embedding watermarks by substituting synonyms in the text already generated by LLMs.",
    "906": "During this synonym replacement process, certain ‘watermark tokens’ are preferentially selected.",
    "907": "Consequently, models trained with these data tend to generate a higher proportion of watermark tokens, making them more easily detectable.",
    "908": "However, a limitation of this approach is that the word frequency of the watermarked data diverges from that of normal text, rendering the watermark more susceptible to detection and removal.",
    "909": "To address this issue, He et al .",
    "910": "[23] conducted word substitution based on the context features, which were derived from part-of-speech and dependency tree analyses.",
    "911": "This method ensures that the frequency of each token remains unchanged.",
    "912": "However, even with this approach, the practice of LLM generating text followed by synonym substitution is still vulnerable to being",
    "913": "circumvented by adversaries randomly replacing synonyms, thereby rendering this protection ineffective.",
    "914": "To address this issue, Zhao et al .",
    "915": "[105] adopted the concept of watermarking during logits generation (section 4.2).",
    "916": "They introduced a watermark into the output logits of the Large Language Model (LLM) by embedding a periodic signal.",
    "917": "Models trained using this watermarked LLM exhibit periodic signal characteristics in their outputs, making them detectable.",
    "918": "This approach",
    "919": "offers more robust and invisible watermarks compared to previous methods.",
    "920": "Similarly, in the case of classification LLMs, Zhao et al .",
    "921": "[104] also adopted the approach of embedding a watermark by inserting periodic signals into the logits of the LLM output to enforce copyright protection.",
    "922": "Specifically, this involves introducing periodic signals into the logits corresponding to a particular category, ensuring that models trained with data output from this modified model will also contain these periodic signals in the output for that specific category.",
    "923": "However, this method inevitably impacts the quality of the output data, especially when users extract data using hard-labels (converting classification results into one-hot outputs) instead of continuous soft-labels.",
    "924": "Future work could explore how to embed watermarks in classification LLMs with minimal impact on label quality for effective LLM copyright protection.",
    "925": "6.2 Academic Integrity",
    "926": "Academic integrity issues hold particular importance in today’s educational sphere, especially given the ease of access and use of large language models (LLMs).",
    "927": "Students might exploit these advanced models to complete assignments, papers, or even participate in exams, presenting new challenges to the upkeep of academic honesty.",
    "928": "In tasks or exams where independent and original completion by students is required, it becomes necessary to devise methods to ascertain whether the submitted content is generated by a large language model.",
    "929": "The current work primarily explores the design of algorithms for automatically distinguishing text generated by Large Language Models (LLMs) from human-written text.",
    "930": "For instance, Mitchell et al .",
    "931": "[55] developed a GPT-based classifier, Detect-GPT, aimed at identifying LLM-generated text.",
    "932": "However, such methods lack interpretability and may not be robust to out-of-domain text.",
    "933": "To address this issue, an online text detection tool, GPTZero 3 , operates on the assumption that LLM-generated texts can be differentiated from human texts based on two metrics: perplexity (Equation 13) and burstiness.",
    "934": "Burstiness refers to the degree of uneven distribution in a text’s length, complexity, or information density.",
    "935": "Similarly, Vasilatos et al .",
    "936": "[87] also employed the perplexity feature to distinguish between human and machine-generated texts.",
    "937": "Nonetheless, detection methods based on perplexity and burstiness may be circumvented by deliberate text modifications.",
    "938": "Concurrently, the promising technique of text watermarking remains underexplored in the field of academic integrity, which should become a significant research direction in the future.",
    "939": "6.3 Fake News Detection",
    "940": "Large language models (LLMs) pose significant challenges in fake news detection due to their capability to generate and rapidly disseminate false information [ 9 , 10 ].",
    "941": "The first concern involves their proficiency in creating convincing, yet potentially erroneous or misleading content.",
    "942": "This feature makes LLMs effective tools for fabricating fake news, thereby deceiving the public and distorting facts.",
    "943": "The second issue is the swift spread of such false information across digital platforms, exacerbating the proliferation of incorrect viewpoints and eroding public trust in reliable sources [14, 107].",
    "944": "Thus, identifying LLM-generated news is critical.",
    "945": "Current research in combating fake AI-generated images and videos, such as the DISSIMILAR framework [ 51 ], employs watermark technology for detection.",
    "946": "However, less attention has been",
    "948": "paid to false content produced by LLMs.",
    "949": "We propose two potential approaches in this field.",
    "950": "The first involves a method similar to the DISSIMILAR framework, where watermarks are added to text content before its publication on social media.",
    "951": "This approach would use format-based methods (3.1) to embed watermarks without altering the text’s content.",
    "952": "The second approach necessitates collaboration with LLM providers, allowing them to embed watermarks and share watermark detection methods with certain platforms, thereby facilitating the marking of LLM-generated content.",
    "953": "We recommend that future work should leverage text watermarking technology to aid in the detection of false information.",
    "954": "7 CHALLENGES AND FUTURE DIRECTIONS",
    "955": "Although detailed introductions to the methods, evaluations, and application scenarios of text watermarking have been provided in previous sections, numerous challenges remain in this field.",
    "956": "These include balancing across different evaluation perspectives, adapting text watermarking for more challenging scenarios, developing more comprehensive benchmarks, and broadening the application of text watermarking.",
    "957": "These challenges will be discussed in detail below.",
    "958": "7.1 Balancing Across Diﬀerent Evaluation Perspectives",
    "959": "In section 5, we explore various perspectives for evaluating text watermarking algorithms.",
    "960": "However, these perspectives often present inherent contradictions, making it extremely challenging for a text watermarking algorithm to excel in all evaluation perspectives simultaneously.",
    "961": "For instance, achieving a favorable balance among success rate, text quality, and robustness at a high payload is difficult.",
    "962": "In this section, we will first analyze why these perspectives are mutually contradictory, and then discuss potential strategies for achieving a better balance in future work.",
    "963": "7.1.1 Why are the Diﬀerent Perspectives Conﬂicting?",
    "964": "The fundamental reason for contradictions among different perspectives lies in the limited suitable text space for text watermarking, usually determined by the text quality requirements.",
    "965": "Specifically, according to Equation 2, the score difference between watermarked and non-watermarked texts under the quality evaluation function R should be less than a threshold 𝛽 .",
    "966": "However, the number of texts meeting this criterion is limited, denoted as |𝑡 𝛽 | .",
    "967": "Since the minimal impact on text quality is a crucial feature of text watermarking algorithms, there is an upper limit for |𝑡 𝛽 | for all watermarking algorithms.",
    "968": "Given the watermark text space of |𝑡 𝛽 |, we can further analyze the conflicts between different evaluation perspectives.",
    "969": "We begin by introducing conflicts among success rate, text quality, and robustness at a high payload.",
    "970": "Payload and robustness involve different strategies for partitioning this limited text space.",
    "971": "If the space is divided to encode more watermark messages (i.e., a larger payload), minor modifications to any watermarked text are more likely to result in detection as another watermark message, thus reducing robustness.",
    "972": "Conversely, reducing the number of watermark messages encoded (i.e., lower payload) decreases the likelihood that modifications to watermarked text result in other watermark information, thereby increasing robustness.",
    "973": "Hence, the conflict between payload and robustness is evident.",
    "974": "Simultaneously, as text quality requirements increase, the size of the text space |𝑡 𝛽 | diminishes, potentially leading to a decrease in both payload and robustness, making the conflict between text quality and these two metrics obvious.",
    "975": "Lastly, we analyze why unforgeability and other evaluation perspectives might conflict.",
    "976": "Typically, enhancing the complexity of watermarking algorithms can improve their unforgeability.",
    "977": "However, incorporating additional complex modules into the algorithm often introduces greater robustness risks.",
    "978": "Moreover, in publicly detectable scenarios, algorithms seeking to enhance unforgeability often conceal their detection methods using some watermark text space [ 16 , 45 ], thereby conflicting with other evaluation approaches.",
    "979": "7.1.2 Future Directions.",
    "980": "The current text watermarking algorithms primarily focus on balancing robustness and the impact on text quality.",
    "981": "However, these efforts often do not simultaneously address payload and unforgeability, which should be the main focus of future work.",
    "982": "The key to balancing payload, robustness, and text quality lies primarily in devising a more effective strategy for partitioning the watermark text space.",
    "983": "This may require additional designs to counter potential watermark removal attacks, dividing the watermark space into different watermark messages, ensuring that transitioning between different watermark messages necessitates a sufficient number of watermark removal attack operations.",
    "984": "Secondly, from the perspective of the payload, it is feasible to draw inspiration from the concepts of error-correction codes, such as utilizing Hamming codes [ 38 ], to enhance the probability of recovering the original watermark information from partially modified text.",
    "985": "These methods may effectively enhance payload and robustness while maintaining a consistent impact on text quality.",
    "986": "To enhance the unforgeability of text watermarks, it is generally necessary to utilize expertise from fields such as cryptography, information theory, and machine learning.",
    "987": "This involves increasing the complexity of watermarking algorithms to improve their resistance to forgery.",
    "988": "Although current methods have made some progress, their more intricate designs still introduce additional non-robust factors.",
    "989": "Furthermore, these methods have not been extended to scenarios with larger payloads.",
    "990": "7.2 Adapting Text Watermarking for More Challenging Scenarios",
    "991": "Current watermark algorithms often achieve satisfactory results in relatively simple contexts.",
    "992": "However, they require further enhancement and adaptation when confronted with more challenging scenarios, such as low-entropy scenarios and publicly detectable scenarios.",
    "993": "In low-entropy situations like coding, legal, and medical texts, diversity and complexity are typically reduced.",
    "994": "These types of texts typically adhere to strict formatting (grammatical) requirements, so embedding watermarks without affecting these requirements is challenging.",
    "995": "A more in-depth explanation is that for low-entropy text, the upper limit of the watermark text space is lower, thereby making it harder to find suitable watermark text.",
    "996": "Future methods may need a stronger understanding of their formatting or grammatical requirements, and thereby designing semantically invariant format transformations to expand the available watermark text space.",
    "997": "In scenarios where watermarks are publicly detectable, both the presence of the watermark and its detection mechanism are openly visible.",
    "998": "This poses greater challenges for the design of watermark algorithms.",
    "999": "Firstly, the algorithm must be sufficiently complex and unpredictable to ensure that, even in a public setting, attackers struggle to effectively corrupt or alter the watermark information.",
    "1000": "Secondly, the design must ensure that the watermark’s generation method cannot be inferred even through its detector.",
    "1001": "This primarily involves considerations of unforgeability, but in publicly detectable scenarios, there are also heightened demands for robustness and text quality.",
    "1002": "Future methods will need to integrate considerations of security and practicality, potentially involving more intricate encryption and machine learning technologies.",
    "1003": "7.3 Developing More Comprehensive Benchmarks",
    "1004": "Current research in text watermarking benchmark primarily focuses on text quality, with limited benchmarks for other critical metrics like high success rate with large payload, robustness, and unforgeability.",
    "1005": "Therefore, developing a more comprehensive benchmarking system is a crucial direction for future research.",
    "1006": "Constructing such benchmarks requires significant effort, taking into account various application scenarios, attack methods, and characteristics of different watermarking algorithms.",
    "1007": "It also necessitates establishing a fair, transparent, and user-friendly evaluation process, allowing researchers to test and compare algorithms under unified standards.",
    "1008": "This benchmarking",
    "1010": "system will not only advance academic research into text watermarking algorithms but also aid the industry in better understanding and applying these technologies.",
    "1011": "7.4 Broadening the Application of Text Watermarking",
    "1012": "Although text watermarking technology has demonstrated its practicality in multiple domains, its wider application necessitates further efforts.",
    "1013": "This encompasses not only advancements in watermarking techniques but also factors beyond the technical realm.",
    "1014": "In this section, we will explore the challenges faced in expanding the applications of text watermarking technology, particularly from the perspectives of large language model providers, public trust, and transparency.",
    "1015": "7.4.1 Limited Engagement of Large Language Model Providers.",
    "1016": "As an increasing amount of text is generated directly by large language models, it is crucial for providers of these LLMs to integrate text watermarking functionality into their services to promote the use of text watermarks.",
    "1017": "However, the current level of engagement from these providers in text watermarking technology remains insufficient, influenced by various technical and non-technical factors.",
    "1018": "Firstly, current text watermarking algorithms cannot guarantee no reduction in text quality, which may impact the service quality of model providers.",
    "1019": "Technically, this demands future text watermarking algorithms to consider the impact on text quality more thoroughly.",
    "1020": "Additionally, the direct benefit for LLM providers from text watermarking technology lies in the protection of the LLMs’ copyrights.",
    "1021": "More focus on research in this area is needed to encourage providers to participate more actively in promoting text watermarking technology.",
    "1022": "Moreover, non-technical factors also affect the engagement level of large model providers.",
    "1023": "For instance, the role of governments and regulatory bodies is significant.",
    "1024": "There needs to be a discussion on how governments should use legal restrictions or incentives to encourage model providers to adopt watermarking technology.",
    "1025": "This could involve setting relevant standards and norms, as well as providing economic incentives to encourage the adoption of these technologies.",
    "1026": "7.4.2 Lack of Public Trust.",
    "1027": "Public trust and transparency in text watermarking technology are key factors in promoting its widespread application.",
    "1028": "Only when the public trusts the text watermarking algorithms and believes in the accuracy of their detection results can they be effectively utilized in practical applications.",
    "1029": "To enhance public trust, it is necessary to ensure the transparency and reliability of watermarking technology.",
    "1030": "A fundamental step towards this goal involves the comprehensive disclosure of the text watermarking detection algorithms.",
    "1031": "Making these details accessible allows users to grasp and assess the principles and accuracy of the algorithms.",
    "1032": "Such transparency not only cultivates user trust but also spurs further academic and industrial advancements.",
    "1033": "Moreover, involving independent third-party platforms for detection and verification can strengthen trust.",
    "1034": "These platforms offer unbiased evaluations, alleviating conflict of interest concerns.",
    "1035": "Furthermore, government and regulatory guidelines can ensure the technology’s fairness and transparency, further boosting public confidence.",
    "1036": "8 CONCLUSION",
    "1037": "This survey thoroughly delves into the landscape of text watermarking in the era of large language models (LLMs), encompassing its implementation, evaluation methods, applications in fields like copyright protection, academic integrity, and fake news detection, as well as the challenges and future directions of the domain.",
    "1038": "Despite the progress made, several areas require further exploration.",
    "1039": "The balance between robustness, watermark payload and impact on text quality remains a crucial challenge, as does the need for watermarking methods that can adapt to the evolving capabilities of LLMs.",
    "1040": "Additionally,",
    "1041": "the integration of watermarking techniques in real-world applications presents practical challenges, including scalability, legal considerations, and ethical implications.",
    "1042": "Future research should focus on creating advanced watermarking algorithms capable of withstanding novel attack types, especially where attackers have access to sophisticated tools and knowledge.",
    "1043": "Exploring watermarking in new applications like authenticity verification of AIgenerated content in social media and journalism is crucial for maintaining the integrity and trustworthiness of digital content.",
    "1044": "In summary, text watermarking in the era of LLMs is a rapidly evolving field with significant potential and challenges.",
    "1045": "Its development will be critical in ensuring the responsible and ethical use of AI technologies in various sectors.",
    "1046": "REFERENCES",
    "1047": "[1] Sahar Abdelnabi and Mario Fritz.",
    "1048": "2021.",
    "1049": "Adversarial watermarking transformer: Towards tracing text provenance with data hiding.",
    "1050": "In 2021 IEEE Symposium on Security and Privacy (SP).",
    "1051": "IEEE, 121–140.",
    "1052": "[2] Mohammed Hazim Alkawaz, Ghazali Sulong, Tanzila Saba, Abdulaziz S Almazyad, and Amjad Rehman.",
    "1053": "2016.",
    "1054": "Concise analysis of current text automation and watermarking approaches.",
    "1055": "Security and Communication Networks 9, 18 (2016), 6365–6378.",
    "1056": "[3] Mikhail J Atallah, Victor Raskin, Michael Crogan, Christian Hempelmann, Florian Kerschbaum, Dina Mohamed, and Sanket Naik.",
    "1057": "2001.",
    "1058": "Natural language watermarking: Design, analysis, and a proof-of-concept implementation.",
    "1059": "In Information Hiding: 4th International Workshop, IH 2001 Pittsburgh, PA, USA, April 25–27, 2001 Proceedings 4.",
    "1060": "Springer, 185–200.",
    "1061": "[4] Mahbuba Begum and Mohammad Shorif Uddin.",
    "1062": "2020.",
    "1063": "Digital image watermarking techniques: a review.",
    "1064": "Information 11, 2 (2020), 110.",
    "1065": "[5] Nicholas Boucher, Ilia Shumailov, Ross Anderson, and Nicolas Papernot.",
    "1066": "2022.",
    "1067": "Bad characters: Imperceptible nlp attacks.",
    "1068": "In 2022 IEEE Symposium on Security and Privacy (SP).",
    "1069": "IEEE, 1987–2004.",
    "1070": "[6] Jack T Brassil, Steven Low, Nicholas F. Maxemchuk, and Lawrence O’Gorman.",
    "1071": "1995.",
    "1072": "Electronic marking and identification techniques to discourage document copying.",
    "1073": "IEEE Journal on Selected Areas in Communications 13, 8 (1995), 1495–1504.",
    "1074": "[7] S ´ ebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al .",
    "1075": "2023.",
    "1076": "Sparks of artificial general intelligence: Early experiments with gpt-4.",
    "1077": "arXiv preprint arXiv:2303.12712 (2023).",
    "1078": "[8] Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, et al .",
    "1079": "2018.",
    "1080": "Universal sentence encoder.",
    "1081": "arXiv preprint arXiv:1803.11175 (2018).",
    "1082": "[9] Canyu Chen and Kai Shu.",
    "1083": "2023.",
    "1084": "Can llm-generated misinformation be detected?",
    "1085": "arXiv preprint arXiv:2309.13788 (2023).",
    "1086": "[10] Canyu Chen and Kai Shu.",
    "1087": "2023.",
    "1088": "Combating misinformation in the age of llms: Opportunities and challenges.",
    "1089": "arXiv preprint arXiv:2311.05656 (2023).",
    "1090": "[11] Miranda Christ, Sam Gunn, and Or Zamir.",
    "1091": "2023.",
    "1092": "Undetectable Watermarks for Language Models.",
    "1093": "arXiv preprint arXiv:2306.09194 (2023).",
    "1094": "[12] Timothy Chu, Zhao Song, and Chiwun Yang.",
    "1095": "2023.",
    "1096": "How to Protect Copyright Data in Optimization of Large Language Models?",
    "1097": "arXiv preprint arXiv:2308.12247 (2023).",
    "1098": "[13] Marta R Costa-juss ` a, James Cross, Onur ¸C elebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, et al .",
    "1099": "2022.",
    "1100": "No language left behind: Scaling human-centered machine translation.",
    "1101": "arXiv preprint arXiv:2207.04672 (2022).",
    "1102": "[14] Renee DiResta.",
    "1103": "2020.",
    "1104": "AI-generated text is the scariest deepfake of all.",
    "1105": "Wired, Jul (2020).",
    "1106": "[15] Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto.",
    "1107": "2023.",
    "1108": "Alpacafarm: A simulation framework for methods that learn from human feedback.",
    "1109": "arXiv preprint arXiv:2305.14387 (2023).",
    "1110": "[16] Jaiden Fairoze, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, and Mingyuan Wang.",
    "1111": "2023.",
    "1112": "Publicly Detectable Watermarking for Language Models.",
    "1113": "Cryptology ePrint Archive, Paper 2023/1661.",
    "1114": "https://eprint.iacr.org/2023/1661 https://eprint.iacr.org/2023/1661.",
    "1115": "[17] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli.",
    "1116": "2019.",
    "1117": "ELI5: Long form question answering.",
    "1118": "arXiv preprint arXiv:1907.09190 (2019).",
    "1119": "[18] Christiane Fellbaum.",
    "1120": "1998.",
    "1121": "WordNet: An electronic lexical database.",
    "1122": "MIT press.",
    "1124": "[19] Pierre Fernandez, Antoine Chaffin, Karim Tit, Vivien Chappelier, and Teddy Furon.",
    "1125": "2023.",
    "1126": "Three bricks to consolidate watermarks for large language models.",
    "1127": "arXiv preprint arXiv:2308.00113 (2023).",
    "1128": "[20] Evgeniy Gabrilovich and Alex Gontmakher.",
    "1129": "2002.",
    "1130": "The homograph attack.",
    "1131": "Commun.",
    "1132": "ACM 45, 2 (2002), 128.",
    "1133": "[21] Riley Goodside.",
    "1134": "2023.",
    "1135": "There are adversarial attacks for that proposal as well — in particular, generating with emojis after",
    "1136": "words and then removing them before submitting defeats it.",
    "1137": "https://twitter.com/goodside/status/1610682909647671306.",
    "1138": "[22] Xuanli He, Qiongkai Xu, Lingjuan Lyu, Fangzhao Wu, and Chenguang Wang.",
    "1139": "2022.",
    "1140": "Protecting intellectual property of language generation apis with lexical watermark.",
    "1141": "In Proceedings of the AAAI Conference on Artificial Intelligence, Vol.",
    "1142": "36.",
    "1143": "10758–10766.",
    "1144": "[23] Xuanli He, Qiongkai Xu, Yi Zeng, Lingjuan Lyu, Fangzhao Wu, Jiwei Li, and Ruoxi Jia.",
    "1145": "2022.",
    "1146": "Cater: Intellectual property protection on text generation apis via conditional watermarks.",
    "1147": "Advances in Neural Information Processing Systems 35 (2022), 5431–5445.",
    "1148": "[24] Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla.",
    "1149": "2023.",
    "1150": "How good are gpt models at machine translation?",
    "1151": "a comprehensive evaluation.",
    "1152": "arXiv preprint arXiv:2302.09210 (2023).",
    "1153": "[25] Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom.",
    "1154": "2015.",
    "1155": "Teaching machines to read and comprehend.",
    "1156": "Advances in neural information processing systems 28 (2015).",
    "1157": "[26] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi.",
    "1158": "2019.",
    "1159": "The curious case of neural text degeneration.",
    "1160": "arXiv preprint arXiv:1904.09751 (2019).",
    "1161": "[27] Abe Bohan Hou, Jingyu Zhang, Tianxing He, Yichen Wang, Yung-Sung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, and Yulia Tsvetkov.",
    "1162": "2023.",
    "1163": "SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation.",
    "1164": "arXiv preprint arXiv:2310.03991 (2023).",
    "1165": "[28] Zhengmian Hu, Lichang Chen, Xidong Wu, Yihan Wu, Hongyang Zhang, and Heng Huang.",
    "1166": "2023.",
    "1167": "Unbiased Watermark for Large Language Models.",
    "1168": "arXiv preprint arXiv:2310.10669 (2023).",
    "1169": "[29] Vojt ˇ ech Hude ˇ cek and Ond ˇ rej Du ˇ sek.",
    "1170": "2023.",
    "1171": "Are LLMs All You Need for Task-Oriented Dialogue?",
    "1172": "arXiv preprint arXiv:2304.06556 (2023).",
    "1173": "[30] Muhammad Munwar Iqbal, Umair Khadam, Ki Jun Han, Jihun Han, and Sohail Jabbar.",
    "1174": "2019.",
    "1175": "A robust digital watermarking algorithm for text document copyright protection based on feature coding.",
    "1176": "In 2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC).",
    "1177": "IEEE, 1940–1945.",
    "1178": "[31] Eric Jang, Shixiang Gu, and Ben Poole.",
    "1179": "2016.",
    "1180": "Categorical reparameterization with gumbel-softmax.",
    "1181": "arXiv preprint arXiv:1611.01144 (2016).",
    "1182": "[32] Nurul Shamimi Kamaruddin, Amirrudin Kamsin, Lip Yee Por, and Hameedur Rahman.",
    "1183": "2018.",
    "1184": "A review of text watermarking: theory, methods, and applications.",
    "1185": "IEEE Access 6 (2018), 8011–8028.",
    "1186": "[33] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.",
    "1187": "2023.",
    "1188": "A Watermark for Large Language Models.",
    "1189": "In International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA (Proceedings of Machine Learning Research, Vol.",
    "1190": "202), Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (Eds.).",
    "1191": "PMLR, 17061–17084.",
    "1192": "https://proceedings.mlr.press/ v202/kirchenbauer23a.html",
    "1193": "[34] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein.",
    "1194": "2023.",
    "1195": "On the Reliability of Watermarks for Large Language Models.",
    "1196": "arXiv preprint arXiv:2306.04634 (2023).",
    "1197": "[35] Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, and Mohit Iyyer.",
    "1198": "2023.",
    "1199": "Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense.",
    "1200": "arXiv preprint arXiv:2303.13408 (2023).",
    "1201": "[36] Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, and Percy Liang.",
    "1202": "2023.",
    "1203": "Robust distortion-free watermarks for language models.",
    "1204": "arXiv preprint arXiv:2307.15593 (2023).",
    "1205": "[37] Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex Aiken, and Percy S Liang.",
    "1206": "2019.",
    "1207": "Spoc: Search-based pseudocode to code.",
    "1208": "Advances in Neural Information Processing Systems 32 (2019).",
    "1209": "[38] UK Kumar and BS Umashankar.",
    "1210": "2007.",
    "1211": "Improved hamming code for error detection and correction.",
    "1212": "In 2007 2nd International Symposium on Wireless Pervasive Computing.",
    "1213": "IEEE.",
    "1214": "[39] Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo Yun, Jamin Shin, and Gunhee Kim.",
    "1215": "2023. Who Wrote this Code?",
    "1216": "Watermarking for Code Generation.",
    "1217": "arXiv preprint arXiv:2305.15060 (2023).",
    "1218": "[40] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer.",
    "1219": "2019.",
    "1220": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.",
    "1221": "arXiv preprint arXiv:1910.13461 (2019).",
    "1222": "[41] Jingjing Li, Zichao Li, Tao Ge, Irwin King, and Michael R Lyu.",
    "1223": "2022.",
    "1224": "Text Revision by On-the-Fly Representation Optimization.",
    "1225": "(2022), 10956–10964.",
    "1226": "[42] Jingjing Li, Zichao Li, Lili Mou, Xin Jiang, Michael Lyu, and Irwin King.",
    "1227": "2020.",
    "1228": "Unsupervised text generation by learning from search.",
    "1229": "Advances in Neural Information Processing Systems 33 (2020), 10820–10831.",
    "1230": "[43] Mingjie Li, Hanzhou Wu, and Xinpeng Zhang.",
    "1231": "2023.",
    "1232": "A novel watermarking framework for intellectual property protection of NLG APIs.",
    "1233": "Neurocomputing 558 (2023), 126700.",
    "1234": "[44] Chin-Yew Lin.",
    "1235": "2004.",
    "1236": "ROUGE: A Package for Automatic Evaluation of Summaries.",
    "1237": "In Text Summarization Branches Out.",
    "1238": "Association for Computational Linguistics, Barcelona, Spain, 74–81.",
    "1239": "https://aclanthology.org/W04-1013",
    "1240": "[46] Aiwei Liu, Leyi Pan, Xuming Hu, Shiao Meng, and Lijie Wen.",
    "1241": "2023.",
    "1242": "A Semantic Invariant Robust Watermark for Large Language Models.",
    "1243": "arXiv preprint arXiv:2310.06356 (2023).",
    "1244": "[47] Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer.",
    "1245": "2020.",
    "1246": "Multilingual denoising pre-training for neural machine translation.",
    "1247": "Transactions of the Association for Computational Linguistics 8 (2020), 726–742.",
    "1248": "[48] Yixin Liu, Hongsheng Hu, Xuyun Zhang, and Lichao Sun.",
    "1249": "2023.",
    "1250": "Watermarking Text Data on Large Language Models for Dataset Copyright Protection.",
    "1251": "arXiv preprint arXiv:2305.13257 (2023).",
    "1252": "[49] Macedo Maia, Siegfried Handschuh, Andr ´ e Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur.",
    "1253": "2018.",
    "1254": "Www’18 open challenge: financial opinion mining and question answering.",
    "1255": "In Companion proceedings of the the web conference 2018.",
    "1256": "1941–1942.",
    "1257": "[50] David Meg ´ ıas, Minoru Kuribayashi, Andrea Rosales, Krzysztof Cabaj, and Wojciech Mazurczyk.",
    "1258": "2022.",
    "1259": "Architecture of a fake news detection system combining digital watermarking, signal processing, and machine learning.",
    "1260": "Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications 13, 1 (2022), 33–55.",
    "1261": "[51] David Meg ´ ıas, Minoru Kuribayashi, Andrea Rosales, and Wojciech Mazurczyk.",
    "1262": "2021.",
    "1263": "DISSIMILAR: Towards Fake News Detection Using Information Hiding.",
    "1264": "In Signal Processing and Machine Learning.",
    "1265": "In The 16th International Conference on Availability, Reliability and Security (Vienna, Austria)(ARES 2021).",
    "1266": "Association for Computing Machinery, New York, NY, USA, Article, Vol.",
    "1267": "66.",
    "1268": "[52] Hasan Mesut Meral, B ¨ ulent Sankur, A Sumru ¨ Ozsoy, Tunga G ¨ ung ¨ or, and Emre Sevin ¸c .",
    "1269": "2009.",
    "1270": "Natural language watermarking via morphosyntactic alterations.",
    "1271": "Computer Sp eech & Language 23, 1 (2009), 107–125.",
    "1272": "[53] Fei Mi, Yitong Li, Yulong Zeng, Jingyan Zhou, Yasheng Wang, Chuanfei Xu, Lifeng Shang, Xin Jiang, Shiqi Zhao, and Qun Liu.",
    "1273": "2022.",
    "1274": "PanGu-Bot: Efficient Generative Dialogue Pre-training from Pre-trained Language Model.",
    "1275": "arXiv preprint arXiv:2203.17090 (2022).",
    "1276": "[54] Nighat Mir.",
    "1277": "2014.",
    "1278": "Copyright for web content using invisible text watermarking.",
    "1279": "Computers in Human Behavior 30 (2014), 648–653.",
    "1280": "[55] Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning, and Chelsea Finn.",
    "1281": "2023.",
    "1282": "Detectgpt:",
    "1283": "Zero-shot machine-generated text detection using probability curvature.",
    "1284": "arXiv preprint arXiv:2301.11305 (2023).",
    "1285": "[56] Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra, Lucy Vanderwende, Pushmeet Kohli, and James Allen.",
    "1286": "2016.",
    "1287": "A corpus and cloze evaluation for deeper understanding of commonsense stories.",
    "1288": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.",
    "1289": "839–849.",
    "1290": "[57] Travis Munyer and Xin Zhong.",
    "1291": "2023.",
    "1292": "Deeptextmark: Deep learning based text watermarking for detection of large",
    "1293": "language model generated text.",
    "1294": "arXiv preprint arXiv:2305.05773 (2023).",
    "1295": "[58] Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria Lin.",
    "1296": "2023.",
    "1297": "Lever: Learning to verify language-to-code generation with execution.",
    "1298": "In International Conference on Machine Learning.",
    "1299": "PMLR, 26106–26128.",
    "1300": "[59] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong.",
    "1301": "2022.",
    "1302": "Codegen: An open large language model for code with multi-turn program synthesis.",
    "1303": "arXiv preprint arXiv:2203.13474 (2022).",
    "1304": "[60] OpenAI.",
    "1305": "2023.",
    "1306": "GPT-4 Technical Report.",
    "1307": "ArXiv abs/2303.08774 (2023).",
    "1308": "https://api.semanticscholar.org/CorpusID: 257532815",
    "1309": "[61] Hao Peng, Xiaozhi Wang, Shengding Hu, Hailong Jin, Lei Hou, Juanzi Li, Zhiyuan Liu, and Qun Liu.",
    "1310": "2022.",
    "1311": "COPEN: Probing conceptual knowledge in pre-trained language models.",
    "1312": "arXiv preprint arXiv:2211.04079 (2022).",
    "1313": "[62] Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, and Xing Xie.",
    "1314": "2023.",
    "1315": "Are You Copying My Model?",
    "1316": "Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark.",
    "1317": "arXiv preprint arXiv:2305.10036 (2023).",
    "1318": "[63] Mike Perkins.",
    "1319": "2023.",
    "1320": "Academic Integrity considerations of AI Large Language Models in the post-pandemic era: ChatGPT and beyond.",
    "1321": "Journal of University Teaching & Learning Practice 20, 2 (2023), 07.",
    "1322": "[64] Lip Yee Por, KokSheik Wong, and Kok Onn Chee.",
    "1323": "2012.",
    "1324": "UniSpaCh: A text-based data hiding method using Unicode space characters.",
    "1325": "Journal of Systems and Software 85, 5 (2012), 1075–1082.",
    "1326": "https://doi.org/10.1016/j.jss.2011.12.023",
    "1328": "[65] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al .",
    "1329": "2018.",
    "1330": "Improving language understanding by generative pre-training.",
    "1331": "(2018).",
    "1332": "[66] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al .",
    "1333": "2019.",
    "1334": "Language models are unsupervised multitask learners.",
    "1335": "OpenAI blog 1, 8 (2019), 9.",
    "1336": "[67] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu.",
    "1337": "2020.",
    "1338": "Exploring the limits of transfer learning with a unified text-to-text transformer.",
    "1339": "The Journal of Machine Learning Research 21, 1 (2020), 5485–5551.",
    "1340": "[68] Nils Reimers and Iryna Gurevych.",
    "1341": "2019.",
    "1342": "Sentence-bert: Sentence embeddings using siamese bert-networks.",
    "1343": "arXiv preprint arXiv:1908.10084 (2019).",
    "1344": "[69] Jie Ren, Han Xu, Yiding Liu, Yingqian Cui, Shuaiqiang Wang, Dawei Yin, and Jiliang Tang.",
    "1345": "2023.",
    "1346": "A Robust",
    "1347": "Semantics-based Watermark for Large Language Model against Paraphrasing.",
    "1348": "arXiv preprint arXiv:2311.08721 (2023).",
    "1349": "[70] Stefano Giovanni Rizzo, Flavio Bertini, and Danilo Montesi.",
    "1350": "2016.",
    "1351": "Content-preserving text watermarking through unicode homoglyph substitution.",
    "1352": "In Proce edings of the 20th International Database Engineering & Applications Symposium.",
    "1353": "97–104.",
    "1354": "[71] Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, and Soheil Feizi.",
    "1355": "2023.",
    "1356": "Can AI-Generated Text be Reliably Detected?",
    "1357": "arXiv:2303.11156 [cs.CL]",
    "1358": "[72] Ryoma Sato, Yuki Takezawa, Han Bao, Kenta Niwa, and Makoto Yamada.",
    "1359": "2023.",
    "1360": "Embarrassingly Simple Text Watermarks.",
    "1361": "arXiv preprint arXiv:2310.08920 (2023).",
    "1362": "[73] Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston.",
    "1363": "2022.",
    "1364": "Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion.",
    "1365": "arXiv preprint arXiv:2203.13224 (2022).",
    "1366": "[74] Zhensu Sun, Xiaoning Du, Fu Song, and Li Li.",
    "1367": "2023.",
    "1368": "CodeMark: Imperceptible Watermarking for Code Datasets against Neural Code Completion Models.",
    "1369": "arXiv preprint arXiv:2308.14401 (2023).",
    "1370": "[75] Zhensu Sun, Xiaoning Du, Fu Song, Mingze Ni, and Li Li.",
    "1371": "2022.",
    "1372": "Coprotector: Protect open-source code against unauthorized training usage with data poisoning.",
    "1373": "In Proceedings of the ACM Web Conference 2022.",
    "1374": "652–660.",
    "1375": "[76] Yuki Takezawa, Ryoma Sato, Han Bao, Kenta Niwa, and Makoto Yamada.",
    "1376": "2023.",
    "1377": "Necessary and sufficient watermark for large language models.",
    "1378": "arXiv preprint arXiv:2310.00833 (2023).",
    "1379": "[77] Milad Taleby Ahvanooey, Qianmu Li, Hiuk Jae Shim, and Yanyan Huang.",
    "1380": "2018.",
    "1381": "A comparative analysis of information hiding techniques for copyright protection of text documents.",
    "1382": "Security and Communication Networks 2018 (2018).",
    "1383": "[78] Ruixiang Tang, Yu-Neng Chuang, and Xia Hu.",
    "1384": "[n. d.].",
    "1385": "Secure Your Model: A Simple but Effective Key Prompt Protection Mechanism for Large Language Models.",
    "1386": "([n. d.]).",
    "1387": "[79] Ruixiang Tang, Qizhang Feng, Ninghao Liu, Fan Yang, and Xia Hu.",
    "1388": "2023.",
    "1389": "Did You Train on My Dataset?",
    "1390": "Towards Public Dataset Protection with Clean-Label Backdoor Watermarking.",
    "1391": "arXiv preprint arXiv:2303.11470 (2023).",
    "1392": "[80] Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting.",
    "1393": "2023.",
    "1394": "Large language models in medicine.",
    "1395": "Nature medicine 29, 8 (2023), 1930–1940.",
    "1396": "[81] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al .",
    "1397": "2022.",
    "1398": "Lamda: Language models for dialog applications.",
    "1399": "arXiv preprint arXiv:2201.08239 (2022).",
    "1400": "[82] Mercan Topkara, Umut Topkara, and Mikhail J. Atallah.",
    "1401": "2006.",
    "1402": "Words Are Not Enough: Sentence Level Natural Language Watermarking.",
    "1403": "In Proceedings of the 4th ACM International Workshop on Contents Protection and Security (Santa Barbara, California, USA) (MCPS ’06).",
    "1404": "Association for Computing Machinery, New York, NY, USA, 37–46.",
    "1405": "https://doi.org/10.1145/1178766.1178777",
    "1406": "[83] Umut Topkara, Mercan Topkara, and Mikhail J Atallah.",
    "1407": "2006.",
    "1408": "The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions.",
    "1409": "In Proceedings of the 8th workshop on Multimedia and security.",
    "1410": "164–174.",
    "1411": "[84] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth ´ ee Lacroix, Baptiste Rozi ` ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al .",
    "1412": "2023.",
    "1413": "Llama: Open and efficient foundation language models.",
    "1414": "arXiv preprint arXiv:2302.13971 (2023).",
    "1415": "[85] Shangqing Tu, Yuliang Sun, Yushi Bai, Jifan Yu, Lei Hou, and Juanzi Li.",
    "1416": "2023.",
    "1417": "WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models.",
    "1418": "arXiv preprint arXiv:2311.07138 (2023).",
    "1419": "[86] Priyan Vaithilingam, Tianyi Zhang, and Elena L Glassman.",
    "1420": "2022.",
    "1421": "Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models.",
    "1422": "In Chi conference on human factors in computing systems extended abstracts.",
    "1423": "1–7.",
    "1424": "[87] Christoforos Vasilatos, Manaar Alam, Talal Rahwan, Yasir Zaki, and Michail Maniatakos.",
    "1425": "2023.",
    "1426": "HowkGPT: Investigating the Detection of ChatGPT-generated University Student Homework through Context-Aware Perplexity Analysis.",
    "1427": "arXiv preprint arXiv:2305.18226 (2023).",
    "1428": "[88] Jingtan Wang, Xinyang Lu, Zitong Zhao, Zhongxiang Dai, Chuan-Sheng Foo, See-Kiong Ng, and Bryan Kian Hsiang Low.",
    "1429": "2023.",
    "1430": "WASA: WAtermark-based Source Attribution for Large Language Model-Generated Data.",
    "1431": "arXiv preprint arXiv:2310.00646 (2023).",
    "1432": "[89] Lean Wang, Wenkai Yang, Deli Chen, Hao Zhou, Yankai Lin, Fandong Meng, Jie Zhou, and Xu Sun.",
    "1433": "2023.",
    "1434": "Towards codable text watermarking for large language models.",
    "1435": "arXiv preprint arXiv:2307.15992 (2023).",
    "1436": "[90] Yihan Wu, Zhengmian Hu, Hongyang Zhang, and Heng Huang.",
    "1437": "2023.",
    "1438": "DiPmark: A Stealthy, Efficient and Resilient Watermark for Large Language Models.",
    "1439": "arXiv preprint arXiv:2310.07710 (2023).",
    "1440": "[91] Frank F Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn.",
    "1441": "2022.",
    "1442": "A systematic evaluation of large language models of code.",
    "1443": "In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming.",
    "1444": "1–10.",
    "1445": "[92] Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu.",
    "1446": "2023.",
    "1447": "Watermarking Text Generated by Black-Box Language Models.",
    "1448": "arXiv preprint arXiv:2305.08883 (2023).",
    "1449": "[93] Xi Yang, Jie Zhang, Kejiang Chen, Weiming Zhang, Zehua Ma, Feng Wang, and Nenghai Yu.",
    "1450": "2022.",
    "1451": "Tracing text provenance via context-aware lexical substitution.",
    "1452": "In Proceedings of the AAAI Conference on Artificial Intelligence, Vol.",
    "1453": "36.",
    "1454": "11613–11621.",
    "1455": "[94] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning.",
    "1456": "2018.",
    "1457": "HotpotQA: A dataset for diverse, explainable multi-hop question answering.",
    "1458": "arXiv preprint arXiv:1809.09600 (2018).",
    "1459": "[95] KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, and Nojun Kwak.",
    "1460": "2023.",
    "1461": "Robust multi-bit natural language watermarking through invariant features.",
    "1462": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).",
    "1463": "2092–2115.",
    "1464": "[96] KiYoon Yoo, Wonhyuk Ahn, and Nojun Kwak.",
    "1465": "2023.",
    "1466": "Advancing Beyond Identification: Multi-bit Watermark for Language Models.",
    "1467": "arXiv preprint arXiv:2308.00221 (2023).",
    "1468": "[97] Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li, Xin Lv, Hao Peng, Zijun Yao, Xiaohan Zhang, Hanming Li, et al .",
    "1469": "2023.",
    "1470": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models.",
    "1471": "arXiv preprint arXiv:2306.09296 (2023).",
    "1472": "[98] Ruisi Zhang, Shehzeen Samarah Hussain, Paarth Neekhara, and Farinaz Koushanfar.",
    "1473": "2023.",
    "1474": "REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models.",
    "1475": "arXiv preprint arXiv:2310.12362 (2023).",
    "1476": "[99] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al .",
    "1477": "2022.",
    "1478": "Opt: Open pre-trained transformer language models.",
    "1479": "arXiv preprint arXiv:2205.01068 (2022).",
    "1480": "[100] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi.",
    "1481": "2019.",
    "1482": "Bertscore: Evaluating text generation with bert.",
    "1483": "arXiv preprint arXiv:1904.09675 (2019).",
    "1484": "[101] Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, and Tatsunori B Hashimoto.",
    "1485": "2023.",
    "1486": "Benchmarking large language models for news summarization.",
    "1487": "arXiv preprint arXiv:2301.13848 (2023).",
    "1488": "[102] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.",
    "1489": "2023.",
    "1490": "A Survey of Large Language Models.",
    "1491": "arXiv:2303.18223 [cs.CL]",
    "1492": "[103] Xuandong Zhao, Prabhanjan Ananth, Lei Li, and Yu-Xiang Wang.",
    "1493": "2023.",
    "1494": "Provable robust watermarking for ai-generated text.",
    "1495": "arXiv preprint arXiv:2306.17439 (2023).",
    "1496": "[104] Xuandong Zhao, Lei Li, and Yu-Xiang Wang.",
    "1497": "2022.",
    "1498": "Distillation-resistant watermarking for model protection in nlp.",
    "1499": "arXiv preprint arXiv:2210.03312 (2022).",
    "1500": "[105] Xuandong Zhao, Yu-Xiang Wang, and Lei Li.",
    "1501": "2023.",
    "1502": "Protecting language generation models via invisible watermarking.",
    "1503": "arXiv preprint arXiv:2302.03162 (2023).",
    "1504": "[106] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al .",
    "1505": "2023.",
    "1506": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.",
    "1507": "arXiv preprint arXiv:2306.05685 (2023).",
    "1508": "[107] Jiawei Zhou, Yixuan Zhang, Qianni Luo, Andrea G Parker, and Munmun De Choudhury.",
    "1509": "2023.",
    "1510": "Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions.",
    "1511": "In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>) (CHI ’23).",
    "1512": "Association for Computing Machinery, New York, NY, USA, Article 436, 20 pages.",
    "1513": "https://doi.org/10.1145/3544548.3581318",
    "1514": "[108] Jinhua Zhu, Yingce Xia, Lijun Wu, Di He, Tao Qin, Wengang Zhou, Houqiang Li, and Tie-Yan Liu.",
    "1515": "2020.",
    "1516": "Incorporating bert into neural machine translation.",
    "1517": "arXiv preprint arXiv:2002.06823 (2020)."
}