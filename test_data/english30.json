{
    "0": "Historically, their\ncapabilities and application scenarios were limited.",
    "1": "However, recent advancements in large language models\n(LLMs) have revolutionized these techniques.",
    "2": "LLMs not only enhance text watermarking algorithms with their\nadvanced text understanding and generation abilities but also create a need for employing these algorithms to\nprotect their own copyrights.",
    "3": "This paper presents a comprehensive survey of text watermarking technology\nin the LLM era, aiming to further its development and application.",
    "4": "CCS Concepts: •Security and privacy →Digital rights management ;•Computing methodologies →\nNatural language processing .",
    "5": "Additional Key Words and Phrases: Text Watermark, Large Language Models, Copyright Protection\nACM Reference Format:\nAiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Xi Zhang, Lijie Wen, Irwin King, Hui Xiong, and Philip\nS. Yu.",
    "6": "2024.",
    "7": "A Survey of Text Watermarking in the Era of Large Language Models.",
    "8": "1, 1 (January 2024), 35 pages.",
    "9": "https://doi.org/10.1145/nnnnnnn.nnnnnnn\n1 INTRODUCTION\nText watermarking involves embedding unique, imperceptible identifiers (watermarks) into textual\ncontent.",
    "10": "These watermarks are designed to be robust yet inconspicuous, ensuring that the integrity\nand ownership of the content are preserved without affecting its readability or meaning.",
    "11": "Historically,\ntext watermarking has played a crucial role in various domains, from copyright protection and\ndocument authentication to preventing plagiarism and unauthorized content distribution [ 32].",
    "12": "With\n∗Both authors contributed equally to this research.",
    "13": "Authors’ addresses: Aiwei Liu, liuaw20@mails.tsinghua.edu.cn; Leyi Pan, ply20@mails.tsinghua.edu.cn, Tsinghua University,\nBeijing; Yijian Lu, luyijian@link.cuhk.edu.hk; Jingjing Li, lijj@link.cuhk.edu.hk, The Chinese University of Hong Kong,\nHong Kong; Xuming Hu, xuminghu@hotmail.com, The Hong Kong University of Science and Technology (Guangzhou),\nGuangzhou; Xi Zhang, zhangx@bupt.edu.cn, Beijing University of Posts and Telecommunications, Beijing; Lijie Wen,\nwenlj@tsinghua.edu.cn, Tsinghua University, Beijing; Irwin King, king@cse.cuhk.edu.hk, The Chinese University of\nHong Kong, Hong Kong; Hui Xiong, xionghui@hkust-gz.edu.cn, The Hong Kong University of Science and Technology\n(Guangzhou), Guangzhou; Philip S. Yu, psyu@cs.uic.edu, University of Illinois Chicago, Chicago.",
    "14": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page.",
    "15": "Copyrights for components of this work owned by others than ACM must be honored.",
    "16": "Abstracting with credit is permitted.",
    "17": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee.",
    "18": "Request permissions from permissions@acm.org.",
    "19": "©2024 Association for Computing Machinery.",
    "20": "XXXX-XXXX/2024/1-ART $15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\n, Vol.",
    "21": "1, No.",
    "22": "1, Article .",
    "23": "Publication date: January 2024.arXiv:2312.07913v4  [cs.CL]  23 Jan 20242 Liu, et al.",
    "24": "Text Watermarking LLMs\nwatermarks\nLLMs\nenhance\nText Watermarking \nAlgorithmsText Watermarking \nAlgorithms\nWatermarks\nIntegrate in\nLLMsapply in\nLLMsText Watermarking \nAlgorithms\n(a) A description of how LLMs promote the development\nof text watermarking techniques and broaden their appli-\ncation scenarios.",
    "25": "2019 2020 2021 2022 2023 2024\nTime08162432404856Number of T ext Watermarking Publications\n 02505007501000125015001750\nNumber of Publications in the Field of LLMsT5 GPT-3CodexInstructGPTChatGPTLLaMAGPT-4T ext Watermarking\nLLMs(b) Number of publications in the field of text watermarking\nand LLMs (the data for \"Number of Publications in the field of\nLLMs\" is sourced from Zhao et al.",
    "26": "[102])\nFig.",
    "27": "1.",
    "28": "Relationships between the development of text watermarking techniques and Large Language\nModels (LLMs).",
    "29": "the advancement of Large Language Models (LLMs), both the techniques and application scenarios\nof text watermarking have seen significant development.",
    "30": "As shown in Figure 1(a), this primarily\nincludes the construction of enhanced text watermarking algorithms using LLMs, the application\nof existing text watermarking algorithms to LLMs, and the exploration of text watermarking\nalgorithms that are more closely integrated with LLMs.",
    "31": "The flourishing development of LLMs\nhas propelled a thriving research landscape within the realm of text watermarking, as depicted\nin Figure 1(b).",
    "32": "Especially with the advent of ChatGPT, text watermarking has notably surged\ninto a research fervor.",
    "33": "This paper surveys the interplay between LLMs and text watermarking,\nhighlighting their synergistic potential in the contemporary landscape of language models.",
    "34": "In the following content, we will separately discuss why text watermarking benefits the\napplication of LLMs (section 1.1), why utilizing LLMs can lead to the development of superior text\nwatermarking algorithms (section 1.2), and the contributions of this survey (section 1.3).",
    "35": "1.1 Why is Text Watermarking Beneficial for LLMs?",
    "36": "In recent years, large language models (LLMs) have made significant progress in the field of natural\nlanguage processing.",
    "37": "As the parameter count of these large language models continues to increase,\ntheir ability to understand and generate language has also substantially improved.",
    "38": "Notable examples\ninclude GPT [ 65], BART [ 40], T5 [ 67], OPT [ 99], LaMDA [ 81], LLaMA [ 84], and GPT4 [ 60].",
    "39": "These\nlarge language models have achieved excellent performance in a variety of downstream tasks,\nincluding machine translation [ 13,24,24,108], dialogue systems [ 29,53,73,81], code generation\n[58,59,86,91], and other tasks [ 41,42,80,101].",
    "40": "A recent work even suggests that GPT-4 is an early\n(yet still incomplete) version of an artificial general intelligence (AGI) system [7].",
    "41": "However, the utilization of Large Language Models (LLMs) introduces several challenges.",
    "42": "Primarily, their capacity for rapid, high-quality text generation may expedite the dissemination\nof misinformation [ 51].",
    "43": "Additionally, there are critical intellectual property concerns involving\nLLMs, encompassing both the copyright of training datasets [ 79] and the establishment of rights\nto impede knowledge extraction from LLMs [ 105].",
    "44": "Implementing effective tagging and detection\nmethods for LLM-generated text would substantially alleviate these problems.",
    "45": "Text watermarking\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 3\npresents as a viable approach to these challenges.",
    "46": "It involves embedding a discrete, identifiable\nmarker within LLM-produced text, enabling content tracking and origin attribution.",
    "47": "1.2 Why are LLMs Beneficial for Text Watermarking?",
    "48": "A key challenge in text watermarking is to embed watermarks without distorting the original text’s\nmeaning or readability.",
    "49": "Traditional methods often fail to modify text without altering its semantics\n[3,52,82].",
    "50": "The necessity for algorithms to comprehend and control text semantics contributes to\nthis difficulty.",
    "51": "However, Large Language Models (LLMs) significantly alter this landscape.",
    "52": "Due to\ntheir advanced grasp of language semantics and context, LLMs facilitate sophisticated watermarking\napproaches that embed watermarks with minimal impact on the text’s inherent meaning [ 1,98].",
    "53": "This integration results in more effective and subtle watermarking techniques, preserving the text’s\noriginal intent while embedding essential watermark features.",
    "54": "1.3 Why a Survey for Text Watermarking in the Era of LLMs?",
    "55": "Text watermarking technology and large language models can effectively enhance each other.",
    "56": "For instance, text generated by LLMs can be watermarked using text watermarking algorithms\n[6,57,64,70,92,93,95], or LLMs themselves can be utilized to embed watermarks in texts [ 1,98].",
    "57": "Additionally, watermark algorithms can be directly incorporated during the text generation process\nof LLMs [ 33,45,46,69,90,103].",
    "58": "However, comprehensive studies exploring text watermarking in\nthe era of LLMs are lacking.",
    "59": "Existing surveys predominantly focus on watermarking techniques\ndeveloped before the advent of LLMs [2, 32].",
    "60": "In this study, we present the first comprehensive survey of text watermarking algorithms\nin the context of large language models.",
    "61": "This survey encompasses a detailed definition of text\nwatermarking algorithms and explores the interrelations among various methods.",
    "62": "Recognizing the\ncomplexity and diversity of text watermarking technology, we examine the evaluation metrics for\nthese algorithms, focusing on success rate, robustness, impact on text quality, and unforgeability.",
    "63": "Moreover, we discuss current applications of text watermarking, such as copyright protection, fake\nnews detection, and academic integrity.",
    "64": "This survey aims to furnish researchers with an in-depth\nunderstanding of text watermarking algorithms, facilitating comparisons and contrasts among\ndifferent methods.",
    "65": "It also guides users interested in applying text watermarking technology by\nhelping them choose suitable algorithms under different application scenarios.",
    "66": "Organization of this survey .",
    "67": "This survey is structured as follows: Section 2 introduces text\nwatermarking definitions and key algorithm properties.",
    "68": "Section 3 and Section 4 address two primary\ntext watermarking categories: for existing text and for LLM-generated text.",
    "69": "Section 5 discusses\nevaluation metrics for these algorithms, including success rate, impact on text quality, robustness,\nand unforgeability.",
    "70": "Section 6 explores application scenarios, namely copyright protection, academic\nintegrity, and fake news detection.",
    "71": "Section 7 examines ongoing challenges and potential future\nresearch avenues in text watermarking.",
    "72": "The survey concludes in Section 8.",
    "73": "2 PRELIMINARIES OF TEXT WATERMARKING\nTo facilitate the introduction of various text watermarking algorithms as well as its evaluation\nmethods in subsequent sections, this section presents the definition of text watermarking algorithms\nand outlines the characteristics that an excellent text watermarking algorithm should possess.",
    "74": "The\ntaxonomy of text watermarking algorithms is also introduced in this section.",
    "75": "2.1 Text Watermarking Algorithms\nA text watermarking algorithm typically comprises two components: a watermark generator A,\nand a watermark detector D. The watermark generator Atakes a text xand a watermark message\nPublication date: January 2024.4 Liu, et al.",
    "76": "𝑤as inputs and outputs a watermarked text t, expressed as:\nA(x,𝑤)=t.",
    "77": "(1)\nThis watermarked text tis either an altered form of the original text xor a newly generated text in\nresponse to x, particularly in contexts like prompts for LLMs.",
    "78": "The watermark message, denoted as\n𝑤, can be a zero-bit watermark, signifying merely its presence or absence, or a multi-bit watermark,\nembedding detailed, customized information.",
    "79": "The phrase ‘watermark payload’ will henceforth\ndenote the information volume conveyed by 𝑤.",
    "80": "For the watermark detector D, its input is any text t, and its output is its predicted watermark\nmessage for the text, denoted as D(t)=𝑤.",
    "81": "If the output is None, it implies that the text contains\nno watermark information.",
    "82": "2.2 Key Characteristics of Text Watermarking Algorithms\nTo enhance the understanding of objectives in text watermarking algorithm design, this section\nhighlights the critical characteristics these algorithms should have.",
    "83": "These primarily include a high\nsuccess rate of watermark detection, minimal impact on text quality, robustness of the detector\nagainst text modifications, and unforgeability.",
    "84": "High success rate of watermark detection.",
    "85": "The high success rate of a watermark algorithm\nindicates that its detector Dcan accurately detect the generated watermark text t. For a zero-bit\nwatermark message, this accuracy is usually measured using binary classification.",
    "86": "When 𝑤consists\nof multiple bits, the evaluation commonly used is bit accuracy.",
    "87": "If a watermarking algorithm\nmaintains a high success rate at a large bit number, it implies that it possesses a high payload.",
    "88": "Low Impact on Text Quality.",
    "89": "LetA(x,None)represent the text generated without watermark.",
    "90": "When xis the target text, the output remains x.",
    "91": "In the context of a prompt for a LLM, it denotes the\nLLM’s output without watermark insertion.",
    "92": "An effective watermark algorithm minimally affects\ntext quality, satisfying the condition:\n∀𝑤𝑖,R(A( x,None),A(x,𝑤𝑖))<𝛿 (2)\nwhereRis a function evaluating text quality from multiple perspectives, as will be discussed in\nsection 5.𝛿represents a threshold.",
    "93": "If the difference in the evaluated scores of two texts is less than\nthis threshold, they are considered to be of similar quality.",
    "94": "Robustness to watermark removal attack.",
    "95": "We use an operation Uto denote the watermark\nremoval operations, which will be detailed in section 5.",
    "96": "If a watermarking algorithm is robust\nagainst watermark removal attacks, it should satisfy the following conditions:\n∀𝑤𝑖,∀t=A(x,𝑤𝑖), 𝑃(D(U( t))=𝑤𝑖)>𝛽.",
    "97": "(3)\nwhere𝛽is a threshold.",
    "98": "If the probability of correctly detecting a watermarked text after text\nmodification exceeds 𝛽, the algorithm is deemed sufficiently robust.",
    "99": "Unforgeability.",
    "100": "Unforgeability refers to the difficulty for a third party to counterfeit text\nwatermarks.",
    "101": "Typically, if the watermark’s generator Ais acquired by an attacker, the watermark\ncan certainly be forged.",
    "102": "Consequently, unforgeability primarily hinges on whether an attacker,\nlacking access toA, can still counterfeit the watermark.",
    "103": "This divides into two scenarios: the\nprivate detection scenario, where the attacker is devoid of the detector Dand limited to detecting\nwatermarks, and the public detection scenario, where the attacker possesses D.\nAlthough an ideal text watermarking algorithm should possess all four aforementioned charac-\nteristics, it is challenging to balance them.",
    "104": "Enhancing one aspect might impact performance in\nanother.",
    "105": "In subsequent sections, we will delve deeper into how different watermark algorithms\nstrike a balance among these characteristics.",
    "106": "Publication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 5\nText\nWatermarkingWatermarking\nfor Existing Text\n(§3)Format-based\nWatermarking\n(§3.1)Line/Word-Shift Coding (Brassil et al .",
    "107": "[6]), UniSpaCh\n(Por et al .",
    "108": "[64] ), Unicode Homoglyph Substitution\n(Rizzo et al.",
    "109": "[70]), EasyMark (Sato et al.",
    "110": "[72])\nLexical-based\nWatermarking\n(§3.2)Equimark (Topkara et al .",
    "111": "[83] ), DeepTextMark (Mun-\nyer and Zhong [57]), Context-aware Lexical Substi-\ntution (Yang et al .",
    "112": "[93] ), Binary-encoding Lexical\nSubstitution (Yang et al .",
    "113": "[92] ), Robust Multi-bit Wa-\ntermark (Yoo et al.",
    "114": "[95])\nSyntatic-based\nWatermarking\n(§3.3)NLW (Atallah et al .",
    "115": "[3]), WANE (Topkara et al .",
    "116": "[82] ),\nMA-NLW (Meral et al.",
    "117": "[52])\nGeneration-based\nWatermarking\n(§3.4)AWT (Abdelnabi and Fritz [1]), REMARK-LLM\n(Zhang et al.",
    "118": "[98])\nWatermarking\nfor LLMs\n(§4)Training Time\nWatermarking\n(§4.1)Dataset Trigger (Liu et al .",
    "119": "[48] ), Clean-Label Back-\ndoor Watermark (Tang et al .",
    "120": "[79] ), Coprotector (Sun\net al.",
    "121": "[75]), CodeMark (Sun et al.",
    "122": "[74])\nWatermarking During\nLogits Generation\n(§4.2)KGW (Kirchenbauer et al .",
    "123": "[33] ), SWEET (Lee et al .",
    "124": "[39]), Unbiased Watermark (Hu et al .",
    "125": "[28] ), DiPmark\n(Wu et al .",
    "126": "[90] ), COLOR (Yoo et al .",
    "127": "[96] ), CTWL\n(Wang et al .",
    "128": "[89] ), ThreeBricks (Fernandez et al .",
    "129": "[19]), Unigram Watermark (Zhao et al .",
    "130": "[103] ), KGW-\nreliability (Kirchenbauer et al .",
    "131": "[34] ), NS-Watermark\n(Takezawa et al .",
    "132": "[76] ), Semantic Invariant Robust Wa-\ntermark (Liu et al .",
    "133": "[46] ), Unforgeable Watermark (Liu\net al.",
    "134": "[45] ), Publicly Detectable Watermark (Fairoze\net al.",
    "135": "[16] ), Semantic-based Robust Watermark (Ren\net al.",
    "136": "[69])\nWatermarking During\nToken Sampling\n(§4.3)Undetectable Watermark (Christ et al .",
    "137": "[11] ), Robust\nDistortion-free Watermark (Kuditipudi et al .",
    "138": "[36] ),\nSemStamp (Hou et al.",
    "139": "[27]))\nFig.",
    "140": "2.",
    "141": "The text watermarking methods can be broadly divided into two categories: Watermarking\nfor Existing Text (section 3) and Watermarking for LLMs (section 4).",
    "142": "2.3 Taxonomy of Text Watermarking Algorithms\nTo facilitate the organization of different text watermarking algorithms in section 3 and section 4,\nthis section provides an overview of our summarized taxonomy of text watermarking algorithms.",
    "143": "Figure 2 categorizes text watermarking algorithms into two primary types.",
    "144": "The first, Water-\nmarking for Existing Text , embeds watermarks into pre-existing texts, as elaborated in Section 3.",
    "145": "This technique typically utilizes semantically invariant transformations for watermark integration.",
    "146": "The second type, Watermarking for Large Language Models , involves modifying LLMs,\nfurther detailed in Section 4.",
    "147": "This method either embeds specific features into the training dataset\nor alters the LLMs’ text generation process, producing watermarked text from the input prompt.",
    "148": "Figure 3 offers a detailed illustration of these methods, emphasizing the nuances of current\ntext watermarking techniques.",
    "149": "Notably, both the ‘watermarking during logits generation’ and\n‘watermarking during token sampling’ methods apply watermarks at the LLM inference stage, a\nprocess collectively referred to as ‘inference time watermarking’ in this context.",
    "150": "The dashed line\nbox under inference time watermarking represents the detailed process of how the watermarked\nLLM generates watermarked text.",
    "151": "3 WATERMARKING FOR EXISTING TEXT\nWatermarking for existing text involves modifying a generated text to produce a watermarked text.",
    "152": "Based on the granularity of modifications, these methods are primarily categorized into four types:\nPublication date: January 2024.6 Liu, et al.",
    "153": "Watermarking for Existing Text\nOriginal Text Watermarked TextWatermark Message\nNone\nWNone\n000 001\n010 011\n100 101\n110 111\nZero-bit Multi -bitThe stars shimmered in \nthe velvet night sky.The stars sparkled in the \nvelvet night sky.",
    "154": "In the velvet night sky, a \nshimmer was cast by the \nstars.a) Format -based b) Lexical -based\nc) Syntactic -basedThe velvet night embraced \nas stars shimmered, a \ncelestial ballet.",
    "155": "d) Generation -based\nThe stars shimmered \nin the velvet night sky.",
    "156": "Watermarking for LLMs\nLLMTraining Time \nWatermarking\nInference Time \nWatermarking\nTraining SetWatermark \nMessage\nWatermarked \nTraining SetWatermarked \nLLMTraining\nWatermarked \nText\nGenerating\nWatermarked \nNext Tokenprompt \n+ \nprevious \ntextLogits Generation Token SamplingWatermarked\nNext Token LogitsWatermark Message Watermark Message\n 𝑙\n𝑉\nNext Token \nLogits𝑙\n𝑉\nWatermarking during Logits Generation Watermarking during Token Sampling\nWatermarked Text\nFig.",
    "157": "3.",
    "158": "This figure offers a concise overview of various text watermarking techniques.",
    "159": "It categorizes\nwatermarking into two main types: for Existing Text and for Large Language Models (LLMs).",
    "160": "The\nformer (section 3) embeds watermarks in existing text using methods like format-based (section 3.1),\ne.g., white-space substitution; lexical-based (section 3.2), e.g., synonym substitution; syntactic-based\n(section 3.3), e.g., passivization; and generation-based (section 3.4), employing pretrained language\nmodels.",
    "161": "The latter (section 4) focuses on embedding watermarks in LLMs, ensuring their presence\nin generated text.",
    "162": "This can be achieved during training (section 4.1), logits generation (section 4.2),\nor token sampling (section 4.3).",
    "163": "format-based watermarking (section 3.1), lexical-based watermarking (section 3.2), syntactic-based\nwatermarking (section 3.3) and generation-based watermarking (section 3.4).",
    "164": "3.1 Format-based Watermarking\nFormat-based watermarking, drawing inspiration from image watermarking [ 4], alters text format\nrather than content to embed watermarks.",
    "165": "For example, Brassil et al .",
    "166": "[6]introduced line-shift coding\nand word shift-coding by vertically and horizontally adjusting text lines and words, respectively.",
    "167": "The detection process measures distances between text line profiles or word column profiles to\nidentify shifts.",
    "168": "However, this method is confined to image-formatted text and does not return a text\nstring with an embedded watermark.",
    "169": "To address this, Unicode codepoint insertion/replacement\nmethods have emerged.",
    "170": "Por et al .",
    "171": "[64] developed UniSpach , inserting Unicode space characters\nin various text spacings.",
    "172": "Rizzo et al .",
    "173": "[70] presented a unicode homoglyph substitution method,\nexploiting visually similar but differently coded text symbols (e.g., U+0043 and U+216d for ‘C’,\nU+004c and U+216c for ‘L’).",
    "174": "Following this, a family of simple watermarks named EasyMark\n[72] is proposed recently, composed of three different methods: WhiteMark ,VariantMark and\nPrintMark .",
    "175": "Specifically, WhiteMark replaces a whitespace (U+0020) with another codepoint\nof a whitespace (e.g.",
    "176": "U+2004).",
    "177": "VariantMark leverages variation selectors of Unicode to embed\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 7\nhard-to-perceive format into CJK texts.",
    "178": "PrintMark , coping with printed texts, uses ligature or\nwhitespaces with slightly different lengths to embed watermark messages.",
    "179": "Correspondingly, the\nwatermark detection process involves searching for and counting the certain codepoints that have\nbeen inserted within the text.",
    "180": "As these watermarking methods relied on the richness of Unicode\nencoding, their watermark payload is often quite large.",
    "181": "Despite the simplicity and effectiveness of format-based watermarking methods in embedding\nsubstantial payloads without altering textual content, their format modifications can be conspicuous\nunder certain conditions, as Por et al .",
    "182": "[64] noted with the DASH attack.",
    "183": "Consequently, these\nmodified formats are vulnerable to removal via canonicalization [ 5], involving techniques such\nas resetting line spacing and replacing specific codepoints throughout the text.",
    "184": "Moreover, these\ndetectable formats may be exploited for watermark forgery, compromising detection efficacy.",
    "185": "3.2 Lexical-based Watermarking\nFormat-based watermarking approaches, which only modify text’s superficial format, are prone\nto be spotted, making them easily removable through reformatting.",
    "186": "This highlights the need for\ninvestigating deeper watermark embedding methods in text.",
    "187": "A number of studies have adopted word-\nlevel modifications, where selected words are replaced with their synonyms without altering the\nsentence’s syntactic structure [ 18,57,83,92,93,95].",
    "188": "These are known as lexical-based watermarking\napproaches.",
    "189": "Topkara et al .",
    "190": "[83] introduced a synonym substitution method, employing WordNet\n[18] as the synonym source.",
    "191": "The watermark detection replicates the embedding process, applying\ninverse rules for message extraction.",
    "192": "Munyer and Zhong [57]enhanced semantic modeling by using\na pretrained Word2Vec model, converting selected words into vectors and identifying n-nearest\nvectors as replacement candidates.",
    "193": "They employed a binary classifier with a pretrained BERT\nmodel and transformer blocks for watermark detection.",
    "194": "The aforementioned watermarking methods relying on context-independent synonym substitu-\ntion (WordNet &Word2Vec ) often neglect the context of target words, potentially compromising\nsentence semantics and text quality.",
    "195": "To address this, context-aware lexical substitution has been\nincorporated into text watermarking.",
    "196": "Yang et al .",
    "197": "[93] introduced a BERT-based infill model for\ngenerating contextually appropriate lexical substitutions.",
    "198": "The watermark detection algorithm\nparallels the generation process, identifying watermark-bearing words, generating substitutes,\nand applying inverse rules for message extraction.",
    "199": "Yang et al .",
    "200": "[92] streamlined watermark de-\ntection by encoding each word with a random binary value and substituting bit-0 words with\ncontext-based synonyms representing bit-1.",
    "201": "As non-watermarked text adheres to a Bernoulli\ndistribution, altered during watermarking, statistical tests can effectively detect watermarks.",
    "202": "Yoo\net al.",
    "203": "[95] enhanced robustness against removal attacks by fine-tuning a BERT-based infill model\nwith keyword-preserving and syntactically invariant corruptions, achieving superior robustness\ncompared to earlier methods.",
    "204": "3.3 Syntactic-based Watermarking\nThe lexical-based methods aim to embed watermarks by substituting specific words, maintaining\nthe sentence’s syntax.",
    "205": "Yet, these approaches, relying exclusively on lexical substitution, might not\nbe robust against straightforward watermark removal tactics like random synonym replacement.",
    "206": "Consequently, several studies have explored embedding watermarks in a manner that resists removal,\nnotably by modifying the text’s syntax structure.",
    "207": "These methods are known as syntactic-based\nwatermarking approaches.",
    "208": "Atallah et al .",
    "209": "[3]introduced three typical syntax transformations– Adjunct\nMovement ,Clefting andPassivization –to embed watermark messages, where:\nPublication date: January 2024.8 Liu, et al.",
    "210": "•Adjunct Movement entails relocating adjuncts within a sentence.",
    "211": "Example: ‘often’ can be\nvariably positioned in The dog often chased the cat .",
    "212": "•Clefting emphasizes a sentence part, typically the subject.",
    "213": "For instance, The dog chased the\ncatbecomes It was the dog that chased the cat to accentuate the dog .",
    "214": "•Passivization changes active sentences with transitive verbs to passive voice.",
    "215": "For example,\nThe dog chased the cat is passivized to The cat was chased by the dog .",
    "216": "Each transformation type is assigned a unique message bit: Adjunct Movement to 0, Clefting to 1,\nandPassivization to 2.",
    "217": "In watermark detection, both original and altered texts are converted into\nsyntax trees, and their structures are compared for message extraction.",
    "218": "Expanding this concept,\nTopkara et al .",
    "219": "[82] introduced additional syntax transformations: Activization andTopicalization .",
    "220": "Moreover, research extends beyond English, with Meral et al .",
    "221": "[52] analyzing 20 morphosyntactic\ntools in Turkish, highlighting that languages with significant suffixation and agglutination, such as\nTurkish, are well-suited for syntactic watermarking.",
    "222": "While syntactic-based watermarking effectively embeds watermarks in a concealed manner, it\nheavily depends on a language’s grammatical rules, often requiring language-specific customization.",
    "223": "Frequent syntactic changes in some texts may also alter their original style and fluency.",
    "224": "3.4 Generation-based Watermarking\nThe aforementioned methods have indeed made significant strides in the field of text watermarking.",
    "225": "However, these methods are still quite reliant on specific rules, which may lead to unnatural\nmodifications in some contexts.",
    "226": "On one hand, the unnatural modifications might lead to degradation\nof text quality.",
    "227": "On the other hand, if these clues are observed by human attackers, there is a higher\nlikelihood of them to design watermark removal attacks or attempt to forge watermarks deliberately\nand specifically.",
    "228": "A groundbreaking advancement would be generating watermarked text directly\nfrom the original text and the watermark message.",
    "229": "With the rapid development of pretrained\nlanguage models, such techniques are gradually becoming feasible.",
    "230": "In the realm of generation-based\napproaches, the encoded original text and the watermark message are typically fed into a pretrained\nlanguage model, which subsequently generates the watermarked text end-to-end.",
    "231": "Abdelnabi and Fritz [1]developed AWT , an end-to-end watermarking scheme utilizing a\ntransformer encoder to encode sentences and merge sentence and message embeddings.",
    "232": "This\ncomposite is processed by a transformer decoder to generate watermarked text.",
    "233": "For watermark\ndetection, the text undergoes transformer encoder layers to retrieve the secret message.",
    "234": "Extending\nAWT , Zhang et al .",
    "235": "[98] identified disparities between the dense watermarked text distributions and\nsparse one-hot watermark encodings.",
    "236": "Addressing this, they proposed REMARK-LLM , employing\na pretrained language model for watermark insertion.",
    "237": "A key innovation is the reparameterization\nstep using Gumbel-Softmax [ 31] to yield sparser token distributions.",
    "238": "A transformer-based decoder\nextracts messages from these embeddings.",
    "239": "REMARK-LLM notably embeds double the signatures\nofAWT while maintaining detection efficacy, significantly enhancing watermark payload capacity.",
    "240": "4 WATERMARKING FOR LLMS\nIn the above section, we discussed watermarking methods for existing text.",
    "241": "With more and more\ntexts directly generated by large language models, studying text watermarking techniques for large\nmodels has become a trend.",
    "242": "Unlike the method of modifying existing text to add a watermark, the\nwatermarking for LLMs technology directly enables LLM-generated text to contain a watermark.",
    "243": "Specifically, given a watermark message 𝑤and a prompt x, the process of watermarking for LLMs\nis defined by the following expression:\nA(x,𝑤)=𝑀𝑤(x)=t.",
    "244": "(4)\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 9\nTo facilitate explanation, we assume that the watermarked text is directly generated by a language\nlanguage model 𝑀𝑤with an embedded watermark message.",
    "245": "To provide a better understanding of how to add a watermark to a Large Language Model, we\nfirst provide an overview of the process used for generating text with an LLM.",
    "246": "Specifically, this\ninvolves three steps, LLM training, logits generation and token sampling:\n•Step1: LLM Training.",
    "247": "This step involves training a large language model, M, with a dataset\nD. Training objectives vary based on the application, with next token prediction being the\nmost common [66].",
    "248": "•Step2: Logits Generation.",
    "249": "With the trained LLM M, given a prompt xand a sequence of\nprior tokens t0:(𝑖−1), the LLM predicts the next token t(𝑖)’s probability distribution in the\nvocabularyV, expressed as logits l(𝑖):\nl(𝑖)=𝑀(x,t0:(𝑖−1)).",
    "250": "(5)\n•Step3: Token Sampling.",
    "251": "The next token t(𝑖)is selected from l(𝑖), using methods like nucleus\nsampling [26], greedy decoding, or beam search.",
    "252": "The sampling process is denoted as:\nt(𝑖)=𝑆(softmax(l(𝑖))).",
    "253": "(6)\nThrough these steps, LLM M generates a token t(𝑖).",
    "254": "For multiple tokens, logits generation and\ntoken sampling are iteratively repeated.",
    "255": "In aligning with the three critical phases of text generation using Large Language Models (LLMs),\nwatermarking techniques for LLMs are similarly categorized into three distinct types.",
    "256": "These are:\nwatermarking at training time, during logits generation, and in the token sampling phase.",
    "257": "Detailed\ndiscussions of these watermarking methods are presented in sections 4.1, 4.2, and 4.3, respectively.",
    "258": "4.1 Watermarking during LLM Training\nThe objective of training time watermarking is to insert a watermark message, 𝑤, into a Large\nLanguage Model (LLM) during training phase.",
    "259": "This involves incorporating 𝑤into the training\ndataset𝐷.",
    "260": "The procedure starts with selecting a subset 𝐷𝑠from𝐷.",
    "261": "The watermark message is\nembedded in 𝐷𝑠using a watermark embedding function 𝑊, resulting in the watermarked subset\ne𝐷𝑠, where e𝐷𝑠=𝑊(𝐷𝑠,𝑤).",
    "262": "The watermarked dataset 𝐷𝑤is then constructed by combining the\noriginal dataset 𝐷withe𝐷𝑠, after removing 𝐷𝑠:\n𝐷𝑤=(𝐷\\𝐷𝑠)∪e𝐷𝑠 (7)\nAn LLM trained on 𝐷𝑤integrates the watermark 𝑤, yielding a model 𝑀𝑤.",
    "263": "This model displays\ncharacteristics of 𝑤when used on data resembling e𝐷𝑠, facilitating watermark detection.",
    "264": "The critical element in this process is designing the embedding function 𝑊, particularly\ntransforming 𝐷𝑠intoe𝐷𝑠.",
    "265": "Current strategies for crafting 𝑊are largely inspired by backdoor attack\nconcepts, where a specific trigger in the training set e𝐷𝑠=(𝑥,𝑦)is embedded in input 𝑥to create a\ndetectable output feature.",
    "266": "Depending on the trigger’s impact on the original label 𝑦, these methods\nare broadly categorized into two types.",
    "267": "The first category involves inserting a trigger into x, altering the corresponding label y.",
    "268": "For\nexample, Liu et al .",
    "269": "[48] introduced a watermark algorithm for text classification, inserting triggers\nat character, word, or sentence levels in a text subset, uniformly changing their labels to a specific 𝑦𝑡.",
    "270": "Sun et al .",
    "271": "[75] applied a similar strategy in code generation, using word or sentence-level triggers\nand code corrupting.",
    "272": "While these methods effectively detect models with trigger-incorporated text,\nthey may degrade the model’s performance by compromising label integrity.",
    "273": "To mitigate label distortion, alternative approaches are employed.",
    "274": "Tang et al .",
    "275": "[79] used adversarial\nlearning to identify and trigger-mark samples within category C without changing their labels.",
    "276": "For\nPublication date: January 2024.10 Liu, et al.",
    "277": "𝑙\n𝑉 𝑙\n𝑉LLM Logits Watermarked LLM LogitsWatermark Generator\nAdd \nwatermarkWatermark Detector\nRed/green \ncategorization CountWatermarked \nor NotSample Token\nLLMGenerate\nInput\nFig.",
    "278": "4.",
    "279": "A more illustrative description of the KGW [33] algorithm.",
    "280": "code generation, Sun et al .",
    "281": "[74] performed semantically invariant code transformations, such as\nsyntactic sugar variations, facilitating trigger detection in varied code styles.",
    "282": "The primary goal of\ntraining time watermarking is to safeguard dataset copyrights against unauthorized use.",
    "283": "Despite its ability to embed watermarks in LLMs, Training Time Watermarking has notable\ndrawbacks.",
    "284": "The watermarked LLM 𝑀𝑤generates watermarked outputs only for specific inputs.",
    "285": "The watermark payload is limited, mainly serving as an indicator rather than conveying extensive\ninformation.",
    "286": "Modifying the watermark message 𝑤usually necessitates model retraining, a resource-\nintensive task.",
    "287": "Hence, the application scope of Training Time Watermarking is relatively restricted.",
    "288": "4.2 Watermarking during Logits Generation\nWatermarking during logits generation refers to the insertion of a watermark message 𝑤into the\nlogits generated by LLMs.",
    "289": "This technique, which does not require modifying the LLM parameters,\nis more versatile and cost-effective than training time watermarking methods.",
    "290": "In this context, the watermarking algorithm Aalters the logits from the LLM to incorporate the\nwatermark message 𝑤.",
    "291": "The modified logitsfl(𝑖)can be computed as follows:\nfl(𝑖)=A(𝑀(x,t0:(𝑖−1)),𝑤)=𝑀𝑤(x,t0:(𝑖−1)), (8)\nwherefl(𝑖)is assumed to be produced by a watermarked LLM 𝑀𝑤.",
    "292": "Kirchenbauer et al .",
    "293": "[33] introduced the first LLM watermarking technique based on logits\nmodification, termed KGW.",
    "294": "This method partitions the vocabulary into a red list (R) and a green list\n(G) at each token position, using a hash function that depends on the preceding token.",
    "295": "As depicted\nin Figure 4, for the 𝑖𝑡ℎtoken generation by 𝑀𝑤, a bias𝛿is applied to the logits of tokens in G. The\nadjusted logit value,fl(𝑖)\n𝑗, for a token 𝑣𝑗at position𝑖is calculated as follows:\nfl(𝑖)\n𝑗=𝑀𝑤(x,t0:(𝑖−1))=\u001a𝑀(x,t0:(𝑖−1))[𝑗]+𝛿, 𝑣𝑗∈𝐺\n𝑀(x,t0:(𝑖−1))[𝑗], 𝑣𝑗∈𝑅(9)\nThis algorithm biases towards green tokens, leading to a higher proportion in watermarked texts.",
    "296": "The detector categorizes each token as red or green using the hash function and calculates the\ngreen token ratio with the z-metric, defined as:\n𝑧=(|𝑠|𝐺−𝛾𝑇)/√︁\n𝑇𝛾(1−𝛾) (10)\nwhere T is the length of the text, 𝛾is the ratio of the green list.",
    "297": "A text exceeding a certain green\ntoken threshold is deemed watermarked.",
    "298": "KGW’s detection method showed low false positive (< 3×10−3%) and false negative (< 1%) rates\nin tests.",
    "299": "Yet, real-world application challenges necessitate further optimization and design.",
    "300": "The\nfollowing outlines four representative scenarios, with improvements and explorations in watermark\nalgorithms, depicted in Figure 5.",
    "301": "Publication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 11\n4.2.1 Watermarking low-entropy text.",
    "302": "In low-entropy scenarios, such as code or formatted\ndocument generation, text is typically deterministic.",
    "303": "Entropy, measuring textual uncertainty, is\ncalculated as follows, where 𝑃(𝑖)\n𝑗denotes the probability of token 𝑣𝑗at position𝑖:\n𝐻(𝑖)=−|V|∑︁\n𝑗=1𝑃(𝑖)\n𝑗log𝑃(𝑖)\n𝑗, (11)\nLower entropy implies higher text predictability.",
    "304": "Watermarking in such contexts is challenging due\nto the need of minimal text alterations.",
    "305": "Lee et al .",
    "306": "[39] proposed calculating entropy before modifying logits of green tokens (set G in\nEquation 9).",
    "307": "If 𝐻(𝑖)falls below a threshold 𝐻, logits are kept unchanged.",
    "308": "Likewise, Wang et al .",
    "309": "[89]\nintroduced a balance-marking strategy, limiting vocabulary choices to subsets with cumulative log\nprobabilities above a specific level.",
    "310": "This method focuses on watermarking high-entropy tokens\nwhile avoiding low-entropy ones.",
    "311": "For example, in cases with a single word candidate, the subset is\nrestricted to this candidate.",
    "312": "These methods [ 39,89], by factoring in text entropy, minimize impact\non text quality.",
    "313": "However, watermarking remains problematic in texts with few high-entropy tokens.",
    "314": "4.2.2 Watermark with multi-bit payload.",
    "315": "The KGW watermark algorithm [ 33], as defined\nin Equation 9, can only verify watermark presence, classifying it as a zero-bit watermark.",
    "316": "Yet,\nmany applications require watermarks to convey additional information like copyright details,\ntimestamps, or identifiers, leading to the need for multi-bit watermarks capable of extracting\nmeaningful data.",
    "317": "To achieve this, one possible solution involves multiple vocabulary divisions into red and\ngreen lists, creating N types of splits [(𝐺1,𝑅1),...,(𝐺𝑁,𝑅𝑁)].",
    "318": "Each split corresponds to a distinct\nwatermark message, offering a 𝑙𝑜𝑔2𝑁-bit payload.",
    "319": "For example, Wang et al .",
    "320": "[89] allows inputting\na𝑙𝑜𝑔2𝑁-bit watermark message 𝑚, with the vocabulary division based on the hash value of 𝑚.",
    "321": "However, this approach is inefficient during detection, requiring iteration over all 𝑁messages to\ncalculate text correlation with each split.",
    "322": "To address this, Fernandez et al .",
    "323": "[19] proposed the Cyclic\nShift method to enhance efficiency, generating different messages by cyclically shifting an initial\none, allowing parallel processing.",
    "324": "Nonetheless, these methods face increased computational complexity with larger watermark\npayloads due to the necessity of iterating each possible message.",
    "325": "To mitigate this, Yoo et al .",
    "326": "[96]\nsuggested assigning different message bits to distinct text positions, facilitating simultaneous bit\ndetection.",
    "327": "The message 𝑚is modeled as a sequence 𝑚=Σ𝑏with Σ={0,1}.",
    "328": "Vocabulary division\nat each step involves selecting a message position Σ𝑏[𝑖]based on the existing random seed, then\ndividing the vocabulary based on the selected Σ𝑏[𝑖].",
    "329": "This method improves efficiency by enabling\nparallel bit detection.",
    "330": "Additionally, Yoo et al .",
    "331": "[96] recommended dividing the vocabulary into more\nsegments, so each position Σ𝑏[𝑖]in𝑚holds more data, increasing the watermark’s payload.",
    "332": "4.2.3 Preventing watermark removal attack.",
    "333": "As discussed in section 2, an effective watermark-\ning algorithm must possess sufficient robustness against watermark removal attacks, ensuring that\nthe watermark text remains detectable after an attack.",
    "334": "These attacks typically involve modifications\nto the text without altering its semantic content, which will be introduced in section 5.3.",
    "335": "Although\nthe KGW algorithm [ 33] demonstrated some robustness to watermark removal attacks in their\nexperiments, there remains room for improvement in its robustness.",
    "336": "For watermarking during logits generation [ 33,34,45,46,103], the pivotal factor for robustness\nlies in the methodology used for modifying logits, especially the red-green list division in KGW\n[33].",
    "337": "The original KGW utilizes the hash values of preceding tokens for this division.",
    "338": "Kirchenbauer\net al.",
    "339": "[34] further elaborated on some specific hash strategies, such as using only the token with the\nPublication date: January 2024.12 Liu, et al.",
    "340": "Global HashingWatermarking Low -Entropy Text Watermark with Multi -bit Payload\nPreventing Watermark Removal Attack Defending Against Watermark Forgeries𝑙\n𝑉\n𝐻>𝐻𝑡ℎ𝑟𝑒𝑠\n 𝑙\n𝑉no\nyes①Multiple Red/Green Splits ②Position Allocation + Multi -color Split\n𝑙\n𝑉\nskGenerator\nDetector\npkDetector\nAPIConceal \nWatermark\nUnbiased Logits \nModificationWatermark \nis Spotted no\nyes\nRestricted \nDetection\nAsymmetric \nAlgorithmsNo Forgery Risk\nSemantic HashingMessage001122120Position Allocation\n01\n00\n10VoteAllocated Textw.00\nw.01\nw.10Detect\nPosition\n0\n1\n2\nAnyInput Text…𝑉\n…𝑉MinHashing\n…𝑉\nInput Text Embedding…𝑉…𝑉\n5421 1Min…𝑉\nFig.",
    "341": "5.",
    "342": "Demonstration of how various methods improve upon KGW [ 33] to adapt to four scenarios:\nWatermarking Low-entropy Text, Watermark with Multi-bit Payload, Preventing Watermark\nRemoval Attack, and Defending against Watermark Forgeries.",
    "343": "smallest token id in previous tokens for hashing to decide the red-green list, which can enhance\nrobustness.",
    "344": "Zhao et al .",
    "345": "[103] proved that a fixed global split of red and green lists offers greater\nresistance to removal attacks.",
    "346": "Additionally, as watermark removal attacks usually preserve the\nsemantic content of the text, several studies have developed methods to determine the red-green\nlist split based on textual semantics.",
    "347": "For example, Liu et al .",
    "348": "[46] trained a watermark model that\ncan directly convert text semantic embeddings into watermark logits.",
    "349": "Ren et al .",
    "350": "[69] converted\nsemantic embeddings into semantic values through weighted embedding pooling followed by\ndiscretizing using NE-Ring, and then divided the vocabulary into red-list and green-list based on\nthese semantic values.",
    "351": "The current methods primarily focus on investigating the robustness of\nzero-bit watermark algorithms against watermark removal attacks.",
    "352": "Future algorithms could delve\ninto exploring the robustness of multi-bit payload watermark algorithms.",
    "353": "4.2.4 Defendingagainstwatermarkforgeries.",
    "354": "In the previously discussed watermark algorithms’\nresilience to removal attacks, it is assumed that the attacker operates in a black-box scenario,\nlacking knowledge about the details and generation methods of the watermark.",
    "355": "If an attacker\nacquires this information, removing or forging the watermark becomes trivial [ 34].",
    "356": "Consequently,\nthe ability of watermark algorithms to withstand forgeries is crucial.",
    "357": "The ability to defend against\nforgeries depends on the watermark algorithm’s capacity to effectively conceal its watermark\ngeneration process.",
    "358": "If a watermark algorithm yields imperceptible watermarked text, where imperceptible means\nindistinguishable distribution between watermarked and unwatermarked texts, it becomes more\nchallenging to forge.",
    "359": "Hu et al .",
    "360": "[28] noted that the KGW algorithm [ 33] introduces bias in its\nlogits modification, compromising imperceptibility.",
    "361": "Imperceptibility here implies that the expected\nwatermarked logits equal the original model’s logits:\nE\n𝑘∼𝐾[𝑀𝑤(x,t0:(𝑖−1))]=𝑀(x,t0:(𝑖−1)), (12)\nwhere each key 𝑘represents a unique red-green list split.",
    "362": "The bias in KGW arises from applying a\nuniform𝛿to green list tokens, disproportionately affecting low-probability tokens, leading to bias.",
    "363": "Publication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 13\nTo counter this, Hu et al .",
    "364": "[28] introduced two unbiased reweighting methods: 𝛿-reweight, sampling\na one-hot distribution from original logits, and 𝛾-reweight, which halves the probability distribution\nrange, doubling the remaining tokens’ probabilities.",
    "365": "Similarly, Wu et al .",
    "366": "[90] proposed the 𝛼-reweight\nmethod, discarding tokens with probabilities below 𝛼and adjusting the rest.",
    "367": "These methods,\ntheoretically unbiased, improve imperceptibility over KGW.",
    "368": "However, unbiased distributions may\nnot ensure imperceptibility, as variances in distributions with identical expectations can differ.",
    "369": "Further research is needed to ascertain true imperceptibility in these algorithms.",
    "370": "The capability of watermark algorithms to defend against watermark forgeries cannot be solely\nbased on the imperceptibility of the watermark.",
    "371": "It is also crucial that these algorithms robustly\nprotect watermark rules from being deciphered.",
    "372": "In this context, we differentiate between two\nscenarios: private detection and public detection.",
    "373": "Private detection allows watermark verification\nsolely via an API, whereas public detection involves open-access watermark detector details.",
    "374": "In\nprivate scenarios, the watermark algorithm’s complexity is critical for preventing forgeries.",
    "375": "For\nexample, Zhao et al .",
    "376": "[103] used a fixed red-green list split for watermark logits, a simplistic approach\nvulnerable to statistical analysis [ 71].",
    "377": "In contrast, Liu et al .",
    "378": "[46] leveraged semantic information,\nmaking rule extraction from watermarked texts significantly harder due to varying complexities.",
    "379": "In the context of public detection scenarios, resisting watermark forgeries becomes significantly\nmore challenging.",
    "380": "This difficulty arises because attackers can access the watermark detectors.",
    "381": "For methods where the watermark generation details are involved in detection (i.e.",
    "382": "the hash key\nin KGW) [ 33,34,46,103], exposing the watermark generator leads to a complete inability to\nresist watermark forgeries.",
    "383": "To address this issue, Fairoze et al .",
    "384": "[16] have utilized digital signature\ntechnology from the field of cryptography.",
    "385": "This approach involves generating watermarks using a\nprivate key and verifying them with a public key.",
    "386": "However, the verification via public key relies\non features extracted from the text and users can still exploit these features to forge watermarks.",
    "387": "Further advancing this field, Liu et al .",
    "388": "[45] proposed the use of neural networks for watermark\ndetection.",
    "389": "Due to the black-box nature of neural networks, the details of watermark generation are\nnot exposed, which could defend against watermark forgeries in public detection scenarios.",
    "390": "4.3 Watermarking during Token Sampling\nThe previous section primarily focused on incorporating watermarks during the logits generation\nphase for Large Language Models.",
    "391": "In this section, we will introduce a technique of watermarking\nduring token sampling, which does not alter the logits but utilize watermark message to guide the\nsampling of each token.",
    "392": "The main advantage of this method is unbiased text generation, which\nminimally affects text quality and offers an initial defense against watermark forgery.",
    "393": "The principle of incorporating watermarks during the token sampling phase is derived from\nthe randomness inherent in token sampling.",
    "394": "In this scenario, watermarks can be introduced\nusing a fixed random seed, where a pseudo-random number generator produces a sequence of\npseudo-random numbers to guide the sampling of each token.",
    "395": "For watermark detection, it is\nonly necessary to assess the alignment between the text tokens and the pseudo-random numbers,\nspecifically evaluating whether the choice of each token in the text matches with the corresponding\nvalue in the random number sequence.",
    "396": "For instance, Christ et al .",
    "397": "[11] use binary representation for\neach word in the vocabulary, with the pseudo-random numbers represented as a series of values\n𝑢∈[0,1].",
    "398": "This facilitates the sampling process using the pseudo-random numbers.",
    "399": "Specifically, if\nthe predicted probability for a certain position exceeds the corresponding pseudo-random number,\nthen 1 is sampled at that position, otherwise 0.",
    "400": "In the detection of watermarks, it can be determined\nwhether the values of the pseudo-random numbers corresponding to the positions with 1 in the\nbinary tokens are significantly higher than those with 0.",
    "401": "However, this method still faces two\nchallenges: 1) the detection algorithm is not robust enough against watermark removal attacks,\nPublication date: January 2024.14 Liu, et al.",
    "402": "which involves certain text modifications, and 2) due to the fixed nature of pseudo-random numbers,\nthe LLM with watermark will generate the same text for the same prompt each time, thereby losing\nthe inherent randomness in text generation by LLM.",
    "403": "To address these issues, Kuditipudi et al .",
    "404": "[36] proposed the use of a pseudo-random number\nsequence significantly longer than the text, randomly selecting a starting position from the\nsequence for each watermark insertion to introduce randomness.",
    "405": "Additionally, during watermark\ndetection, they incorporate a soft notion of edit distance (i.e., Levenshtein distance) into the\ncomputation of the alignment between text and the pseudo-random number sequence.",
    "406": "This\napproach significantly enhances the robustness of the watermarking algorithm against watermark\nremoval attacks.",
    "407": "Apart from intervening in the sampling process of each token one by one, Hou et al .",
    "408": "[27] suggested incorporating watermarks during sentence-level sampling.",
    "409": "The algorithm initially\npartitions the semantic embedding space into a watermarked region and a non-watermarked\nregion, and then performs sentence-level rejection sampling until the sampled sentence falls within\nthe watermarked region.",
    "410": "Since the partition principles are based on sentence-level semantics,\nthis approach significantly enhances robustness against watermark removal attacks such as\nparaphrasing.",
    "411": "Current research in token-sampling watermarking is limited, indicating room for\nadvancement.",
    "412": "The effectiveness and robustness of these methods warrant further exploration\nthrough experiments and real-world applications.",
    "413": "5 EVALUATION METRICS FOR TEXT WATERMARKING\nIn Sections 3 and 4, we presented a detailed overview of existing text watermarking techniques.",
    "414": "A thorough evaluation of a text watermarking algorithm is essential.",
    "415": "This section outlines the\nevaluation metrics from multi perspectives: success rate, text quality, robustness, and unforgeability.",
    "416": "Among these, success rate (Section 5.1) measures the accuracy of detecting watermarked texts.",
    "417": "Text quality (Section 5.2) evaluates the integrity of watermarked text in comparison to its original\nform.",
    "418": "Robustness (Section 5.3) assesses the detectability of watermarks after removal attacks.",
    "419": "Unforgeability (Section 5.4) considers the difficulty in counterfeiting the watermark.",
    "420": "Additionally,\nTable 1 outlines the alignment between various text watermarking algorithms discussed in the\nsurvey and the evaluation perspectives they contribute to.",
    "421": "5.1 Success Rate\nFor a text watermarking algorithm, the fundamental requirement is that the watermarked text\ncould be detected with a high probability.",
    "422": "In this section, we consolidate how current watermarking\nalgorithms measure their success rate.",
    "423": "Based on the amount of information carried by the\nwatermarking algorithm, we will introduce it in two scenarios: zero-bit and multi-bit.",
    "424": "5.1.1 Zero-bit Watermark.",
    "425": "In zero-bit watermarking, the algorithm discerns the presence of a\nwatermark in text but cannot extract additional information.",
    "426": "This detection essentially constitutes\na binary classification problem, evaluating whether text is watermarked.",
    "427": "Classification metrics like\naccuracy and F1 score are typically used for evaluation.",
    "428": "In many studies [ 33,45,46,103], given the\nequal distribution of watermarked and non-watermarked texts in test datasets, accuracy and F1 score\nvalues are often comparable.",
    "429": "However, F1 score, along with false positive and false negative rates,\nis more frequently employed [ 33,45,103].",
    "430": "False positives signify misclassifying non-watermarked\ntexts as watermarked, and false negatives involve incorrectly identifying watermarked texts as\nnon-watermarked.",
    "431": "False positives are critical due to misidentifying human-generated texts as\nwatermarked can lead to more adverse consequences.",
    "432": "Nevertheless, the reliance on a threshold for determining F1 or accuracy introduces comparability\nchallenges among algorithms.",
    "433": "Some studies [ 46,103] report F1 scores at fixed false positive rates of\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 15\nTable 1.",
    "434": "Relationships between text watermarking algorithms covered in the survey and the\nevaluation metrics, featuring the individual objectives each text watermarking algorithm aims to\nachieve.",
    "435": "▲stands for basic objectives, •stands for primary objectives, and ◦stands for secondary\nobjectives.",
    "436": "Text Watermarking Algorithms Objectives\nWatermarked\nObjectCategory MethodSuccess Rate\nText Quality Robustness Unforgeability\nDetection Accuracy Payload\nExisting Text\n(§3)Format-based\n(§3.1)Line/Word-Shift Coding [6] ▲ •\nUniSpach [64] ▲• •\nUnicode Homoglyph Substitution [70] ▲• •\nEasyMark [72] ▲• •\nLexical-based\n(§3.2)Equimark [83] ▲ • ◦\nDeepTextMark [57] ▲ • •\nContext-aware Lexical Substitution [93] ▲◦ • ◦\nBinary-encoding Lexical Substitution [92] ▲ ◦ ◦\nRobust Multi-bit Watermark [95] ▲◦ ◦ •\nSyntatic-based\n(§3.3)NLW [3] ▲ •\nWANE [82] ▲• ◦ •\nMA-NLW [52] ▲• ◦ ◦\nGeneration-based\n(§3.4)AWT [1] ▲ • •\nREMARK-LLM [98] ▲• ◦ ◦\nLLMs\n(§4)Training Time\n(§4.1)Dataset Trigger [48] ▲ •\nClean-Label Backdoor Watermark [79] ▲ •\nCoprotector [75] ▲ •\nCodeMark [74] ▲ •\nLogits Generation\n(§4.2)KGW [33] ▲ •\nSWEET [39] ▲ •\nUnbiased Watermark [28] ▲ • ◦ •\nDiPmark [90] ▲ • ◦ •\nCOLOR [96] ▲• ◦\nCTWL [89] ▲• • ◦ •\nThreeBrick [19] ▲ ◦\nUnigram Watermark [103] ▲ •\nKGW-reliability [34] ▲ •\nNS-Watermark [76] ▲ • ◦\nSemantic Invariant Robust Watermark [46] ▲ ◦ • •\nUnforgeable Watermark [45] ▲ ◦ ◦ •\nPublicly Detectable Watermark [16] ▲ ◦ ◦ •\nSemantic-based Robust Watermark [69] ▲ ◦ •\nToken Sampling\n(§4.3)Undetectable Watermark [11] ▲ • ◦ •\nRobust Distortion-free Watermark [36] ▲ • • •\nSemStamp [27] ▲ ◦ •\n1% and 10%, while others [ 46] present optimal F1 scores across all thresholds for a fair comparison.",
    "437": "Additionally, hypothesis testing methods are used to calculate the p-value as a key success rate\nmetric.",
    "438": "Different algorithms employ varying hypotheses for p-value computation.",
    "439": "For instance,\nKirchenbauer et al .",
    "440": "[33] assess if the calculated z-score surpasses a threshold, whereas Kuditipudi\net al.",
    "441": "[36] hypothesizes that the key generating the watermark text detects the watermark with\nhigher probability than random keys.",
    "442": "This approach, not requiring a predefined threshold, needs\nmultiple detection runs, potentially slowing detection speed.",
    "443": "5.1.2 Multi-bit Watermark.",
    "444": "In multi-bit watermarking methods [ 1,70,89,93,95,96], the focus\nextends beyond merely detecting watermarks to extracting detailed watermark message.",
    "445": "For\nexample, a watermarked text may encode specific data, such as \"This text is generated by GPT-4 on\nJune 6 by the Administrator\" [89].",
    "446": "Evaluating the efficacy of multi-bit watermarks involves not\nonly assessing accuracy in information retrieval but also considering the watermark’s payload, the\nnumber of bits in the watermark message.",
    "447": "Publication date: January 2024.16 Liu, et al.",
    "448": "Consider watermark message 𝑤encoded in𝑛bits, represented as 𝑤=𝑏1𝑏2...𝑏𝑛, where each\n𝑏𝑖is binary.",
    "449": "The prevalent metrics for success rate evaluation are the bit error rate (BER) [ 95],\nindicating the likelihood of erroneous bit predictions, and bit accuracy [ 1,96], the rate of correct\nbit predictions.",
    "450": "These metrics are complementary.",
    "451": "BER is usually calculated for a fixed bit number;\nas the number of bits increases, BER tends to rise, potentially reaching 50% (random).",
    "452": "Therefore, the bit capacity, or payload, of a watermark algorithm is a critical evaluation metric,\nknown as Bits Per Watermark [ 93,95] or code rate [ 70,89].",
    "453": "Payload is calculated by dividing the\ntotal bit count of the watermark information by the number of tokens.",
    "454": "The payload of a watermark\nalgorithm has an upper limit, with enhancements often compromising text quality (section 5.2) or\nrobustness (section 5.3).",
    "455": "Furthermore, the payload is context-dependent: higher entropy scenarios\nyield greater payloads, whereas lower entropy scenarios result in smaller payloads.",
    "456": "5.2 Text Quality\nIn section 2, we demonstrated that an essential characteristic of text watermarking technology is its\nlow-impact on text quality.",
    "457": "This means that the quality scores of texts, with or without watermarks,\nshould be similar under the text quality evaluation function Ras described in Equation 2.",
    "458": "This\nsection primarily introduces potential forms of the text quality evaluation function R. Current text\nwatermarking research predominantly assesses text quality using methods like perplexity values\n[28,33,45,46,89,90,92,103], semantic score [ 1,57,92,93,95,98], performance evaluations for\nspecific tasks [28, 39, 74, 82, 90, 92, 98], or text diversity [34].",
    "459": "5.2.1 Perplexity.",
    "460": "Perplexity (PPL) is defined as the exponentiated average negative log-likelihood\nof a sequence.",
    "461": "Specifically, given a text 𝑊=𝑤1,...,𝑤𝑁, the PPL can be computed using an LLM M:\nRPPL(𝑊)=exp \n−1\n𝑁𝑁∑︁\n𝑖=1logM(𝑤𝑖|𝑤1,...,𝑤𝑖−1)!",
    "462": ".",
    "463": "(13)\nPerplexity is an effective metric for assessing the consistency and fluency of text.",
    "464": "Generally, a\nlower PPL indicates higher text quality.",
    "465": "Typically, larger LLMs are employed to compute PPL for\nmore accurate assessments, examples of which include GPT2[ 92], GPT-3 [ 103], OPT2.7B [ 33,89],\nLLaMA-13B [45, 46], among others.",
    "466": "Watermarked texts typically exhibit higher PPL, reflecting a quality reduction.",
    "467": "The higher\nthe watermark strength, the more evident the decline in text quality.",
    "468": "For example, in the KGW\nalgorithm [ 33], an increased 𝛿value noticeably affects text quality.",
    "469": "Takezawa et al .",
    "470": "[76] recommend\nusing lower watermark strength for longer texts to mitigate quality degradation while preserving\nwatermark efficacy.",
    "471": "5.2.2 Semantic Score.",
    "472": "Although text perplexity facilitates the evaluation of textual consistency\nand fluency, it could not assess the accuracy of watermarked texts, specifically in terms of\nsemantic consistency between watermarked and non-watermarked text.",
    "473": "Consequently, some\nstudies employ semantic scores, which measure the semantic similarity between watermarked and\nnon-watermarked texts, to evaluate the impact of watermarking algorithms on text quality.",
    "474": "The most commonly utilized method for assessing semantic scores involves the computation\nof semantic embeddings by Large Language Models (LLMs), followed by the comparison of these\nembeddings using cosine similarity.",
    "475": "This process can be represented by the following formula:\nRse(𝑊𝑢,𝑊𝑤)=M(𝑊𝑢)·M(𝑊𝑤)\n∥M(𝑊𝑢)∥×∥M(𝑊𝑤)∥, (14)\nwhere𝑊𝑢and𝑊𝑤respectively represent the text without watermark and the text with watermark.",
    "476": "The modelMis typically an LLM that has been optimized specifically for text similarity.",
    "477": "For\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 17\ninstance, Munyer and Zhong [57]have used the Universal Sentence Encoder [ 8], whereas Abdelnabi\nand Fritz [1], Yang et al .",
    "478": "[93] , Yoo et al .",
    "479": "[95] have employed Sentence-BERT [ 68], and Yang et al .",
    "480": "[92] have utilized all-MiniLM-L6-v21.",
    "481": "Most watermarking algorithms could achieve a semantic\nsimilarity between the watermarked text and the original text (without watermark) above 0.9.",
    "482": "Additionally, the achievable semantic scores in these works are still correlated with the watermark\nstrength (degree of textual modification), indicating that lower watermark strength correlates with\nhigher semantic scores.",
    "483": "While the text embedding based evaluation method could effectively captures the overall semantic\nsimilarity, it falls short in delving into the semantic nuances at a detailed level.",
    "484": "Consequently, Yoo\net al.",
    "485": "[95] have further employed RoBERTa-Large-NLI [ 68] for a more precise understanding and\ninference of complex semantic relations between texts (Entailment Score, ES).",
    "486": "RoBERTa-Large-NLI\nis pre-trained on Natural Language Inference (NLI) tasks and focuses not only on the overall\nsimilarity between two texts but also discerns subtle semantic differences.",
    "487": "In actual experiments,\nthe ES values generally tend to be lower than text embedding similarities.",
    "488": "Although semantic scores assessment based on Natural Language Inference (NLI) offers an\nin-depth semantic analysis, it might still struggle to accurately capture variations at the level of\nindividual words or phrases.",
    "489": "To address this, Zhang et al .",
    "490": "[98] employed BERT-Score [ 100] for\na word-level detailed comparison of texts.",
    "491": "BERT-Score is more adept at evaluating whether the\nwatermark has altered specific vocabulary or expressions in the original text.",
    "492": "5.2.3 Task-specified Evaluation.",
    "493": "Although the assessment method based on semantic scores\ncould effectively evaluate whether adding watermarks alters the text semantics, its impact on\nreal-world applications remains unclear.",
    "494": "Consequently, many studies are now focusing on exploring\nthe effects of watermarking algorithms on specific downstream tasks to assess their impact on\ntext quality.",
    "495": "These tasks include machine translation [ 28,82,90,105], sentiment classification [ 92],\nknowledge understanding [ 85], code generation [ 39,74,85], text summarization [ 28,85,90], story\ngeneration [105], question answering [85], and instruction following [85], as shown in Figure 6.",
    "496": "Machine Translation.",
    "497": "Commonly, the assessment of watermarking in Large Language Models\n(Section 4) includes machine translation as a downstream task to evaluate text quality.",
    "498": "This\nevaluation involves comparing the translation outputs from watermarked and original non-\nwatermarked LLMs, utilizing the BLEU score, a standard metric in machine translation.",
    "499": "For\ntranslation LLMs, [ 28,90] utilized Multilingual BART [47], and Takezawa et al .",
    "500": "[76] employed the\nNLLB-200 model [ 13].",
    "501": "The WMT14 dataset, particularly translations between French, German,\nand English, is predominantly used for testing.",
    "502": "Watermarking LLMs typically leads to a marginal\nreduction in BLEU scores [ 33,45,76].",
    "503": "Nonetheless, unbiased watermark methods [ 28,90] show\nnegligible impact on BLEU scores, indicating their efficacy in maintaining translation quality.",
    "504": "Sentiment Classification.",
    "505": "Using sentiment classification as a downstream task can validate\nwhether text watermarking algorithms can affect the sentiment distribution, i.e., whether the text\ncan maintain its original sentiment (e.g., positive or negative) after the insertion of a watermark.",
    "506": "Yang et al .",
    "507": "[92] analyzed the sentiment distribution of texts with and without watermarks using\ntheTwitter-XLM-RoBERTa-Base-Sentiment2model.",
    "508": "Different sentiments generally have clear\ndifferences, making it easy for watermark algorithms to maintain sentiment distribution.",
    "509": "Knowledge Understanding.",
    "510": "To explore the performance of the watermark for LLMs algorithm\nin tasks with shorter output lengths, Tu et al .",
    "511": "[85] proposed testing on Knowledge Understanding\ntasks.",
    "512": "Specifically, this involves two scenarios: Knowledge Probing, using the KoLA dataset [ 97]\nfor assessing factual recall in LLMs, and Concept Probing, employing the Copen dataset [ 61] for\n1https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n2https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment\nPublication date: January 2024.18 Liu, et al.",
    "513": "Machine \nTranslationSentiment \nClassification\nKnowledge \nUnderstanding\nCode \nGeneration\nStory \nGeneration\nText \nSummarization\nQuestion \nAnswering\nInstruction \nFollowing\nFig.",
    "514": "6.",
    "515": "Specific downstream tasks used to evaluate the impact of text watermarking algorithms on\ntext quality.",
    "516": "evaluating conceptual understanding.",
    "517": "The typical evaluation metric for these tasks is the F1 score.",
    "518": "In practical tests, applying watermarks to Knowledge Understanding tasks significantly decreases\nthe F1 scores across all algorithms, indicating the challenging nature of this scenario.",
    "519": "Code Generation.",
    "520": "Text watermarking for code generation is an important application, which\ncould test the impact of watermarking on code functionality.",
    "521": "Code evaluation could use unit test\nmetrics like pass@k [ 37], or matching metrics such as BLEU and Exact match.",
    "522": "Sun et al .",
    "523": "[74]\nimplemented watermarking in a code dataset by embedding features in a dataset subset.",
    "524": "They\nreported minimal differences in BLEU and Exact match scores between models trained on datasets\nwith and without watermarks.",
    "525": "Nonetheless, watermarking individual code pieces is more complex\nthan watermarking an entire dataset.",
    "526": "Lee et al .",
    "527": "[39] incorporated watermarks into large models\nfor code generation, resulting in approximately a 10% decrease in pass@100 and pass@80 metrics.",
    "528": "Considering the sensitivity of code to minor alterations, preserving the code utility while achieving\nwatermarking poses a significant challenge[85].",
    "529": "Text Summarization.",
    "530": "Only the watermark algorithms for LLM consider text summarization as\na downstream evaluation task.",
    "531": "Specifically, it compares the effectiveness of text summarization\nbetween a watermarked Large Language Model (LLM) and an non-watermarked LLM.",
    "532": "The\nevaluation metric for text summarization is ROUGE [ 44].",
    "533": "Furthermore, the most frequently used\nlarge model for summarization is BART-Large [ 47], with the CNN-DM dataset [ 25] being prevalent.",
    "534": "In practical results, current watermark algorithms have a relatively minimal impact on text\nsummarization tasks.",
    "535": "The algorithm by Kirchenbauer et al .",
    "536": "[33] only causes a slight decrease in\nROUGE scores, whereas the unbiased watermark [ 28,90]algorithms hardly affect the ROUGE\nscores.",
    "537": "Story Generation.",
    "538": "Similar to text summarization tasks, story generation also presents a suitable\nscenario for evaluating watermark algorithms for Large Language Models.",
    "539": "Tests in the story\ngeneration context typically involve inputting the first half of a story and having the model (LLM)\npredict its ending.",
    "540": "The ROCstories dataset [ 56] is commonly used, with ROUGE as the evaluation\nmetric.",
    "541": "According to the experiments by Zhao et al .",
    "542": "[105] , current watermark algorithms still cause\na 1%-2% decrease in performance on ROUGE scores.",
    "543": "Question Answering.",
    "544": "Question answering (QA) is an important downstream application of\nLarge Language Models.",
    "545": "Tu et al .",
    "546": "[85] conducted tests on three different QA tasks, specifically: the\nELI5 dataset [ 17] for long-form QA tasks, the FinQA dataset [ 49] for Finance QA tasks, and the\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 19\nHotpotQA dataset [ 94] for multi-hop reasoning QA tasks.",
    "547": "For the long-form QA and Finance QA\ntasks, the Rouge-L metric was used for evaluation, while the F1 score was utilized for the multi-hop\nreasoning QA task.",
    "548": "Experimental results revealed that, after the introduction of watermarks,\nall current watermark algorithms experienced a performance decline of about 50% in QA tasks,\nindicating the challenging nature of watermark algorithms in the context of QA.",
    "549": "Instruction Following.",
    "550": "The capacity of Large Language Models (LLMs) to adhere to user\ninstructions in generating responses for open-ended tasks is increasingly crucial.",
    "551": "Tu et al .",
    "552": "[85]\nexamined the influence of the prevalent LLM watermarking algorithm on Instruction Following\nusing the AlpacaFarm dataset [ 15].",
    "553": "The assessment utilized GPT4-Judge [ 106], wherein GPT-4\nevaluates the appropriateness of outputs from the watermarked LLM and Davinci-003 in response\nto specific instructions.",
    "554": "According to this criterion, both the Llama2-7B-chat and Internlm-7B-\n8k models exhibited over a 90% decrease in performance when watermarked, highlighting the\nsignificant challenge watermark algorithms face in instruction following tasks.",
    "555": "5.2.4 Text Diversity.",
    "556": "Although previous text quality assessment methods provide comprehensive\nevaluations of consistency, fluency, and accuracy, they still overlook an essential aspect: assessing the\ndiversity of watermarked texts.",
    "557": "Diversity evaluation is often targeted at the watermark algorithms\nfor Large Language Models.",
    "558": "These algorithms embed watermarks into LLMs, necessitating an\nassessment of evaluating whether the diversity of the text generated by LLMs has changed.",
    "559": "Text\ndiversity is defined by calculating the proportion of unique n-grams in a text sequence, with the\nformula being the negative logarithm multiplied by the product of (1 - proportion) of unique\nn-grams from 1 to N. A higher diversity score indicates fewer repeated n-grams and richer text.",
    "560": "The specific formula is defined as follows:\nR𝑑=−log \n1−𝑁Ö\n𝑛=1(1−𝑢𝑛)!",
    "561": ", (15)\nwhere𝑢𝑛represents the ratio of different n-grams to the total number of n-grams in a given text\nsequence.",
    "562": "If a sequence contains many non-repeating n-grams, 𝑢𝑛will be close to 1, indicating\nhigh diversity.",
    "563": "Conversely, if many n-grams are repeated, 𝑢𝑛will be small, indicating low diversity.",
    "564": "In Kirchenbauer et al .",
    "565": "[34] , it was noted that for the KGW algorithm [ 33], context width—the\nnumber of tokens used to hash and create the green list—significantly influences text diversity.",
    "566": "A larger context width enhances the diversity of the text, but this comes at the cost of reduced\nrobustness of the watermark to text modifications.",
    "567": "Furthermore, with a larger context width, as\nthe watermark strength increases, so does the diversity.",
    "568": "Conversely, with a smaller context width,\nan increase in watermark strength leads to a decrease in diversity.",
    "569": "Presently, limited research on\nLLM watermarking addresses its impact on text diversity.",
    "570": "Future studies should focus more on this\naspect of watermarking evaluation.",
    "571": "5.3 Robustness\nAnother key metric for evaluation is the robustness against watermark removal attacks.",
    "572": "These\nattacks entail modifying watermarked text to erase the embedded watermark.",
    "573": "A watermarking\nalgorithm is considered highly robust if the watermark remains detectable post-attack.",
    "574": "Presently, watermark removal attack models assume black-box access to the watermarking\nalgorithm.",
    "575": "Here, the watermark generation method is undisclosed, and there is no access to the\nwatermark detector during the attack.",
    "576": "This assumption is due to the ease of developing effective\nremoval strategies under white-box access, which could potentially eliminate most watermarks,\nas highlighted by Kirchenbauer et al .",
    "577": "[34] in their anti-watermark framework.",
    "578": "In scenarios with\nblack-box access, several watermark removal attacks have been developed with the aim of erasing\nPublication date: January 2024.20 Liu, et al.",
    "579": "the watermark through textual modifications.",
    "580": "These methods are categorized based on modification\ngranularity, including character-level, word-level, and document-level attacks.",
    "581": "The subsequent\nsections will explore these attack implementations and evaluate the resilience of text watermarking\ntechniques against them.",
    "582": "5.3.1 Character-level Attack.",
    "583": "Character modification in text, without altering words, is a basic\nstrategy for watermark removal attacks.",
    "584": "One method involves introducing spelling errors by\nperturbing characters, but this can be easily identified and may degrade text quality.",
    "585": "An alternative\nstrategy involves replacing characters with visually similar Unicode IDs, leveraging the fact that\nmany Unicode IDs correspond to identical or visually indistinguishable characters.",
    "586": "This technique\nis also known as a Homoglyph attack [ 20].",
    "587": "Although such methods are difficult to detect by human\nobservation, they can still be mitigated by various canonicalization techniques [ 33].",
    "588": "Therefore,\nnormalization preprocessing before passing through watermark detectors is crucial.",
    "589": "The effectiveness of character-level attacks varies with different types of text watermark\nalgorithms.",
    "590": "For format-based watermark algorithms, which embed watermarks through Unicode\nID substitutions (e.g., EasyMark [ 72] replaces Unicode 0x0020 with 0x2004), Homoglyph attacks\nmay be a direct and effective method for watermark removal.",
    "591": "For other watermark algorithms, the\nimpact is on tokenizers; after character modification, the tokenizer may divide the word into a\ndifferent token list.",
    "592": "For instance, changing the \"a\" in \"apple\" to a Cyrillic character \"а\" alters the\ntokenization from [\"apple\"] to [\"а\", \"pple\"].",
    "593": "This change in tokenization result poses challenges to\nthe detection effectiveness of many watermark algorithms.",
    "594": "A character-level attack offers simplicity and effectiveness as its advantage.",
    "595": "However, its\ndrawback is that it is easily detectable or can be eliminated by some simply designed algorithms.",
    "596": "Therefore, it is not a reliable watermark removal attack in all scenarios.",
    "597": "5.3.2 Word-level Attack.",
    "598": "Compared to character-level attacks that only alter the surface of text,\nword-level attacks modify the content of the text by adding, deleting, or altering words to remove\nwatermarks [ 1,33,36,92,95,103].",
    "599": "These methods have a broader scope than character-level attacks,\nas they are less likely to be mitigated by rule-based methods and align more closely with realistic\nattack scenarios.",
    "600": "Currently, there are two main types of word-level attacks.",
    "601": "Word-level Attack to Existing Text.",
    "602": "Word-level attack to existing text refers to the insertion,\ndeletion, or replacement of words in a pre-generated watermarked text.",
    "603": "During the attack process,\nan attack rate is typically established, which is a certain likelihood of inserting, deleting, or replacing\neach token.",
    "604": "For example, when the deletion attack rate is set as 0.5, nearly half of the text will be\nremoved [ 92].",
    "605": "In terms of word substitution, synonym replacement is typically employed to ensure\nminimal impact on the semantics.",
    "606": "Specifically, the replacement word will be the one from the word\ndatabase giving the smallest sentence score difference, for example, BERT score difference.",
    "607": "For the two types of watermark methods: watermarking for existing text and watermarking\nfor Large Language Models (LLMs), the effects produced by word-level attacks vary.",
    "608": "Regarding\nwatermarking for existing text [ 1,92,95], word deletion has the most effect in removing text\nwatermark among the above three attacks.",
    "609": "While low deletion rate under 0.1 produces acceptable\nperformance drop, the figure exceeding 0.3 or more could result in the watermark severely damaged\nor even erased [ 92].",
    "610": "Word deletion stands out for two key reasons.",
    "611": "The first is that it can directly\nremove words that may contain embedded watermark information, whereas word insertion not\ndirectly delete existing watermark information and not all words have suitable synonyms during\nsynonyms substitution.",
    "612": "Secondly, word deletion significantly alters the semantics, surpassing both\nword insertion and synonym replacement, as these methods do not remove the original semantics.",
    "613": "Regarding watermarking during logits generaion methods (section 4.2), the basic attack effect\nis that the watermarked tokens (e.g.",
    "614": "green tokens in Kirchenbauer et al .",
    "615": "[33] ) in the text will be\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 21\ndisturbed.",
    "616": "Watermark methods [ 33,89,103] that rely on preceding tokens to determine the current\ntoken’s watermark status are more vulnerable to word-level attacks.",
    "617": "This is because word-level\nattacks not only change the current token but also modify its preceding tokens, thereby altering\nthe detection status of the current token.",
    "618": "Usually, to achieve significant performance drop, sustainable word-level attacks on the text is\nrequired.",
    "619": "That is, the attack rate should be large enough.",
    "620": "For example, to decrease detection F1\nscore below 80%, a minimal attack rate of 30% is required, which requires performing deletion\nor replacement every 3 words [ 92].",
    "621": "High attack rates drastically change semantics and degrade\ntext quality [ 1,33,92].",
    "622": "Word deletion with high attack rate may even leave each sentence\nincomplete.",
    "623": "Often, the text under such heavy word-level attacks is not ideal in real world, where\nthe watermark-removed text should still be usable and understandable.",
    "624": "In conclusion, although word-level attacks on existing watermarked texts perform well in some\nscenarios [ 95], they may not best simulate reality as exhibited by obvious quality issues due to lack\nof text understanding ability.",
    "625": "Word-level Attack during Text Generation.",
    "626": "Due to the inevitable impact on text quality\nduring word-level attack to existing texts, particularly when these modifications are extensive,\nrecent work has begun to explore word-level attacks during text generation.",
    "627": "These methods target\nwatermarking algorithms for LLMs.",
    "628": "A notable example is the emoji attack [ 21], which prompts the\nLLM to generate emojis between each token and then remove the emojis after generation.",
    "629": "This attack is effective when watermark embedding process depends on the preceding token.",
    "630": "Once the emojis are removed, the detector would fail to recognize the watermarked tokens, as\nemojis are intended to convey the watermarking information of a subsequent token [ 33,74].",
    "631": "For\nexample, a user could request the LLM to generate \" ⌣\" between every word, resulting in a sentence\nlooking like \"There ⌣are⌣some⌣apples⌣here\".",
    "632": "Assuming the word \"apples\" is watermarked,\nand the proper detection computation of this word needs its prefix, the emoji \" ⌣\".",
    "633": "However,\nthe user will remove the emojis before using this machine-generated text, making the prefix of\n\"apples\" become the word \"some\".",
    "634": "Detection using a different prefix will be inaccurate, and such\nmiscalculation is applied in every word of the watermarked text.",
    "635": "The advantage of such attacks is their near-complete erasure of certain watermarking methods\n[11,33].",
    "636": "However, they have two main disadvantages.",
    "637": "First, their effectiveness hinges on the LLM’s\nability to adhere to directives.",
    "638": "Advanced LLMs like ChatGPT and Claude can successfully perform\nemoji attacks, ensuring coherent text generation, but less advanced models might struggle, resulting\nin illogical outputs.",
    "639": "Second, the success of these attacks is intricately linked to the watermark\ngeneration mechanism.",
    "640": "For instance, the emoji attack presupposes that a token’s watermark status\ndepends on the preceding token’s hash value.",
    "641": "However, alternative approaches, like those by [ 46],\nwhich utilize generated text embeddings instead of relying on preceding token hashes, remain\nlargely unaffected by emoji attacks.",
    "642": "5.3.3 Document-level Attack.",
    "643": "While word-level attacks alter or remove text watermarks through\nindividual word modifications, their impact is comparatively confined.",
    "644": "Conversely, document-level\nattacks adopt a holistic and in-depth strategy.",
    "645": "They extend beyond mere word alterations in a\ndocument, encompassing extensive modifications to both content and structure.",
    "646": "Typical document-\nlevel attacks involve semantic-preserving rewrites, often referred to as rewrite attacks, and the\nintegration of watermark text into pre-existing human text, known as copy-paste attacks.",
    "647": "Rewrite Attack.",
    "648": "The rewrite attack offers comprehensive and in-depth modifications to text,\nyet its implementation is more challenging compared to the word-level approach.",
    "649": "Early methods of\nrewrite attacks often employed a re-translation strategy [ 92], which involves translating the text\ninto another language and then back into the original language.",
    "650": "This method exploits subtle changes\nPublication date: January 2024.22 Liu, et al.",
    "651": "that may occur during the translation process to achieve text rewriting.",
    "652": "While the re-translation\nmethod was widely used initially, its limitation lies in the potential introduction of additional\nerrors during double translation, which can result in significant semantic deviations from the\noriginal text.",
    "653": "Consequently, specialized language models for text rewriting, such as Dipper [ 35],\nhave been developed.",
    "654": "These models provide higher quality text and allow for configurable degrees\nof modification during the rewriting process.",
    "655": "With the recent popularity of ChatGPT, many studies\nand practices have started using it for text rewriting, most commonly the gpt-3.5-Turbo version.",
    "656": "Its advantage lies in requiring only a specific prompt for the text rewrite attack, such as \"please\nrewrite the following text:\".",
    "657": "For more realistic scenario validation, manual rewriting is also an\noption.",
    "658": "Manual rewriting offers more precise semantic preservation and more natural language\nexpression but has the main disadvantage of being costlier, especially when handling large amount\nof text.",
    "659": "The effectiveness of rewrite attacks varies for different types of watermarking methods.",
    "660": "Format-\nbased approaches [ 6,64,70,72] are particularly vulnerable, as homoglyphs are often replaced with\nstandard language tokens by LLMs or humans in the output.",
    "661": "For other algorithms that embed\nwatermarks based on text content, the impact of rewrite attacks depends on three factors: token\nsequence dependence, watermark strength, and text length.",
    "662": "Firstly, watermark detection methods that do not rely on token order, like Zhao et al .",
    "663": "[103] ’s\napproach, demonstrate greater robustness since rewrite attacks can disrupt token sequences\nbut are less effective at replacing all tokens.",
    "664": "In contrast, algorithms like Kuditipudi et al .",
    "665": "[36] ’s,\nwhere robustness hinges on token sequences, exhibit varying susceptibility levels to such attacks.",
    "666": "Secondly, the watermark strength, or the extent of text modification, is crucial.",
    "667": "Watermarking that\nnecessitates substantial alterations from the original text tends to enhance resistance against rewrite\nattacks.",
    "668": "Lastly, the length of the watermarked text is a significant factor.",
    "669": "Empirical evidence from\nKirchenbauer et al .",
    "670": "[33] indicates that texts with over 600 tokens generally maintain robustness\nagainst rewrite attacks.",
    "671": "It is also observed that manually erasing watermarks from texts of 400 to\n800 tokens through rewriting poses a considerable challenge for humans.",
    "672": "There are some designs to further increase algorithm robustness against rewrite attack as well.",
    "673": "1)\nDecrease the token-level dependency.",
    "674": "The dependency of watermark algorithms on specific contexts\ncan compromise their effectiveness when the original text is rewritten, as the original context may\nnot remain intact.",
    "675": "Take the watermarking during logits generation methods as example, if the\npartitioning of a token’s red-green list relies on 𝑚adjacent words, the detection rate significantly\ndecreases after an attack when 𝑚is not very small.",
    "676": "Hence, watermark algorithms should reduce\nreliance on neighboring words.",
    "677": "This can be achieved by decreasing the window size 𝑚[33], or by\nusing hashing schemes that only involve a subset of words within the window [ 34].",
    "678": "Some studies\nhave even reduced the window size 𝑚to zero [ 103].",
    "679": "2) Replace with semantic-level dependency.",
    "680": "A better approach is for the watermark algorithm to refer to the general semantics around the\nwatermarked token [ 46,95] instead of the exactly identical tokens or words.",
    "681": "That is to say, for a\ngroup of altered but semantically similar contexts, the watermark generator and detector would\nproduce the same result.",
    "682": "Unless the semantics is drastically altered, the watermark detection could\nmaintain a higher accuracy against rewrite attacks.",
    "683": "One can even train the watermark generator to\nproduce closer results on semantically close texts ;\nIt is worth noting that although human writers are stronger paraphrasers than machines, there\nare significant differences in individuals’ ability to rewrite text.",
    "684": "Moreover, when the text is lengthy,\nhumans are often powerless.",
    "685": "Copy-paste Attack.",
    "686": "Copy-paste attack is to surround the target text (watermarked text) with\ndistraction text (non-watermarked text).",
    "687": "This attack aims to test whether a low ratio of watermarked\ntext can cause a drop in algorithm effectiveness.",
    "688": "The copy-paste attack primarily diminishes the\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 23\ndetectability of watermarks in text by diluting their concentration.",
    "689": "The efficacy of this attack is\nsignificantly influenced by the proportion of watermarked text.",
    "690": "For instance, when the watermarked\ntext constitutes a mere 10% of the total, the attack’s impact tends to surpass that of most rewriting\nattacks [ 34].",
    "691": "However, as the share of watermarked text increases to, say, 25%, its effectiveness in\nundermining certain watermarking algorithms [ 33] becomes comparable to that of some rewriting\nattacks.",
    "692": "Similar to rewriting attacks, lengthening the text can enhance the reliability of watermark\ndetection, particularly in the context of copy-paste attacks.",
    "693": "However, copy-paste attacks may be identified by certain specific watermark detection methods.",
    "694": "For example, Kirchenbauer et al .",
    "695": "[34] mentioned a windowed test to calculate the level of\nwatermarking in a region of the text instead of the whole text.",
    "696": "It is specifically designed to\neffectively detect watermarked text that is inserted into existing text, making it applicable for\naddressing copy-paste attacks.",
    "697": "5.4 Unforgeability\nIn section 5.3, we discussed watermark removal attacks that assume the attacker is unaware of the\nwatermark’s generation method (black-box setting).",
    "698": "However, in real-world scenarios, attackers\nmay attempt to obtain or decipher the watermark’s generation method.",
    "699": "Once an attacker acquires\nthis method, they can easily fabricate or remove existing watermarks, as mentioned by [ 34]\nin their anti-watermark methods.",
    "700": "Therefore, a watermark algorithm must possess substantial\nunforgeability, meaning it should be exceedingly difficult for attackers to discern the method of\nwatermark generation.",
    "701": "This might imply that the algorithm itself needs to be highly complex and\nsecure, or involve mathematical problems that are challenging to crack.",
    "702": "The discussion on watermark unforgeability could be differentiated into two distinct scenarios:\nprivate detection and public detection.",
    "703": "In the private detection scenario, the watermark detection\nmethod is kept confidential, accessible only to specific users or institutions, or indirectly provided\nto users via an API [ 33].",
    "704": "This setup’s advantage lies in increasing the difficulty for attackers to\nobtain and analyze the detection algorithm, as they lack direct access to the detection mechanism.",
    "705": "Conversely, in the public detection scenario, the watermark detection algorithm is publicly\navailable, allowing anyone to access and utilize these algorithms.",
    "706": "In this scenario, attackers can\nmore easily study the detection algorithms and seek methods to breach the watermark.",
    "707": "Therefore,\nthe requirements for unforgeability in public detection scenarios might be higher.",
    "708": "5.4.1 Unforgeability in Privately Detectable Scenario.",
    "709": "In private detection scenarios, the\nimperceptibility of text watermarking algorithms is crucial for ensuring unforgeability due to\nthe limited detection capabilities of users.",
    "710": "Imperceptibility refers to the watermark’s impact on\nthe original content being nearly undetectable in its statistical distribution, which is essential for\nensuring the watermark’s non-forgery.",
    "711": "If users are unaware of the watermark in the text, they\ncannot forge it.",
    "712": "Therefore, some studies have focused on testing imperceptibility.",
    "713": "For instance,\nAbdelnabi and Fritz [1]collected texts with and without watermarks and trained classifiers to try\nto distinguish between these two categories.",
    "714": "The purpose of this test was to see if the classifiers\ncould effectively identify which texts contained watermarks.",
    "715": "The performance of the classifiers\nserves as a measure of the watermarking algorithm’s imperceptibility.",
    "716": "The classifiers’ efficacy in\ndetecting watermarks serves as a proxy for the algorithm’s imperceptibility, with ideal outcomes\nbeing their inability to distinguish between the two categories.",
    "717": "When text watermarking algorithms fail to achieve complete imperceptibility, or when attackers\nsuspect or infer the presence of watermarks in the text, they may resort to statistical methods\nto extract the details of the watermark generator.",
    "718": "These statistical attack methods primarily rely\non the analysis of statistical traces or patterns that the watermarking algorithm might leave in\nPublication date: January 2024.24 Liu, et al.",
    "719": "the text, which generally requires sufficient prior knowledge about the method of watermark\ninsertion.",
    "720": "For instance, Sadasivan et al .",
    "721": "[71] proposed a spoofing attack algorithm that can target\nnumerous watermarking during logits generation methods [ 33,103].",
    "722": "Specifically, this attack\ninvolves calculating the frequency of tokens in a text under a fixed prefix.",
    "723": "In watermarked texts, the\nfrequency of these tokens may differ from normal texts.",
    "724": "For instance, by analyzing the frequency\nof tokens following ‘the’, tokens that appear more frequently might be identified as part of the\nwatermark (green list [ 33]).",
    "725": "The effectiveness of this attack is closely related to the complexity\nof the watermarking method.",
    "726": "If a watermarking algorithm operates in a complex manner on a\ntext, statistical-based attacks become less effective.",
    "727": "This suggests that increasing the complexity of\nwatermarking algorithms is key to preventing such attacks.",
    "728": "For example, Liu et al .",
    "729": "[46] proposed\nusing text semantic information associated with the watermarking rule, which effectively resists\nspoofing attacks.",
    "730": "In the context of private watermark detection scenarios, several strategies are imperative.",
    "731": "First, detection frequency must be limited.",
    "732": "For watermark detection services via APIs, frequency-\nrestricting mechanisms can reduce attackers’ capacity to analyze the algorithm through repeated\nattempts, thus mitigating spoofing attacks [ 71].",
    "733": "Second, enhancing network security is critical to\nsafeguard watermark rules against theft.",
    "734": "This includes encrypted communications, regular security\nupdates, and intrusion detection systems.",
    "735": "Third, defending against social engineering attacks is\nessential.",
    "736": "These attacks exploit trust or coerce information disclosure.",
    "737": "Implementing stringent\ninternal security protocols and verification processes is crucial to prevent unauthorized release of\nsensitive data, such as watermark keys.",
    "738": "5.4.2 Unforgeability in Publicly Detectable Scenario.",
    "739": "Assessing the unforgeability of wa-\ntermark algorithms under publicly detectable scenarios is considerably more complex since the\nwatermark detector is publicly accessible, providing attackers with a wider range of cracking\nmethods.",
    "740": "In such scenarios, attackers could still employ previously mentioned statistical attack\nmethods, such as spoofing attacks [ 71], to analyze and extract the watermark’s generation rules.",
    "741": "Additionally, given the close relationship between watermark generation and detection algorithms,\nattackers may gain insights into the design of the watermark generator by directly analyzing the\nimplementation of the watermark detector.",
    "742": "Currently, the watermark detector in most watermarking algorithms involves details in watermark\ngenerator.",
    "743": "For example, KGW requires the hash key in watermark generator to determine whether\neach token is on the green list during the watermark detection process, which exposes the\nwatermark generation method.",
    "744": "Consequently, these watermarking algorithms lack unforgeability\nin publicly detectable scenarios, where the watermark detector is fully accessible to the public.",
    "745": "A\ntext watermarking algorithm with unforgeability must ensure that the watermark detector does\nnot reveal information about the watermark generator.",
    "746": "For instance, some current methods employ\nneural networks for watermark detection [ 1,45], achieving effective detection while preventing\nfurther information disclosure due to the black-box nature of neural networks.",
    "747": "For watermark detection algorithms that do not reveal watermark generation methods, evaluating\ntheir unforgeability poses a challenge.",
    "748": "Typically, it necessitates the design of complex attack\nalgorithms to assess their unforgeability.",
    "749": "For instance, Liu et al .",
    "750": "[45] proposed using reverse\ntraining, where a watermark generator is trained inversely based on the watermark detector.",
    "751": "The consistency between the trained and the actual watermark generator is used to evaluate\nunforgeability.",
    "752": "However, this approach also requires the attacker to have prior knowledge of\nthe watermark generator’s architecture.",
    "753": "If the attacker is unaware of the watermark generator’s\nimplementation, the attack becomes extremely difficult.",
    "754": "Overall, a greater variety of attacks need\nto be developed to effectively test unforgeability.",
    "755": "Publication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 25\nCopyright Protection\n Fake News Detection\nFig.",
    "756": "7.",
    "757": "This figure displays three major application scenarios of text watermarking: copyright\nprotection (section 6.1), academic integrity (section 6.2), and fake news detection (section 6.3).",
    "758": "6 APPLICATION FOR TEXT WATERMARKING\nIn preceding sections, we outlined the implementation methods of text watermarking technologies in\nthe era of LLMs and detailed how to thoroughly evaluate these methods.",
    "759": "This section delves into their\nreal-world applications, focusing on three areas: copyright protection [ 12,22,23,30,43,54,62,74,77–\n79,88,104,105], academic integrity [ 63,87,104], and fake news detection [ 50,51].",
    "760": "First, we analyze\nthe use of text watermarking for copyright protection of large models and datasets, preventing\ninfringement and misuse.",
    "761": "Second, we explore its importance in upholding academic integrity,\nincluding plagiarism detection and originality verification in academic outputs.",
    "762": "Finally, we assess\nits role in detecting and mitigating fake news, particularly within social media and news platforms.",
    "763": "Figure 7 provides an illustrative overview of these applications.",
    "764": "6.1 Copyright Protection\n6.1.1 Text/Dataset Copyright.",
    "765": "In the digital era, the protection of copyrights for texts and\ndatasets is particularly crucial.",
    "766": "As data sharing and utilization increase, safeguarding these assets\nfrom illegal replication and misuse becomes paramount.",
    "767": "Text watermarking technology plays a key\nrole in this regard, embedding imperceptible markers within texts and datasets to help preserve\nintellectual property rights.",
    "768": "Text copyright refers to the legal protection of original textual content, such as writings\nand online posts, ensuring unique rights for the creators.",
    "769": "Copyrighted texts should provide\nsufficient information to identify their creators and sources.",
    "770": "This protection extends beyond\ntraditional publications like books and journals to digital-era web articles, blog posts, and other\nonline contents.",
    "771": "Present research in textual copyright predominantly centers on format-based\nwatermarking algorithms (see section 3.1), primarily because these algorithms do not necessitate\ncontent alteration, which is a critical consideration for some creators.",
    "772": "For example, Taleby Ahvanooey et al .",
    "773": "[77] employs layout attributes like word and line spacing,\nalongside formatting elements such as text color and font, for watermark insertion.",
    "774": "Mir [54]\nintroduced an invisible digital watermark for web content, using encrypted semantic and syntactic\nrules converted into spaces with binary control characters, and embedded via HTML structure.",
    "775": "Furthermore, specific text formats may require tailored watermarking approaches, as illustrated by\nIqbal et al .",
    "776": "[30] , who embedded watermarks in MS-Word documents using unique features like\nvariables and bookmarks.",
    "777": "Despite the current reliance on format-based watermarking, the evolution of large language\nmodels points to integrating watermark algorithms with these models as a promising avenue for\nfuture text copyright protection research.",
    "778": "Publication date: January 2024.26 Liu, et al.",
    "779": "With the rise and widespread application of deep learning technology, the dataset copyright\nhas become particularly important, which means protecting datasets from unauthorized use has\nemerged as a crucial issue.",
    "780": "Text watermarking technology is central in this domain, creating\nwatermarked datasets by embedding watermarks into data.",
    "781": "Models trained on these datasets exhibit\nidentifiable features that discourage unauthorized exploitation.",
    "782": "The method of adding watermarks to datasets for copyright protection is almost identical to the\ntraining time watermarking method mentioned in Section 4.1.",
    "783": "Specifically, the dataset watermarking\nmethod involves adding a trigger to some of the text in the dataset.",
    "784": "This trigger, a specific input\nfeature, is associated with a particular output in the dataset, ensuring that models trained with this\ndataset produce the corresponding output feature when encountering the trigger.",
    "785": "This trigger can\nbe implemented by modifying labels.",
    "786": "For instance, Liu et al .",
    "787": "[48] altered the labels corresponding\nto text in a text classification dataset.",
    "788": "Sun et al .",
    "789": "[75] disrupted code in a code generation dataset.",
    "790": "However, this approach turns the corresponding data into noise data, potentially affecting the\nquality of the dataset.",
    "791": "Therefore, finding unique inputs to add as features is an effective method.",
    "792": "For\nexample, Tang et al .",
    "793": "[79] first used adversarial learning to identify data prone to misclassification,\nthen added triggers to this data.",
    "794": "Sun et al .",
    "795": "[74] added semantically invariant transformations to\ncode to incorporate triggers.",
    "796": "These watermarking techniques effectively protect the copyright\nof datasets.",
    "797": "However, there is still a lack of exploration into the copyright protection of datasets\nwhen only a small portion of the training data consists of watermarked datasets, which could be a\nsignificant direction for future research.",
    "798": "6.1.2 LLM Copyright.",
    "799": "In the field of copyright protection for LLMs, the key goal is to defend\nagainst extraction attacks, where significant data is extracted from LLMs to train new models.",
    "800": "A prevalent strategy for copyright protection involves embedding watermarks in LLM outputs.",
    "801": "Consequently, attackers inadvertently use watermarked datasets for training, leading to water-\nmarked characteristics in the new model’s outputs.",
    "802": "This approach parallels dataset copyright,\nwith the distinction that the watermarked dataset originates from an LLM.",
    "803": "Current efforts have\ndeveloped watermark algorithms for various LLM types, including embedding [ 62], generative\n[22,23,105], and classification [ 104] LLMs.",
    "804": "The input of an embedding LLM is text, and its output\nis the corresponding embedding of that text.",
    "805": "The generative LLM is currently the most commonly\nused LLM, with both its input and output being text.",
    "806": "In the case of a classification LLM, the input is\ntext, and the output is a specific category.",
    "807": "Peng et al .",
    "808": "[62] have developed a watermarking algorithm designed to protect embedding LLMs.",
    "809": "This algorithm initially involves the creation of a trigger set.",
    "810": "When the input contains a trigger\nfrom this set, the algorithm introduces a poison weight into the output embedding.",
    "811": "The ‘trigger’\nmentioned here is conceptually identical to that referenced in the context of dataset copyright in\nsection 6.1.1.",
    "812": "The new embedding model, trained with watermarked data, produces embeddings\nwith poison weights when encountering inputs containing triggers, thereby enabling detection.",
    "813": "For generative LLMs, He et al .",
    "814": "[22] implemented a method of embedding watermarks by\nsubstituting synonyms in the text already generated by LLMs.",
    "815": "During this synonym replacement\nprocess, certain ‘watermark tokens’ are preferentially selected.",
    "816": "Consequently, models trained with\nthese data tend to generate a higher proportion of watermark tokens, making them more easily\ndetectable.",
    "817": "However, a limitation of this approach is that the word frequency of the watermarked\ndata diverges from that of normal text, rendering the watermark more susceptible to detection and\nremoval.",
    "818": "To address this issue, He et al .",
    "819": "[23] conducted word substitution based on the context\nfeatures, which were derived from part-of-speech and dependency tree analyses.",
    "820": "This method\nensures that the frequency of each token remains unchanged.",
    "821": "However, even with this approach,\nthe practice of LLM generating text followed by synonym substitution is still vulnerable to being\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 27\ncircumvented by adversaries randomly replacing synonyms, thereby rendering this protection\nineffective.",
    "822": "To address this issue, Zhao et al .",
    "823": "[105] adopted the concept of watermarking during\nlogits generation (section 4.2).",
    "824": "They introduced a watermark into the output logits of the Large\nLanguage Model (LLM) by embedding a periodic signal.",
    "825": "Models trained using this watermarked\nLLM exhibit periodic signal characteristics in their outputs, making them detectable.",
    "826": "This approach\noffers more robust and invisible watermarks compared to previous methods.",
    "827": "Similarly, in the case of classification LLMs, Zhao et al .",
    "828": "[104] also adopted the approach\nof embedding a watermark by inserting periodic signals into the logits of the LLM output to\nenforce copyright protection.",
    "829": "Specifically, this involves introducing periodic signals into the logits\ncorresponding to a particular category, ensuring that models trained with data output from this\nmodified model will also contain these periodic signals in the output for that specific category.",
    "830": "However, this method inevitably impacts the quality of the output data, especially when users\nextract data using hard-labels (converting classification results into one-hot outputs) instead of\ncontinuous soft-labels.",
    "831": "Future work could explore how to embed watermarks in classification LLMs\nwith minimal impact on label quality for effective LLM copyright protection.",
    "832": "6.2 Academic Integrity\nAcademic integrity issues hold particular importance in today’s educational sphere, especially\ngiven the ease of access and use of large language models (LLMs).",
    "833": "Students might exploit these\nadvanced models to complete assignments, papers, or even participate in exams, presenting new\nchallenges to the upkeep of academic honesty.",
    "834": "In tasks or exams where independent and original\ncompletion by students is required, it becomes necessary to devise methods to ascertain whether\nthe submitted content is generated by a large language model.",
    "835": "The current work primarily explores the design of algorithms for automatically distinguishing\ntext generated by Large Language Models (LLMs) from human-written text.",
    "836": "For instance, Mitchell\net al.",
    "837": "[55] developed a GPT-based classifier, Detect-GPT, aimed at identifying LLM-generated text.",
    "838": "However, such methods lack interpretability and may not be robust to out-of-domain text.",
    "839": "To address\nthis issue, an online text detection tool, GPTZero3, operates on the assumption that LLM-generated\ntexts can be differentiated from human texts based on two metrics: perplexity (Equation 13) and\nburstiness.",
    "840": "Burstiness refers to the degree of uneven distribution in a text’s length, complexity,\nor information density.",
    "841": "Similarly, Vasilatos et al .",
    "842": "[87] also employed the perplexity feature to\ndistinguish between human and machine-generated texts.",
    "843": "Nonetheless, detection methods based\non perplexity and burstiness may be circumvented by deliberate text modifications.",
    "844": "Concurrently,\nthe promising technique of text watermarking remains underexplored in the field of academic\nintegrity, which should become a significant research direction in the future.",
    "845": "6.3 Fake News Detection\nLarge language models (LLMs) pose significant challenges in fake news detection due to their\ncapability to generate and rapidly disseminate false information [ 9,10].",
    "846": "The first concern involves\ntheir proficiency in creating convincing, yet potentially erroneous or misleading content.",
    "847": "This\nfeature makes LLMs effective tools for fabricating fake news, thereby deceiving the public and\ndistorting facts.",
    "848": "The second issue is the swift spread of such false information across digital\nplatforms, exacerbating the proliferation of incorrect viewpoints and eroding public trust in reliable\nsources [14, 107].",
    "849": "Thus, identifying LLM-generated news is critical.",
    "850": "Current research in combating fake AI-generated images and videos, such as the DISSIMILAR\nframework [ 51], employs watermark technology for detection.",
    "851": "However, less attention has been\n3https://gptzero.me/\nPublication date: January 2024.28 Liu, et al.",
    "852": "paid to false content produced by LLMs.",
    "853": "We propose two potential approaches in this field.",
    "854": "The\nfirst involves a method similar to the DISSIMILAR framework, where watermarks are added to text\ncontent before its publication on social media.",
    "855": "This approach would use format-based methods\n(3.1) to embed watermarks without altering the text’s content.",
    "856": "The second approach necessitates\ncollaboration with LLM providers, allowing them to embed watermarks and share watermark\ndetection methods with certain platforms, thereby facilitating the marking of LLM-generated\ncontent.",
    "857": "We recommend that future work should leverage text watermarking technology to aid in\nthe detection of false information.",
    "858": "7 CHALLENGES AND FUTURE DIRECTIONS\nAlthough detailed introductions to the methods, evaluations, and application scenarios of text\nwatermarking have been provided in previous sections, numerous challenges remain in this field.",
    "859": "These include balancing across different evaluation perspectives, adapting text watermarking for\nmore challenging scenarios, developing more comprehensive benchmarks, and broadening the\napplication of text watermarking.",
    "860": "These challenges will be discussed in detail below.",
    "861": "7.1 Balancing Across Different Evaluation Perspectives\nIn section 5, we explore various perspectives for evaluating text watermarking algorithms.",
    "862": "However,\nthese perspectives often present inherent contradictions, making it extremely challenging for a\ntext watermarking algorithm to excel in all evaluation perspectives simultaneously.",
    "863": "For instance,\nachieving a favorable balance among success rate, text quality, and robustness at a high payload is\ndifficult.",
    "864": "In this section, we will first analyze why these perspectives are mutually contradictory,\nand then discuss potential strategies for achieving a better balance in future work.",
    "865": "7.1.1 Why are the Different Perspectives Conflicting?",
    "866": "The fundamental reason for contradic-\ntions among different perspectives lies in the limited suitable text space for text watermarking,\nusually determined by the text quality requirements.",
    "867": "Specifically, according to Equation 2, the score\ndifference between watermarked and non-watermarked texts under the quality evaluation function\nRshould be less than a threshold 𝛽.",
    "868": "However, the number of texts meeting this criterion is limited,\ndenoted as|𝑡𝛽|.",
    "869": "Since the minimal impact on text quality is a crucial feature of text watermarking\nalgorithms, there is an upper limit for |𝑡𝛽|for all watermarking algorithms.",
    "870": "Given the watermark\ntext space of|𝑡𝛽|, we can further analyze the conflicts between different evaluation perspectives.",
    "871": "We begin by introducing conflicts among success rate, text quality, and robustness at a high\npayload.",
    "872": "Payload and robustness involve different strategies for partitioning this limited text\nspace.",
    "873": "If the space is divided to encode more watermark messages (i.e., a larger payload), minor\nmodifications to any watermarked text are more likely to result in detection as another watermark\nmessage, thus reducing robustness.",
    "874": "Conversely, reducing the number of watermark messages\nencoded (i.e., lower payload) decreases the likelihood that modifications to watermarked text\nresult in other watermark information, thereby increasing robustness.",
    "875": "Hence, the conflict between\npayload and robustness is evident.",
    "876": "Simultaneously, as text quality requirements increase, the size\nof the text space|𝑡𝛽|diminishes, potentially leading to a decrease in both payload and robustness,\nmaking the conflict between text quality and these two metrics obvious.",
    "877": "Lastly, we analyze why unforgeability and other evaluation perspectives might conflict.",
    "878": "Typically,\nenhancing the complexity of watermarking algorithms can improve their unforgeability.",
    "879": "However,\nincorporating additional complex modules into the algorithm often introduces greater robustness\nrisks.",
    "880": "Moreover, in publicly detectable scenarios, algorithms seeking to enhance unforgeability\noften conceal their detection methods using some watermark text space [ 16,45], thereby conflicting\nwith other evaluation approaches.",
    "881": "Publication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 29\n7.1.2 Future Directions.",
    "882": "The current text watermarking algorithms primarily focus on balancing\nrobustness and the impact on text quality.",
    "883": "However, these efforts often do not simultaneously\naddress payload and unforgeability, which should be the main focus of future work.",
    "884": "The key to balancing payload, robustness, and text quality lies primarily in devising a more\neffective strategy for partitioning the watermark text space.",
    "885": "This may require additional designs to\ncounter potential watermark removal attacks, dividing the watermark space into different watermark\nmessages, ensuring that transitioning between different watermark messages necessitates a\nsufficient number of watermark removal attack operations.",
    "886": "Secondly, from the perspective of the\npayload, it is feasible to draw inspiration from the concepts of error-correction codes, such as\nutilizing Hamming codes [ 38], to enhance the probability of recovering the original watermark\ninformation from partially modified text.",
    "887": "These methods may effectively enhance payload and\nrobustness while maintaining a consistent impact on text quality.",
    "888": "To enhance the unforgeability of text watermarks, it is generally necessary to utilize expertise\nfrom fields such as cryptography, information theory, and machine learning.",
    "889": "This involves increasing\nthe complexity of watermarking algorithms to improve their resistance to forgery.",
    "890": "Although current\nmethods have made some progress, their more intricate designs still introduce additional non-robust\nfactors.",
    "891": "Furthermore, these methods have not been extended to scenarios with larger payloads.",
    "892": "7.2 Adapting Text Watermarking for More Challenging Scenarios\nCurrent watermark algorithms often achieve satisfactory results in relatively simple contexts.",
    "893": "However, they require further enhancement and adaptation when confronted with more challenging\nscenarios, such as low-entropy scenarios and publicly detectable scenarios.",
    "894": "In low-entropy situations like coding, legal, and medical texts, diversity and complexity are\ntypically reduced.",
    "895": "These types of texts typically adhere to strict formatting (grammatical) require-\nments, so embedding watermarks without affecting these requirements is challenging.",
    "896": "A more\nin-depth explanation is that for low-entropy text, the upper limit of the watermark text space\nis lower, thereby making it harder to find suitable watermark text.",
    "897": "Future methods may need a\nstronger understanding of their formatting or grammatical requirements, and thereby designing\nsemantically invariant format transformations to expand the available watermark text space.",
    "898": "In scenarios where watermarks are publicly detectable, both the presence of the watermark\nand its detection mechanism are openly visible.",
    "899": "This poses greater challenges for the design of\nwatermark algorithms.",
    "900": "Firstly, the algorithm must be sufficiently complex and unpredictable to\nensure that, even in a public setting, attackers struggle to effectively corrupt or alter the watermark\ninformation.",
    "901": "Secondly, the design must ensure that the watermark’s generation method cannot\nbe inferred even through its detector.",
    "902": "This primarily involves considerations of unforgeability,\nbut in publicly detectable scenarios, there are also heightened demands for robustness and text\nquality.",
    "903": "Future methods will need to integrate considerations of security and practicality, potentially\ninvolving more intricate encryption and machine learning technologies.",
    "904": "7.3 Developing More Comprehensive Benchmarks\nCurrent research in text watermarking benchmark primarily focuses on text quality, with limited\nbenchmarks for other critical metrics like high success rate with large payload, robustness, and\nunforgeability.",
    "905": "Therefore, developing a more comprehensive benchmarking system is a crucial\ndirection for future research.",
    "906": "Constructing such benchmarks requires significant effort, taking into\naccount various application scenarios, attack methods, and characteristics of different watermarking\nalgorithms.",
    "907": "It also necessitates establishing a fair, transparent, and user-friendly evaluation process,\nallowing researchers to test and compare algorithms under unified standards.",
    "908": "This benchmarking\nPublication date: January 2024.30 Liu, et al.",
    "909": "system will not only advance academic research into text watermarking algorithms but also aid the\nindustry in better understanding and applying these technologies.",
    "910": "7.4 Broadening the Application of Text Watermarking\nAlthough text watermarking technology has demonstrated its practicality in multiple domains,\nits wider application necessitates further efforts.",
    "911": "This encompasses not only advancements in\nwatermarking techniques but also factors beyond the technical realm.",
    "912": "In this section, we will explore\nthe challenges faced in expanding the applications of text watermarking technology, particularly\nfrom the perspectives of large language model providers, public trust, and transparency.",
    "913": "7.4.1 Limited Engagement of Large Language Model Providers.",
    "914": "As an increasing amount of\ntext is generated directly by large language models, it is crucial for providers of these LLMs to\nintegrate text watermarking functionality into their services to promote the use of text watermarks.",
    "915": "However, the current level of engagement from these providers in text watermarking technology\nremains insufficient, influenced by various technical and non-technical factors.",
    "916": "Firstly, current text watermarking algorithms cannot guarantee no reduction in text quality,\nwhich may impact the service quality of model providers.",
    "917": "Technically, this demands future text\nwatermarking algorithms to consider the impact on text quality more thoroughly.",
    "918": "Additionally,\nthe direct benefit for LLM providers from text watermarking technology lies in the protection of\nthe LLMs’ copyrights.",
    "919": "More focus on research in this area is needed to encourage providers to\nparticipate more actively in promoting text watermarking technology.",
    "920": "Moreover, non-technical factors also affect the engagement level of large model providers.",
    "921": "For\ninstance, the role of governments and regulatory bodies is significant.",
    "922": "There needs to be a discussion\non how governments should use legal restrictions or incentives to encourage model providers to\nadopt watermarking technology.",
    "923": "This could involve setting relevant standards and norms, as well\nas providing economic incentives to encourage the adoption of these technologies.",
    "924": "7.4.2 Lack of Public Trust.",
    "925": "Public trust and transparency in text watermarking technology\nare key factors in promoting its widespread application.",
    "926": "Only when the public trusts the text\nwatermarking algorithms and believes in the accuracy of their detection results can they be\neffectively utilized in practical applications.",
    "927": "To enhance public trust, it is necessary to ensure the\ntransparency and reliability of watermarking technology.",
    "928": "A fundamental step towards this goal involves the comprehensive disclosure of the text\nwatermarking detection algorithms.",
    "929": "Making these details accessible allows users to grasp and\nassess the principles and accuracy of the algorithms.",
    "930": "Such transparency not only cultivates user\ntrust but also spurs further academic and industrial advancements.",
    "931": "Moreover, involving independent third-party platforms for detection and verification can\nstrengthen trust.",
    "932": "These platforms offer unbiased evaluations, alleviating conflict of interest\nconcerns.",
    "933": "Furthermore, government and regulatory guidelines can ensure the technology’s fairness\nand transparency, further boosting public confidence.",
    "934": "8 CONCLUSION\nThis survey thoroughly delves into the landscape of text watermarking in the era of large language\nmodels (LLMs), encompassing its implementation, evaluation methods, applications in fields like\ncopyright protection, academic integrity, and fake news detection, as well as the challenges and\nfuture directions of the domain.",
    "935": "Despite the progress made, several areas require further exploration.",
    "936": "The balance between\nrobustness, watermark payload and impact on text quality remains a crucial challenge, as does the\nneed for watermarking methods that can adapt to the evolving capabilities of LLMs.",
    "937": "Additionally,\nPublication date: January 2024.A Survey of Text Watermarking in the Era of Large Language Models 31\nthe integration of watermarking techniques in real-world applications presents practical challenges,\nincluding scalability, legal considerations, and ethical implications.",
    "938": "Future research should focus on creating advanced watermarking algorithms capable of with-\nstanding novel attack types, especially where attackers have access to sophisticated tools and\nknowledge.",
    "939": "Exploring watermarking in new applications like authenticity verification of AI-\ngenerated content in social media and journalism is crucial for maintaining the integrity and\ntrustworthiness of digital content.",
    "940": "In summary, text watermarking in the era of LLMs is a rapidly evolving field with significant\npotential and challenges.",
    "941": "Its development will be critical in ensuring the responsible and ethical\nuse of AI technologies in various sectors.",
    "942": "REFERENCES\n[1]Sahar Abdelnabi and Mario Fritz.",
    "943": "2021."
}